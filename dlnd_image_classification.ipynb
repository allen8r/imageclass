{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Image Classification\n",
    "In this project, you'll classify images from the [CIFAR-10 dataset](https://www.cs.toronto.edu/~kriz/cifar.html).  The dataset consists of airplanes, dogs, cats, and other objects. You'll preprocess the images, then train a convolutional neural network on all the samples. The images need to be normalized and the labels need to be one-hot encoded.  You'll get to apply what you learned and build a convolutional, max pooling, dropout, and fully connected layers.  At the end, you'll get to see your neural network's predictions on the sample images.\n",
    "## Get the Data\n",
    "Run the following cell to download the [CIFAR-10 dataset for python](https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CIFAR-10 Dataset: 171MB [00:32, 5.30MB/s]                              \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files found!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "from urllib.request import urlretrieve\n",
    "from os.path import isfile, isdir\n",
    "from tqdm import tqdm\n",
    "import problem_unittests as tests\n",
    "import tarfile\n",
    "\n",
    "cifar10_dataset_folder_path = 'cifar-10-batches-py'\n",
    "\n",
    "# Use Floyd's cifar-10 dataset if present\n",
    "floyd_cifar10_location = '/input/cifar-10/python.tar.gz'\n",
    "if isfile(floyd_cifar10_location):\n",
    "    tar_gz_path = floyd_cifar10_location\n",
    "else:\n",
    "    tar_gz_path = 'cifar-10-python.tar.gz'\n",
    "\n",
    "class DLProgress(tqdm):\n",
    "    last_block = 0\n",
    "\n",
    "    def hook(self, block_num=1, block_size=1, total_size=None):\n",
    "        self.total = total_size\n",
    "        self.update((block_num - self.last_block) * block_size)\n",
    "        self.last_block = block_num\n",
    "\n",
    "if not isfile(tar_gz_path):\n",
    "    with DLProgress(unit='B', unit_scale=True, miniters=1, desc='CIFAR-10 Dataset') as pbar:\n",
    "        urlretrieve(\n",
    "            'https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz',\n",
    "            tar_gz_path,\n",
    "            pbar.hook)\n",
    "\n",
    "if not isdir(cifar10_dataset_folder_path):\n",
    "    with tarfile.open(tar_gz_path) as tar:\n",
    "        tar.extractall()\n",
    "        tar.close()\n",
    "\n",
    "\n",
    "tests.test_folder_path(cifar10_dataset_folder_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Explore the Data\n",
    "The dataset is broken into batches to prevent your machine from running out of memory.  The CIFAR-10 dataset consists of 5 batches, named `data_batch_1`, `data_batch_2`, etc.. Each batch contains the labels and images that are one of the following:\n",
    "* airplane\n",
    "* automobile\n",
    "* bird\n",
    "* cat\n",
    "* deer\n",
    "* dog\n",
    "* frog\n",
    "* horse\n",
    "* ship\n",
    "* truck\n",
    "\n",
    "Understanding a dataset is part of making predictions on the data.  Play around with the code cell below by changing the `batch_id` and `sample_id`. The `batch_id` is the id for a batch (1-5). The `sample_id` is the id for a image and label pair in the batch.\n",
    "\n",
    "Ask yourself \"What are all possible labels?\", \"What is the range of values for the image data?\", \"Are the labels in order or random?\".  Answers to questions like these will help you preprocess the data and end up with better predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stats of batch 1:\n",
      "Samples: 10000\n",
      "Label Counts: {0: 1005, 1: 974, 2: 1032, 3: 1016, 4: 999, 5: 937, 6: 1030, 7: 1001, 8: 1025, 9: 981}\n",
      "First 20 Labels: [6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, 9, 9, 3, 2, 6]\n",
      "\n",
      "Example of Image 505:\n",
      "Image - Min Value: 0 Max Value: 252\n",
      "Image - Shape: (32, 32, 3)\n",
      "Label - Label Id: 4 Name: deer\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfoAAAH0CAYAAADVH+85AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nnMEAAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ffb7447c748>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 250,
       "width": 253
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import helper\n",
    "import numpy as np\n",
    "\n",
    "# Explore the dataset\n",
    "batch_id = 1\n",
    "sample_id = 505\n",
    "helper.display_stats(cifar10_dataset_folder_path, batch_id, sample_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Implement Preprocess Functions\n",
    "### Normalize\n",
    "In the cell below, implement the `normalize` function to take in image data, `x`, and return it as a normalized Numpy array. The values should be in the range of 0 to 1, inclusive.  The return object should be the same shape as `x`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def normalize(x):\n",
    "    \"\"\"\n",
    "    Normalize a list of sample image data in the range of 0 to 1\n",
    "    : x: List of image data.  The image shape is (32, 32, 3)\n",
    "    : return: Numpy array of normalize data\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    x_min = x.min()\n",
    "    x_max = x.max()\n",
    "    return (x - x_min) / (x_max - x_min)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_normalize(normalize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### One-hot encode\n",
    "Just like the previous code cell, you'll be implementing a function for preprocessing.  This time, you'll implement the `one_hot_encode` function. The input, `x`, are a list of labels.  Implement the function to return the list of labels as One-Hot encoded Numpy array.  The possible values for labels are 0 to 9. The one-hot encoding function should return the same encoding for each value between each call to `one_hot_encode`.  Make sure to save the map of encodings outside the function.\n",
    "\n",
    "Hint: Don't reinvent the wheel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def one_hot_encode(x):\n",
    "    \"\"\"\n",
    "    One hot encode a list of sample labels. Return a one-hot encoded vector for each label.\n",
    "    : x: List of sample Labels\n",
    "    : return: Numpy array of one-hot encoded labels\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    encoded = np.zeros([len(x), 10])\n",
    "    for i in range(len(x)):\n",
    "        encoded[i][x[i]] = 1\n",
    "    \n",
    "    return encoded\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_one_hot_encode(one_hot_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Randomize Data\n",
    "As you saw from exploring the data above, the order of the samples are randomized.  It doesn't hurt to randomize it again, but you don't need to for this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Preprocess all the data and save it\n",
    "Running the code cell below will preprocess all the CIFAR-10 data and save it to file. The code below also uses 10% of the training data for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "# Preprocess Training, Validation, and Testing Data\n",
    "helper.preprocess_and_save_data(cifar10_dataset_folder_path, normalize, one_hot_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Check Point\n",
    "This is your first checkpoint.  If you ever decide to come back to this notebook or have to restart the notebook, you can start from here.  The preprocessed data has been saved to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "import pickle\n",
    "import problem_unittests as tests\n",
    "import helper\n",
    "\n",
    "# Load the Preprocessed Validation data\n",
    "valid_features, valid_labels = pickle.load(open('preprocess_validation.p', mode='rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Build the network\n",
    "For the neural network, you'll build each layer into a function.  Most of the code you've seen has been outside of functions. To test your code more thoroughly, we require that you put each layer in a function.  This allows us to give you better feedback and test for simple mistakes using our unittests before you submit your project.\n",
    "\n",
    ">**Note:** If you're finding it hard to dedicate enough time for this course each week, we've provided a small shortcut to this part of the project. In the next couple of problems, you'll have the option to use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages to build each layer, except the layers you build in the \"Convolutional and Max Pooling Layer\" section.  TF Layers is similar to Keras's and TFLearn's abstraction to layers, so it's easy to pickup.\n",
    "\n",
    ">However, if you would like to get the most out of this course, try to solve all the problems _without_ using anything from the TF Layers packages. You **can** still use classes from other packages that happen to have the same name as ones you find in TF Layers! For example, instead of using the TF Layers version of the `conv2d` class, [tf.layers.conv2d](https://www.tensorflow.org/api_docs/python/tf/layers/conv2d), you would want to use the TF Neural Network version of `conv2d`, [tf.nn.conv2d](https://www.tensorflow.org/api_docs/python/tf/nn/conv2d). \n",
    "\n",
    "Let's begin!\n",
    "\n",
    "### Input\n",
    "The neural network needs to read the image data, one-hot encoded labels, and dropout keep probability. Implement the following functions\n",
    "* Implement `neural_net_image_input`\n",
    " * Return a [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder)\n",
    " * Set the shape using `image_shape` with batch size set to `None`.\n",
    " * Name the TensorFlow placeholder \"x\" using the TensorFlow `name` parameter in the [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder).\n",
    "* Implement `neural_net_label_input`\n",
    " * Return a [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder)\n",
    " * Set the shape using `n_classes` with batch size set to `None`.\n",
    " * Name the TensorFlow placeholder \"y\" using the TensorFlow `name` parameter in the [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder).\n",
    "* Implement `neural_net_keep_prob_input`\n",
    " * Return a [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder) for dropout keep probability.\n",
    " * Name the TensorFlow placeholder \"keep_prob\" using the TensorFlow `name` parameter in the [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder).\n",
    "\n",
    "These names will be used at the end of the project to load your saved model.\n",
    "\n",
    "Note: `None` for shapes in TensorFlow allow for a dynamic size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Input Tests Passed.\n",
      "Label Input Tests Passed.\n",
      "Keep Prob Tests Passed.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "def neural_net_image_input(image_shape):\n",
    "    \"\"\"\n",
    "    Return a Tensor for a batch of image input\n",
    "    : image_shape: Shape of the images\n",
    "    : return: Tensor for image input.\n",
    "    \"\"\"\n",
    "    return tf.placeholder(tf.float32, shape=[None] + list(image_shape), name='x')\n",
    "\n",
    "\n",
    "def neural_net_label_input(n_classes):\n",
    "    \"\"\"\n",
    "    Return a Tensor for a batch of label input\n",
    "    : n_classes: Number of classes\n",
    "    : return: Tensor for label input.\n",
    "    \"\"\"\n",
    "    return tf.placeholder(tf.float32, shape=[None] + [n_classes], name='y')\n",
    "\n",
    "\n",
    "def neural_net_keep_prob_input():\n",
    "    \"\"\"\n",
    "    Return a Tensor for keep probability\n",
    "    : return: Tensor for keep probability.\n",
    "    \"\"\"\n",
    "    return tf.placeholder(tf.float32, name='keep_prob')\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tf.reset_default_graph()\n",
    "tests.test_nn_image_inputs(neural_net_image_input)\n",
    "tests.test_nn_label_inputs(neural_net_label_input)\n",
    "tests.test_nn_keep_prob_inputs(neural_net_keep_prob_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Convolution and Max Pooling Layer\n",
    "Convolution layers have a lot of success with images. For this code cell, you should implement the function `conv2d_maxpool` to apply convolution then max pooling:\n",
    "* Create the weight and bias using `conv_ksize`, `conv_num_outputs` and the shape of `x_tensor`.\n",
    "* Apply a convolution to `x_tensor` using weight and `conv_strides`.\n",
    " * We recommend you use same padding, but you're welcome to use any padding.\n",
    "* Add bias\n",
    "* Add a nonlinear activation to the convolution.\n",
    "* Apply Max Pooling using `pool_ksize` and `pool_strides`.\n",
    " * We recommend you use same padding, but you're welcome to use any padding.\n",
    "\n",
    "**Note:** You **can't** use [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) for **this** layer, but you can still use TensorFlow's [Neural Network](https://www.tensorflow.org/api_docs/python/tf/nn) package. You may still use the shortcut option for all the **other** layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def conv2d_maxpool(x_tensor, conv_num_outputs, conv_ksize, conv_strides, pool_ksize, pool_strides):\n",
    "    \"\"\"\n",
    "    Apply convolution then max pooling to x_tensor\n",
    "    :param x_tensor: TensorFlow Tensor\n",
    "    :param conv_num_outputs: Number of outputs for the convolutional layer\n",
    "    :param conv_ksize: kernal size 2-D Tuple for the convolutional layer\n",
    "    :param conv_strides: Stride 2-D Tuple for convolution\n",
    "    :param pool_ksize: kernal size 2-D Tuple for pool\n",
    "    :param pool_strides: Stride 2-D Tuple for pool\n",
    "    : return: A tensor that represents convolution and max pooling of x_tensor\n",
    "    \"\"\"\n",
    "        \n",
    "    weight = tf.Variable(tf.truncated_normal(\n",
    "            [conv_ksize[0], conv_ksize[1], int(x_tensor.shape[3]), conv_num_outputs]))\n",
    "    \n",
    "    bias = tf.Variable(tf.zeros(conv_num_outputs))\n",
    "    \n",
    "    # Apply the convolution\n",
    "    conv_layer = tf.nn.conv2d(\n",
    "        x_tensor, \n",
    "        weight, \n",
    "        strides=[1, conv_strides[0], conv_strides[1], 1], \n",
    "        padding='SAME')\n",
    "    \n",
    "    # Add Bias\n",
    "    conv_layer = tf.nn.bias_add(conv_layer, bias)\n",
    "    \n",
    "    # Add nonlinear activation\n",
    "    conv_layer = tf.nn.relu(conv_layer)\n",
    "    \n",
    "    # Apply max pooling\n",
    "    conv_layer = tf.nn.max_pool(\n",
    "        conv_layer, \n",
    "        ksize=[1, pool_ksize[0], pool_ksize[1], 1],\n",
    "        strides=[1, pool_strides[0], pool_strides[1], 1], \n",
    "        padding='SAME')\n",
    "\n",
    "    return conv_layer\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_con_pool(conv2d_maxpool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Flatten Layer\n",
    "Implement the `flatten` function to change the dimension of `x_tensor` from a 4-D tensor to a 2-D tensor.  The output should be the shape (*Batch Size*, *Flattened Image Size*). Shortcut option: you can use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages for this layer. For more of a challenge, only use other TensorFlow packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def flatten(x_tensor):\n",
    "    \"\"\"\n",
    "    Flatten x_tensor to (Batch Size, Flattened Image Size)\n",
    "    : x_tensor: A tensor of size (Batch Size, ...), where ... are the image dimensions.\n",
    "    : return: A tensor of size (Batch Size, Flattened Image Size).\n",
    "    \"\"\"\n",
    "    img_height = int(x_tensor.shape[1])\n",
    "    img_weight = int(x_tensor.shape[2])\n",
    "    img_depth = int(x_tensor.shape[3])\n",
    "    return tf.reshape(x_tensor, [-1, img_height * img_weight * img_depth])\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_flatten(flatten)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Fully-Connected Layer\n",
    "Implement the `fully_conn` function to apply a fully connected layer to `x_tensor` with the shape (*Batch Size*, *num_outputs*). Shortcut option: you can use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages for this layer. For more of a challenge, only use other TensorFlow packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def fully_conn(x_tensor, num_outputs):\n",
    "    \"\"\"\n",
    "    Apply a fully connected layer to x_tensor using weight and bias\n",
    "    : x_tensor: A 2-D tensor where the first dimension is batch size.\n",
    "    : num_outputs: The number of output that the new tensor should be.\n",
    "    : return: A 2-D tensor where the second dimension is num_outputs.\n",
    "    \"\"\"\n",
    "    fully_connected = tf.contrib.layers.fully_connected(x_tensor, num_outputs)\n",
    "    return tf.nn.relu(fully_connected)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_fully_conn(fully_conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Output Layer\n",
    "Implement the `output` function to apply a fully connected layer to `x_tensor` with the shape (*Batch Size*, *num_outputs*). Shortcut option: you can use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages for this layer. For more of a challenge, only use other TensorFlow packages.\n",
    "\n",
    "**Note:** Activation, softmax, or cross entropy should **not** be applied to this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def output(x_tensor, num_outputs):\n",
    "    \"\"\"\n",
    "    Apply a output layer to x_tensor using weight and bias\n",
    "    : x_tensor: A 2-D tensor where the first dimension is batch size.\n",
    "    : num_outputs: The number of output that the new tensor should be.\n",
    "    : return: A 2-D tensor where the second dimension is num_outputs.\n",
    "    \"\"\"\n",
    "    return tf.contrib.layers.fully_connected(x_tensor, num_outputs)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_output(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Create Convolutional Model\n",
    "Implement the function `conv_net` to create a convolutional neural network model. The function takes in a batch of images, `x`, and outputs logits.  Use the layers you created above to create this model:\n",
    "\n",
    "* Apply 1, 2, or 3 Convolution and Max Pool layers\n",
    "* Apply a Flatten Layer\n",
    "* Apply 1, 2, or 3 Fully Connected Layers\n",
    "* Apply an Output Layer\n",
    "* Return the output\n",
    "* Apply [TensorFlow's Dropout](https://www.tensorflow.org/api_docs/python/tf/nn/dropout) to one or more layers in the model using `keep_prob`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network Built!\n"
     ]
    }
   ],
   "source": [
    "def conv_net(x, keep_prob):\n",
    "    \"\"\"\n",
    "    Create a convolutional neural network model\n",
    "    : x: Placeholder tensor that holds image data.\n",
    "    : keep_prob: Placeholder tensor that hold dropout keep probability.\n",
    "    : return: Tensor that represents logits\n",
    "    \"\"\"\n",
    "    # Apply 1, 2, or 3 Convolution and Max Pool layers\n",
    "    #    Play around with different number of outputs, kernel size and stride\n",
    "    # Function Definition from Above:\n",
    "    #    conv2d_maxpool(x_tensor, conv_num_outputs, conv_ksize, conv_strides, pool_ksize, pool_strides)\n",
    "    \n",
    "    conv_layer = conv2d_maxpool(x, 32, (5,5), (2,2), (2,2), (1,1))\n",
    "    #conv_layer = tf.nn.dropout(conv_layer, keep_prob)\n",
    "\n",
    "    conv_layer = conv2d_maxpool(conv_layer, 32, (5,5), (1,1), (2,2), (1,1))\n",
    "    #conv_layer = tf.nn.dropout(conv_layer, keep_prob)\n",
    "\n",
    "    conv_layer = conv2d_maxpool(conv_layer, 64, (5,5), (1,1), (2,2), (1,1))\n",
    "    conv_layer = tf.nn.dropout(conv_layer, keep_prob)\n",
    "    \n",
    "    # Apply a Flatten Layer\n",
    "    # Function Definition from Above:\n",
    "    #   flatten(x_tensor)\n",
    "    conv_layer = flatten(conv_layer)\n",
    "\n",
    "    # Apply 1, 2, or 3 Fully Connected Layers\n",
    "    #    Play around with different number of outputs\n",
    "    # Function Definition from Above:\n",
    "    #   fully_conn(x_tensor, num_outputs)\n",
    "    full_conn_layer = fully_conn(conv_layer, 512)\n",
    "    #full_conn_layer = tf.nn.dropout(full_conn_layer, keep_prob)\n",
    "    \n",
    "    #full_conn_layer = fully_conn(full_conn_layer, 10)\n",
    "    #full_conn_layer = tf.nn.dropout(full_conn_layer, keep_prob)\n",
    "    \n",
    "    # Apply an Output Layer\n",
    "    #    Set this to the number of classes\n",
    "    # Function Definition from Above:\n",
    "    #   output(x_tensor, num_outputs)\n",
    "    output_layer = output(full_conn_layer, 10)\n",
    "    \n",
    "    \n",
    "    return output_layer\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "\n",
    "##############################\n",
    "## Build the Neural Network ##\n",
    "##############################\n",
    "\n",
    "# Remove previous weights, bias, inputs, etc..\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Inputs\n",
    "x = neural_net_image_input((32, 32, 3))\n",
    "y = neural_net_label_input(10)\n",
    "keep_prob = neural_net_keep_prob_input()\n",
    "\n",
    "# Model\n",
    "logits = conv_net(x, keep_prob)\n",
    "\n",
    "# Name logits Tensor, so that is can be loaded from disk after training\n",
    "logits = tf.identity(logits, name='logits')\n",
    "\n",
    "# Loss and Optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y))\n",
    "optimizer = tf.train.AdamOptimizer().minimize(cost)\n",
    "\n",
    "# Accuracy\n",
    "correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name='accuracy')\n",
    "\n",
    "tests.test_conv_net(conv_net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Train the Neural Network\n",
    "### Single Optimization\n",
    "Implement the function `train_neural_network` to do a single optimization.  The optimization should use `optimizer` to optimize in `session` with a `feed_dict` of the following:\n",
    "* `x` for image input\n",
    "* `y` for labels\n",
    "* `keep_prob` for keep probability for dropout\n",
    "\n",
    "This function will be called for each batch, so `tf.global_variables_initializer()` has already been called.\n",
    "\n",
    "Note: Nothing needs to be returned. This function is only optimizing the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def train_neural_network(session, optimizer, keep_probability, feature_batch, label_batch):\n",
    "    \"\"\"\n",
    "    Optimize the session on a batch of images and labels\n",
    "    : session: Current TensorFlow session\n",
    "    : optimizer: TensorFlow optimizer function\n",
    "    : keep_probability: keep probability\n",
    "    : feature_batch: Batch of Numpy image data\n",
    "    : label_batch: Batch of Numpy label data\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    session.run(optimizer, feed_dict={\n",
    "            x: feature_batch,\n",
    "            y: label_batch,\n",
    "            keep_prob: keep_probability\n",
    "        })\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_train_nn(train_neural_network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Show Stats\n",
    "Implement the function `print_stats` to print loss and validation accuracy.  Use the global variables `valid_features` and `valid_labels` to calculate validation accuracy.  Use a keep probability of `1.0` to calculate the loss and validation accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def print_stats(session, feature_batch, label_batch, cost, accuracy):\n",
    "    \"\"\"\n",
    "    Print information about loss and validation accuracy\n",
    "    : session: Current TensorFlow session\n",
    "    : feature_batch: Batch of Numpy image data\n",
    "    : label_batch: Batch of Numpy label data\n",
    "    : cost: TensorFlow cost function\n",
    "    : accuracy: TensorFlow accuracy function\n",
    "    \"\"\"\n",
    "    loss = session.run(cost, feed_dict={\n",
    "                x: feature_batch,\n",
    "                y: label_batch,\n",
    "                keep_prob: 1.0\n",
    "        })\n",
    "    \n",
    "    val_acc = session.run(accuracy, feed_dict={\n",
    "                x: valid_features,\n",
    "                y: valid_labels,\n",
    "                keep_prob: 1.0\n",
    "        })\n",
    "    \n",
    "    print(\"Loss: {:<20}\".format(loss), \"Validation Accuracy: {}\".format(val_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Hyperparameters\n",
    "Tune the following parameters:\n",
    "* Set `epochs` to the number of iterations until the network stops learning or start overfitting\n",
    "* Set `batch_size` to the highest number that your machine has memory for.  Most people set them to common sizes of memory:\n",
    " * 64\n",
    " * 128\n",
    " * 256\n",
    " * ...\n",
    "* Set `keep_probability` to the probability of keeping a node using dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# TODO: Tune Parameters\n",
    "epochs = 400\n",
    "batch_size = 1024\n",
    "keep_probability = 0.85"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Train on a Single CIFAR-10 Batch\n",
    "Instead of training the neural network on all the CIFAR-10 batches of data, let's use a single batch. This should save time while you iterate on the model to get a better accuracy.  Once the final validation accuracy is 50% or greater, run the model on all the data in the next section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking the Training on a Single Batch...\n",
      "Epoch  1, CIFAR-10 Batch 1:  Loss: 2.616894006729126    Validation Accuracy: 0.10799999535083771\n",
      "Epoch  2, CIFAR-10 Batch 1:  Loss: 2.2948203086853027   Validation Accuracy: 0.1289999783039093\n",
      "Epoch  3, CIFAR-10 Batch 1:  Loss: 2.2409207820892334   Validation Accuracy: 0.18239998817443848\n",
      "Epoch  4, CIFAR-10 Batch 1:  Loss: 2.2607040405273438   Validation Accuracy: 0.17019999027252197\n",
      "Epoch  5, CIFAR-10 Batch 1:  Loss: 2.207207202911377    Validation Accuracy: 0.19999998807907104\n",
      "Epoch  6, CIFAR-10 Batch 1:  Loss: 2.129110336303711    Validation Accuracy: 0.23179998993873596\n",
      "Epoch  7, CIFAR-10 Batch 1:  Loss: 2.1111228466033936   Validation Accuracy: 0.24939996004104614\n",
      "Epoch  8, CIFAR-10 Batch 1:  Loss: 2.0773963928222656   Validation Accuracy: 0.2759999930858612\n",
      "Epoch  9, CIFAR-10 Batch 1:  Loss: 2.0454955101013184   Validation Accuracy: 0.2889999747276306\n",
      "Epoch 10, CIFAR-10 Batch 1:  Loss: 2.012801170349121    Validation Accuracy: 0.30699998140335083\n",
      "Epoch 11, CIFAR-10 Batch 1:  Loss: 2.002556085586548    Validation Accuracy: 0.3157999813556671\n",
      "Epoch 12, CIFAR-10 Batch 1:  Loss: 2.037741184234619    Validation Accuracy: 0.3001999855041504\n",
      "Epoch 13, CIFAR-10 Batch 1:  Loss: 1.976001501083374    Validation Accuracy: 0.3083999752998352\n",
      "Epoch 14, CIFAR-10 Batch 1:  Loss: 1.9335527420043945   Validation Accuracy: 0.319599986076355\n",
      "Epoch 15, CIFAR-10 Batch 1:  Loss: 1.9019110202789307   Validation Accuracy: 0.3474000096321106\n",
      "Epoch 16, CIFAR-10 Batch 1:  Loss: 1.8921518325805664   Validation Accuracy: 0.34859997034072876\n",
      "Epoch 17, CIFAR-10 Batch 1:  Loss: 1.864613652229309    Validation Accuracy: 0.3691999912261963\n",
      "Epoch 18, CIFAR-10 Batch 1:  Loss: 1.8406566381454468   Validation Accuracy: 0.37139996886253357\n",
      "Epoch 19, CIFAR-10 Batch 1:  Loss: 1.7897846698760986   Validation Accuracy: 0.3829999566078186\n",
      "Epoch 20, CIFAR-10 Batch 1:  Loss: 1.7768995761871338   Validation Accuracy: 0.3845999538898468\n",
      "Epoch 21, CIFAR-10 Batch 1:  Loss: 1.7449190616607666   Validation Accuracy: 0.39579999446868896\n",
      "Epoch 22, CIFAR-10 Batch 1:  Loss: 1.7105141878128052   Validation Accuracy: 0.40720000863075256\n",
      "Epoch 23, CIFAR-10 Batch 1:  Loss: 1.6971274614334106   Validation Accuracy: 0.405599981546402\n",
      "Epoch 24, CIFAR-10 Batch 1:  Loss: 1.6875736713409424   Validation Accuracy: 0.4015999734401703\n",
      "Epoch 25, CIFAR-10 Batch 1:  Loss: 1.684442400932312    Validation Accuracy: 0.4016000032424927\n",
      "Epoch 26, CIFAR-10 Batch 1:  Loss: 1.619970679283142    Validation Accuracy: 0.41679999232292175\n",
      "Epoch 27, CIFAR-10 Batch 1:  Loss: 1.6085090637207031   Validation Accuracy: 0.4169999957084656\n",
      "Epoch 28, CIFAR-10 Batch 1:  Loss: 1.5999877452850342   Validation Accuracy: 0.4187999367713928\n",
      "Epoch 29, CIFAR-10 Batch 1:  Loss: 1.5712544918060303   Validation Accuracy: 0.4277999699115753\n",
      "Epoch 30, CIFAR-10 Batch 1:  Loss: 1.5853774547576904   Validation Accuracy: 0.4103999733924866\n",
      "Epoch 31, CIFAR-10 Batch 1:  Loss: 1.5028353929519653   Validation Accuracy: 0.4333999454975128\n",
      "Epoch 32, CIFAR-10 Batch 1:  Loss: 1.5027025938034058   Validation Accuracy: 0.4309999644756317\n",
      "Epoch 33, CIFAR-10 Batch 1:  Loss: 1.4617964029312134   Validation Accuracy: 0.4323999583721161\n",
      "Epoch 34, CIFAR-10 Batch 1:  Loss: 1.4261776208877563   Validation Accuracy: 0.45479995012283325\n",
      "Epoch 35, CIFAR-10 Batch 1:  Loss: 1.3878397941589355   Validation Accuracy: 0.4479999840259552\n",
      "Epoch 36, CIFAR-10 Batch 1:  Loss: 1.355328917503357    Validation Accuracy: 0.4487999379634857\n",
      "Epoch 37, CIFAR-10 Batch 1:  Loss: 1.3692477941513062   Validation Accuracy: 0.4413999915122986\n",
      "Epoch 38, CIFAR-10 Batch 1:  Loss: 1.3041037321090698   Validation Accuracy: 0.45579996705055237\n",
      "Epoch 39, CIFAR-10 Batch 1:  Loss: 1.2512210607528687   Validation Accuracy: 0.46239998936653137\n",
      "Epoch 40, CIFAR-10 Batch 1:  Loss: 1.2154494524002075   Validation Accuracy: 0.45899999141693115\n",
      "Epoch 41, CIFAR-10 Batch 1:  Loss: 1.157616376876831    Validation Accuracy: 0.46439996361732483\n",
      "Epoch 42, CIFAR-10 Batch 1:  Loss: 1.188421607017517    Validation Accuracy: 0.4533999562263489\n",
      "Epoch 43, CIFAR-10 Batch 1:  Loss: 1.1555012464523315   Validation Accuracy: 0.45639997720718384\n",
      "Epoch 44, CIFAR-10 Batch 1:  Loss: 1.120251178741455    Validation Accuracy: 0.4589999318122864\n",
      "Epoch 45, CIFAR-10 Batch 1:  Loss: 1.140390396118164    Validation Accuracy: 0.4509999752044678\n",
      "Epoch 46, CIFAR-10 Batch 1:  Loss: 1.1035635471343994   Validation Accuracy: 0.4485999345779419\n",
      "Epoch 47, CIFAR-10 Batch 1:  Loss: 1.1462152004241943   Validation Accuracy: 0.4297999441623688\n",
      "Epoch 48, CIFAR-10 Batch 1:  Loss: 1.0758569240570068   Validation Accuracy: 0.43959999084472656\n",
      "Epoch 49, CIFAR-10 Batch 1:  Loss: 1.051092267036438    Validation Accuracy: 0.46299996972084045\n",
      "Epoch 50, CIFAR-10 Batch 1:  Loss: 1.0362029075622559   Validation Accuracy: 0.47039997577667236\n",
      "Epoch 51, CIFAR-10 Batch 1:  Loss: 0.9647254943847656   Validation Accuracy: 0.4625999331474304\n",
      "Epoch 52, CIFAR-10 Batch 1:  Loss: 1.0457990169525146   Validation Accuracy: 0.44159996509552\n",
      "Epoch 53, CIFAR-10 Batch 1:  Loss: 0.9624759554862976   Validation Accuracy: 0.4421999752521515\n",
      "Epoch 54, CIFAR-10 Batch 1:  Loss: 0.8343948125839233   Validation Accuracy: 0.4753999710083008\n",
      "Epoch 55, CIFAR-10 Batch 1:  Loss: 0.713765025138855    Validation Accuracy: 0.504599928855896\n",
      "Epoch 56, CIFAR-10 Batch 1:  Loss: 0.6000471115112305   Validation Accuracy: 0.5057999491691589\n",
      "Epoch 57, CIFAR-10 Batch 1:  Loss: 0.6175028681755066   Validation Accuracy: 0.5101999640464783\n",
      "Epoch 58, CIFAR-10 Batch 1:  Loss: 0.5130137205123901   Validation Accuracy: 0.5183999538421631\n",
      "Epoch 59, CIFAR-10 Batch 1:  Loss: 0.46391165256500244  Validation Accuracy: 0.5255999565124512\n",
      "Epoch 60, CIFAR-10 Batch 1:  Loss: 0.4415402114391327   Validation Accuracy: 0.5203999280929565\n",
      "Epoch 61, CIFAR-10 Batch 1:  Loss: 0.4378952383995056   Validation Accuracy: 0.5103999376296997\n",
      "Epoch 62, CIFAR-10 Batch 1:  Loss: 0.41276606917381287  Validation Accuracy: 0.5125999450683594\n",
      "Epoch 63, CIFAR-10 Batch 1:  Loss: 0.4599458575248718   Validation Accuracy: 0.5019999146461487\n",
      "Epoch 64, CIFAR-10 Batch 1:  Loss: 0.4338502883911133   Validation Accuracy: 0.5155999660491943\n",
      "Epoch 65, CIFAR-10 Batch 1:  Loss: 0.42502331733703613  Validation Accuracy: 0.5153999328613281\n",
      "Epoch 66, CIFAR-10 Batch 1:  Loss: 0.3630649149417877   Validation Accuracy: 0.5225999355316162\n",
      "Epoch 67, CIFAR-10 Batch 1:  Loss: 0.3690228760242462   Validation Accuracy: 0.5117999315261841\n",
      "Epoch 68, CIFAR-10 Batch 1:  Loss: 0.37656620144844055  Validation Accuracy: 0.5059999823570251\n",
      "Epoch 69, CIFAR-10 Batch 1:  Loss: 0.32419833540916443  Validation Accuracy: 0.5149999260902405\n",
      "Epoch 70, CIFAR-10 Batch 1:  Loss: 0.3252493739128113   Validation Accuracy: 0.5199999213218689\n",
      "Epoch 71, CIFAR-10 Batch 1:  Loss: 0.28990888595581055  Validation Accuracy: 0.5157999396324158\n",
      "Epoch 72, CIFAR-10 Batch 1:  Loss: 0.24545937776565552  Validation Accuracy: 0.5259999632835388\n",
      "Epoch 73, CIFAR-10 Batch 1:  Loss: 0.2233595848083496   Validation Accuracy: 0.5273999571800232\n",
      "Epoch 74, CIFAR-10 Batch 1:  Loss: 0.20559906959533691  Validation Accuracy: 0.525399923324585\n",
      "Epoch 75, CIFAR-10 Batch 1:  Loss: 0.18910163640975952  Validation Accuracy: 0.5305999517440796\n",
      "Epoch 76, CIFAR-10 Batch 1:  Loss: 0.18177101016044617  Validation Accuracy: 0.5225999355316162\n",
      "Epoch 77, CIFAR-10 Batch 1:  Loss: 0.17691722512245178  Validation Accuracy: 0.5231999754905701\n",
      "Epoch 78, CIFAR-10 Batch 1:  Loss: 0.17680981755256653  Validation Accuracy: 0.5227999687194824\n",
      "Epoch 79, CIFAR-10 Batch 1:  Loss: 0.22599205374717712  Validation Accuracy: 0.5133999586105347\n",
      "Epoch 80, CIFAR-10 Batch 1:  Loss: 0.23136724531650543  Validation Accuracy: 0.5165998935699463\n",
      "Epoch 81, CIFAR-10 Batch 1:  Loss: 0.225701704621315    Validation Accuracy: 0.5069999694824219\n",
      "Epoch 82, CIFAR-10 Batch 1:  Loss: 0.24669817090034485  Validation Accuracy: 0.5131999850273132\n",
      "Epoch 83, CIFAR-10 Batch 1:  Loss: 0.19710323214530945  Validation Accuracy: 0.5125999450683594\n",
      "Epoch 84, CIFAR-10 Batch 1:  Loss: 0.1768341064453125   Validation Accuracy: 0.5149999260902405\n",
      "Epoch 85, CIFAR-10 Batch 1:  Loss: 0.20126864314079285  Validation Accuracy: 0.5133999586105347\n",
      "Epoch 86, CIFAR-10 Batch 1:  Loss: 0.2006417214870453   Validation Accuracy: 0.5099999904632568\n",
      "Epoch 87, CIFAR-10 Batch 1:  Loss: 0.2649315893650055   Validation Accuracy: 0.4869999885559082\n",
      "Epoch 88, CIFAR-10 Batch 1:  Loss: 0.2637224793434143   Validation Accuracy: 0.5001999735832214\n",
      "Epoch 89, CIFAR-10 Batch 1:  Loss: 0.2516328692436218   Validation Accuracy: 0.5077999830245972\n",
      "Epoch 90, CIFAR-10 Batch 1:  Loss: 0.16710343956947327  Validation Accuracy: 0.5135999321937561\n",
      "Epoch 91, CIFAR-10 Batch 1:  Loss: 0.16764560341835022  Validation Accuracy: 0.5145999193191528\n",
      "Epoch 92, CIFAR-10 Batch 1:  Loss: 0.13350306451320648  Validation Accuracy: 0.5195999145507812\n",
      "Epoch 93, CIFAR-10 Batch 1:  Loss: 0.14544972777366638  Validation Accuracy: 0.5157999992370605\n",
      "Epoch 94, CIFAR-10 Batch 1:  Loss: 0.10061712563037872  Validation Accuracy: 0.5199999809265137\n",
      "Epoch 95, CIFAR-10 Batch 1:  Loss: 0.09015373140573502  Validation Accuracy: 0.5275999307632446\n",
      "Epoch 96, CIFAR-10 Batch 1:  Loss: 0.10305358469486237  Validation Accuracy: 0.5279999375343323\n",
      "Epoch 97, CIFAR-10 Batch 1:  Loss: 0.09895031899213791  Validation Accuracy: 0.5191999673843384\n",
      "Epoch 98, CIFAR-10 Batch 1:  Loss: 0.10119634866714478  Validation Accuracy: 0.5194000005722046\n",
      "Epoch 99, CIFAR-10 Batch 1:  Loss: 0.13145971298217773  Validation Accuracy: 0.504599928855896\n",
      "Epoch 100, CIFAR-10 Batch 1:  Loss: 0.10928291082382202  Validation Accuracy: 0.5090000033378601\n",
      "Epoch 101, CIFAR-10 Batch 1:  Loss: 0.09531640261411667  Validation Accuracy: 0.518799901008606\n",
      "Epoch 102, CIFAR-10 Batch 1:  Loss: 0.11477770656347275  Validation Accuracy: 0.5035998821258545\n",
      "Epoch 103, CIFAR-10 Batch 1:  Loss: 0.1232127770781517   Validation Accuracy: 0.49619996547698975\n",
      "Epoch 104, CIFAR-10 Batch 1:  Loss: 0.12065748125314713  Validation Accuracy: 0.5055999159812927\n",
      "Epoch 105, CIFAR-10 Batch 1:  Loss: 0.09837601333856583  Validation Accuracy: 0.5087999701499939\n",
      "Epoch 106, CIFAR-10 Batch 1:  Loss: 0.12113121896982193  Validation Accuracy: 0.5157999396324158\n",
      "Epoch 107, CIFAR-10 Batch 1:  Loss: 0.12015542387962341  Validation Accuracy: 0.5111998915672302\n",
      "Epoch 108, CIFAR-10 Batch 1:  Loss: 0.08902055770158768  Validation Accuracy: 0.5245999693870544\n",
      "Epoch 109, CIFAR-10 Batch 1:  Loss: 0.08741492033004761  Validation Accuracy: 0.5137999653816223\n",
      "Epoch 110, CIFAR-10 Batch 1:  Loss: 0.08606725186109543  Validation Accuracy: 0.5005999207496643\n",
      "Epoch 111, CIFAR-10 Batch 1:  Loss: 0.13964113593101501  Validation Accuracy: 0.4959999620914459\n",
      "Epoch 112, CIFAR-10 Batch 1:  Loss: 0.20144964754581451  Validation Accuracy: 0.48019999265670776\n",
      "Epoch 113, CIFAR-10 Batch 1:  Loss: 0.1698511838912964   Validation Accuracy: 0.4893999695777893\n",
      "Epoch 114, CIFAR-10 Batch 1:  Loss: 0.1317008137702942   Validation Accuracy: 0.5099999308586121\n",
      "Epoch 115, CIFAR-10 Batch 1:  Loss: 0.08196178823709488  Validation Accuracy: 0.5271999835968018\n",
      "Epoch 116, CIFAR-10 Batch 1:  Loss: 0.06076174974441528  Validation Accuracy: 0.527999997138977\n",
      "Epoch 117, CIFAR-10 Batch 1:  Loss: 0.06320012360811234  Validation Accuracy: 0.5321999192237854\n",
      "Epoch 118, CIFAR-10 Batch 1:  Loss: 0.06881193071603775  Validation Accuracy: 0.528999924659729\n",
      "Epoch 119, CIFAR-10 Batch 1:  Loss: 0.048243455588817596 Validation Accuracy: 0.5371999144554138\n",
      "Epoch 120, CIFAR-10 Batch 1:  Loss: 0.06169624999165535  Validation Accuracy: 0.5269998908042908\n",
      "Epoch 121, CIFAR-10 Batch 1:  Loss: 0.05331556871533394  Validation Accuracy: 0.5231999158859253\n",
      "Epoch 122, CIFAR-10 Batch 1:  Loss: 0.05887152627110481  Validation Accuracy: 0.5157999396324158\n",
      "Epoch 123, CIFAR-10 Batch 1:  Loss: 0.110740065574646    Validation Accuracy: 0.4939999580383301\n",
      "Epoch 124, CIFAR-10 Batch 1:  Loss: 0.2252744883298874   Validation Accuracy: 0.4711999297142029\n",
      "Epoch 125, CIFAR-10 Batch 1:  Loss: 0.20207533240318298  Validation Accuracy: 0.4723999500274658\n",
      "Epoch 126, CIFAR-10 Batch 1:  Loss: 0.11965011805295944  Validation Accuracy: 0.5083999633789062\n",
      "Epoch 127, CIFAR-10 Batch 1:  Loss: 0.07071121037006378  Validation Accuracy: 0.5219998955726624\n",
      "Epoch 128, CIFAR-10 Batch 1:  Loss: 0.057874131947755814 Validation Accuracy: 0.5171999335289001\n",
      "Epoch 129, CIFAR-10 Batch 1:  Loss: 0.046542294323444366 Validation Accuracy: 0.5347999334335327\n",
      "Epoch 130, CIFAR-10 Batch 1:  Loss: 0.04053403064608574  Validation Accuracy: 0.5371999144554138\n",
      "Epoch 131, CIFAR-10 Batch 1:  Loss: 0.03962629660964012  Validation Accuracy: 0.531999945640564\n",
      "Epoch 132, CIFAR-10 Batch 1:  Loss: 0.037780243903398514 Validation Accuracy: 0.5297999382019043\n",
      "Epoch 133, CIFAR-10 Batch 1:  Loss: 0.036602262407541275 Validation Accuracy: 0.5333999395370483\n",
      "Epoch 134, CIFAR-10 Batch 1:  Loss: 0.036604657769203186 Validation Accuracy: 0.5347999334335327\n",
      "Epoch 135, CIFAR-10 Batch 1:  Loss: 0.035257913172245026 Validation Accuracy: 0.5351999402046204\n",
      "Epoch 136, CIFAR-10 Batch 1:  Loss: 0.035757437348365784 Validation Accuracy: 0.5345999598503113\n",
      "Epoch 137, CIFAR-10 Batch 1:  Loss: 0.03482285141944885  Validation Accuracy: 0.5363999605178833\n",
      "Epoch 138, CIFAR-10 Batch 1:  Loss: 0.03454402834177017  Validation Accuracy: 0.5363999605178833\n",
      "Epoch 139, CIFAR-10 Batch 1:  Loss: 0.03460492566227913  Validation Accuracy: 0.5377999544143677\n",
      "Epoch 140, CIFAR-10 Batch 1:  Loss: 0.03417007252573967  Validation Accuracy: 0.53739994764328\n",
      "Epoch 141, CIFAR-10 Batch 1:  Loss: 0.03407520800828934  Validation Accuracy: 0.5387999415397644\n",
      "Epoch 142, CIFAR-10 Batch 1:  Loss: 0.03382628783583641  Validation Accuracy: 0.53739994764328\n",
      "Epoch 143, CIFAR-10 Batch 1:  Loss: 0.03363897651433945  Validation Accuracy: 0.5383999347686768\n",
      "Epoch 144, CIFAR-10 Batch 1:  Loss: 0.03358025476336479  Validation Accuracy: 0.5369999408721924\n",
      "Epoch 145, CIFAR-10 Batch 1:  Loss: 0.03330855444073677  Validation Accuracy: 0.5381999015808105\n",
      "Epoch 146, CIFAR-10 Batch 1:  Loss: 0.03341764956712723  Validation Accuracy: 0.5393999814987183\n",
      "Epoch 147, CIFAR-10 Batch 1:  Loss: 0.033256299793720245 Validation Accuracy: 0.5397999286651611\n",
      "Epoch 148, CIFAR-10 Batch 1:  Loss: 0.0335359051823616   Validation Accuracy: 0.5373998880386353\n",
      "Epoch 149, CIFAR-10 Batch 1:  Loss: 0.033433061093091965 Validation Accuracy: 0.5379999279975891\n",
      "Epoch 150, CIFAR-10 Batch 1:  Loss: 0.032773833721876144 Validation Accuracy: 0.539199948310852\n",
      "Epoch 151, CIFAR-10 Batch 1:  Loss: 0.03310953080654144  Validation Accuracy: 0.5393999814987183\n",
      "Epoch 152, CIFAR-10 Batch 1:  Loss: 0.0327509343624115   Validation Accuracy: 0.539199948310852\n",
      "Epoch 153, CIFAR-10 Batch 1:  Loss: 0.03286340832710266  Validation Accuracy: 0.5401999950408936\n",
      "Epoch 154, CIFAR-10 Batch 1:  Loss: 0.03270639479160309  Validation Accuracy: 0.5385999083518982\n",
      "Epoch 155, CIFAR-10 Batch 1:  Loss: 0.03256555646657944  Validation Accuracy: 0.5375999212265015\n",
      "Epoch 156, CIFAR-10 Batch 1:  Loss: 0.032586775720119476 Validation Accuracy: 0.5389999151229858\n",
      "Epoch 157, CIFAR-10 Batch 1:  Loss: 0.03255530074238777  Validation Accuracy: 0.5397999286651611\n",
      "Epoch 158, CIFAR-10 Batch 1:  Loss: 0.03267424553632736  Validation Accuracy: 0.5387999415397644\n",
      "Epoch 159, CIFAR-10 Batch 1:  Loss: 0.03242163360118866  Validation Accuracy: 0.53739994764328\n",
      "Epoch 160, CIFAR-10 Batch 1:  Loss: 0.03274953365325928  Validation Accuracy: 0.5371999740600586\n",
      "Epoch 161, CIFAR-10 Batch 1:  Loss: 0.03230453282594681  Validation Accuracy: 0.5381999015808105\n",
      "Epoch 162, CIFAR-10 Batch 1:  Loss: 0.03247363120317459  Validation Accuracy: 0.5389999151229858\n",
      "Epoch 163, CIFAR-10 Batch 1:  Loss: 0.03225326165556908  Validation Accuracy: 0.5383999347686768\n",
      "Epoch 164, CIFAR-10 Batch 1:  Loss: 0.032326191663742065 Validation Accuracy: 0.5361999273300171\n",
      "Epoch 165, CIFAR-10 Batch 1:  Loss: 0.032274167984724045 Validation Accuracy: 0.5411999225616455\n",
      "Epoch 166, CIFAR-10 Batch 1:  Loss: 0.03222965821623802  Validation Accuracy: 0.5389999747276306\n",
      "Epoch 167, CIFAR-10 Batch 1:  Loss: 0.03234907612204552  Validation Accuracy: 0.5389999151229858\n",
      "Epoch 168, CIFAR-10 Batch 1:  Loss: 0.03238790109753609  Validation Accuracy: 0.5375999212265015\n",
      "Epoch 169, CIFAR-10 Batch 1:  Loss: 0.03219422325491905  Validation Accuracy: 0.5395999550819397\n",
      "Epoch 170, CIFAR-10 Batch 1:  Loss: 0.03225220367312431  Validation Accuracy: 0.5377999544143677\n",
      "Epoch 171, CIFAR-10 Batch 1:  Loss: 0.0321655198931694   Validation Accuracy: 0.5387999415397644\n",
      "Epoch 172, CIFAR-10 Batch 1:  Loss: 0.03216001018881798  Validation Accuracy: 0.5391998887062073\n",
      "Epoch 173, CIFAR-10 Batch 1:  Loss: 0.032095521688461304 Validation Accuracy: 0.5399999022483826\n",
      "Epoch 174, CIFAR-10 Batch 1:  Loss: 0.03206538408994675  Validation Accuracy: 0.5395999550819397\n",
      "Epoch 175, CIFAR-10 Batch 1:  Loss: 0.03198143094778061  Validation Accuracy: 0.5393999218940735\n",
      "Epoch 176, CIFAR-10 Batch 1:  Loss: 0.03199518471956253  Validation Accuracy: 0.5381999015808105\n",
      "Epoch 177, CIFAR-10 Batch 1:  Loss: 0.032037459313869476 Validation Accuracy: 0.5371999740600586\n",
      "Epoch 178, CIFAR-10 Batch 1:  Loss: 0.03195170313119888  Validation Accuracy: 0.5415999889373779\n",
      "Epoch 179, CIFAR-10 Batch 1:  Loss: 0.032017748802900314 Validation Accuracy: 0.5389999747276306\n",
      "Epoch 180, CIFAR-10 Batch 1:  Loss: 0.03183992952108383  Validation Accuracy: 0.5377999544143677\n",
      "Epoch 181, CIFAR-10 Batch 1:  Loss: 0.03202786296606064  Validation Accuracy: 0.5375999212265015\n",
      "Epoch 182, CIFAR-10 Batch 1:  Loss: 0.031840041279792786 Validation Accuracy: 0.5375999212265015\n",
      "Epoch 183, CIFAR-10 Batch 1:  Loss: 0.0319138765335083   Validation Accuracy: 0.5389999151229858\n",
      "Epoch 184, CIFAR-10 Batch 1:  Loss: 0.03184421360492706  Validation Accuracy: 0.5379999279975891\n",
      "Epoch 185, CIFAR-10 Batch 1:  Loss: 0.03183078393340111  Validation Accuracy: 0.5347999930381775\n",
      "Epoch 186, CIFAR-10 Batch 1:  Loss: 0.0319385901093483   Validation Accuracy: 0.5349999666213989\n",
      "Epoch 187, CIFAR-10 Batch 1:  Loss: 0.03185996413230896  Validation Accuracy: 0.535599946975708\n",
      "Epoch 188, CIFAR-10 Batch 1:  Loss: 0.031902290880680084 Validation Accuracy: 0.5361999273300171\n",
      "Epoch 189, CIFAR-10 Batch 1:  Loss: 0.0318877287209034   Validation Accuracy: 0.53739994764328\n",
      "Epoch 190, CIFAR-10 Batch 1:  Loss: 0.031793013215065    Validation Accuracy: 0.5341999530792236\n",
      "Epoch 191, CIFAR-10 Batch 1:  Loss: 0.031834926456213    Validation Accuracy: 0.5323999524116516\n",
      "Epoch 192, CIFAR-10 Batch 1:  Loss: 0.03187635540962219  Validation Accuracy: 0.5369999408721924\n",
      "Epoch 193, CIFAR-10 Batch 1:  Loss: 0.03188716992735863  Validation Accuracy: 0.5351999402046204\n",
      "Epoch 194, CIFAR-10 Batch 1:  Loss: 0.0317954383790493   Validation Accuracy: 0.5377999544143677\n",
      "Epoch 195, CIFAR-10 Batch 1:  Loss: 0.031941596418619156 Validation Accuracy: 0.5389999151229858\n",
      "Epoch 196, CIFAR-10 Batch 1:  Loss: 0.031778790056705475 Validation Accuracy: 0.5369999408721924\n",
      "Epoch 197, CIFAR-10 Batch 1:  Loss: 0.03186822310090065  Validation Accuracy: 0.5389999151229858\n",
      "Epoch 198, CIFAR-10 Batch 1:  Loss: 0.03174846991896629  Validation Accuracy: 0.5375999212265015\n",
      "Epoch 199, CIFAR-10 Batch 1:  Loss: 0.03177880123257637  Validation Accuracy: 0.5367999076843262\n",
      "Epoch 200, CIFAR-10 Batch 1:  Loss: 0.03174533694982529  Validation Accuracy: 0.5395999550819397\n",
      "Epoch 201, CIFAR-10 Batch 1:  Loss: 0.0317743644118309   Validation Accuracy: 0.538599967956543\n",
      "Epoch 202, CIFAR-10 Batch 1:  Loss: 0.03168926388025284  Validation Accuracy: 0.53739994764328\n",
      "Epoch 203, CIFAR-10 Batch 1:  Loss: 0.03176131471991539  Validation Accuracy: 0.5395999550819397\n",
      "Epoch 204, CIFAR-10 Batch 1:  Loss: 0.031726740300655365 Validation Accuracy: 0.5369999408721924\n",
      "Epoch 205, CIFAR-10 Batch 1:  Loss: 0.03179082274436951  Validation Accuracy: 0.5407999157905579\n",
      "Epoch 206, CIFAR-10 Batch 1:  Loss: 0.03166515380144119  Validation Accuracy: 0.538599967956543\n",
      "Epoch 207, CIFAR-10 Batch 1:  Loss: 0.031744442880153656 Validation Accuracy: 0.5401999354362488\n",
      "Epoch 208, CIFAR-10 Batch 1:  Loss: 0.03165065124630928  Validation Accuracy: 0.5395998954772949\n",
      "Epoch 209, CIFAR-10 Batch 1:  Loss: 0.03170555830001831  Validation Accuracy: 0.5379999279975891\n",
      "Epoch 210, CIFAR-10 Batch 1:  Loss: 0.03171668201684952  Validation Accuracy: 0.539199948310852\n",
      "Epoch 211, CIFAR-10 Batch 1:  Loss: 0.03162846341729164  Validation Accuracy: 0.5389999747276306\n",
      "Epoch 212, CIFAR-10 Batch 1:  Loss: 0.03169643133878708  Validation Accuracy: 0.5377999544143677\n",
      "Epoch 213, CIFAR-10 Batch 1:  Loss: 0.03162956237792969  Validation Accuracy: 0.5387999415397644\n",
      "Epoch 214, CIFAR-10 Batch 1:  Loss: 0.03166788071393967  Validation Accuracy: 0.538599967956543\n",
      "Epoch 215, CIFAR-10 Batch 1:  Loss: 0.031625233590602875 Validation Accuracy: 0.53739994764328\n",
      "Epoch 216, CIFAR-10 Batch 1:  Loss: 0.031757455319166183 Validation Accuracy: 0.5399999022483826\n",
      "Epoch 217, CIFAR-10 Batch 1:  Loss: 0.03163821995258331  Validation Accuracy: 0.5393999218940735\n",
      "Epoch 218, CIFAR-10 Batch 1:  Loss: 0.03166303038597107  Validation Accuracy: 0.540399968624115\n",
      "Epoch 219, CIFAR-10 Batch 1:  Loss: 0.0316644161939621   Validation Accuracy: 0.5361999273300171\n",
      "Epoch 220, CIFAR-10 Batch 1:  Loss: 0.031673457473516464 Validation Accuracy: 0.534600019454956\n",
      "Epoch 221, CIFAR-10 Batch 1:  Loss: 0.03164355084300041  Validation Accuracy: 0.5347999334335327\n",
      "Epoch 222, CIFAR-10 Batch 1:  Loss: 0.031708937138319016 Validation Accuracy: 0.5379999279975891\n",
      "Epoch 223, CIFAR-10 Batch 1:  Loss: 0.03167206794023514  Validation Accuracy: 0.5399999618530273\n",
      "Epoch 224, CIFAR-10 Batch 1:  Loss: 0.031621091067790985 Validation Accuracy: 0.5401999950408936\n",
      "Epoch 225, CIFAR-10 Batch 1:  Loss: 0.03172575682401657  Validation Accuracy: 0.5401999354362488\n",
      "Epoch 226, CIFAR-10 Batch 1:  Loss: 0.03166940435767174  Validation Accuracy: 0.535599946975708\n",
      "Epoch 227, CIFAR-10 Batch 1:  Loss: 0.03163467347621918  Validation Accuracy: 0.53739994764328\n",
      "Epoch 228, CIFAR-10 Batch 1:  Loss: 0.03170667216181755  Validation Accuracy: 0.5375999212265015\n",
      "Epoch 229, CIFAR-10 Batch 1:  Loss: 0.0316101536154747   Validation Accuracy: 0.5379999279975891\n",
      "Epoch 230, CIFAR-10 Batch 1:  Loss: 0.03160126134753227  Validation Accuracy: 0.5339999198913574\n",
      "Epoch 231, CIFAR-10 Batch 1:  Loss: 0.03161150589585304  Validation Accuracy: 0.5331999659538269\n",
      "Epoch 232, CIFAR-10 Batch 1:  Loss: 0.03170014172792435  Validation Accuracy: 0.5357999205589294\n",
      "Epoch 233, CIFAR-10 Batch 1:  Loss: 0.03154420107603073  Validation Accuracy: 0.5397999286651611\n",
      "Epoch 234, CIFAR-10 Batch 1:  Loss: 0.03167742118239403  Validation Accuracy: 0.5395999550819397\n",
      "Epoch 235, CIFAR-10 Batch 1:  Loss: 0.03163143992424011  Validation Accuracy: 0.5369999408721924\n",
      "Epoch 236, CIFAR-10 Batch 1:  Loss: 0.031563714146614075 Validation Accuracy: 0.535599946975708\n",
      "Epoch 237, CIFAR-10 Batch 1:  Loss: 0.03158799558877945  Validation Accuracy: 0.5389999747276306\n",
      "Epoch 238, CIFAR-10 Batch 1:  Loss: 0.03159375116229057  Validation Accuracy: 0.5347999334335327\n",
      "Epoch 239, CIFAR-10 Batch 1:  Loss: 0.0315682627260685   Validation Accuracy: 0.5385999083518982\n",
      "Epoch 240, CIFAR-10 Batch 1:  Loss: 0.031563691794872284 Validation Accuracy: 0.5363999009132385\n",
      "Epoch 241, CIFAR-10 Batch 1:  Loss: 0.031551115214824677 Validation Accuracy: 0.5369999408721924\n",
      "Epoch 242, CIFAR-10 Batch 1:  Loss: 0.03161114454269409  Validation Accuracy: 0.5397999286651611\n",
      "Epoch 243, CIFAR-10 Batch 1:  Loss: 0.03156055510044098  Validation Accuracy: 0.5395999550819397\n",
      "Epoch 244, CIFAR-10 Batch 1:  Loss: 0.03154642879962921  Validation Accuracy: 0.5397998690605164\n",
      "Epoch 245, CIFAR-10 Batch 1:  Loss: 0.0315563902258873   Validation Accuracy: 0.5397999286651611\n",
      "Epoch 246, CIFAR-10 Batch 1:  Loss: 0.03154817968606949  Validation Accuracy: 0.5417999625205994\n",
      "Epoch 247, CIFAR-10 Batch 1:  Loss: 0.03152931109070778  Validation Accuracy: 0.5401999354362488\n",
      "Epoch 248, CIFAR-10 Batch 1:  Loss: 0.03156602382659912  Validation Accuracy: 0.5389999151229858\n",
      "Epoch 249, CIFAR-10 Batch 1:  Loss: 0.031527504324913025 Validation Accuracy: 0.5389999747276306\n",
      "Epoch 250, CIFAR-10 Batch 1:  Loss: 0.031554002314805984 Validation Accuracy: 0.5405998826026917\n",
      "Epoch 251, CIFAR-10 Batch 1:  Loss: 0.03149610012769699  Validation Accuracy: 0.5387999415397644\n",
      "Epoch 252, CIFAR-10 Batch 1:  Loss: 0.031571730971336365 Validation Accuracy: 0.5405998826026917\n",
      "Epoch 253, CIFAR-10 Batch 1:  Loss: 0.031528107821941376 Validation Accuracy: 0.5407999753952026\n",
      "Epoch 254, CIFAR-10 Batch 1:  Loss: 0.031539153307676315 Validation Accuracy: 0.5423998832702637\n",
      "Epoch 255, CIFAR-10 Batch 1:  Loss: 0.03153403475880623  Validation Accuracy: 0.5383999347686768\n",
      "Epoch 256, CIFAR-10 Batch 1:  Loss: 0.03154170885682106  Validation Accuracy: 0.5423998832702637\n",
      "Epoch 257, CIFAR-10 Batch 1:  Loss: 0.03150435537099838  Validation Accuracy: 0.5395998954772949\n",
      "Epoch 258, CIFAR-10 Batch 1:  Loss: 0.03166505694389343  Validation Accuracy: 0.5421999096870422\n",
      "Epoch 259, CIFAR-10 Batch 1:  Loss: 0.03151601180434227  Validation Accuracy: 0.5403999090194702\n",
      "Epoch 260, CIFAR-10 Batch 1:  Loss: 0.03150283917784691  Validation Accuracy: 0.5389999151229858\n",
      "Epoch 261, CIFAR-10 Batch 1:  Loss: 0.031502578407526016 Validation Accuracy: 0.539199948310852\n",
      "Epoch 262, CIFAR-10 Batch 1:  Loss: 0.03149724379181862  Validation Accuracy: 0.5397998690605164\n",
      "Epoch 263, CIFAR-10 Batch 1:  Loss: 0.03152061998844147  Validation Accuracy: 0.5429999232292175\n",
      "Epoch 264, CIFAR-10 Batch 1:  Loss: 0.031540676951408386 Validation Accuracy: 0.542199969291687\n",
      "Epoch 265, CIFAR-10 Batch 1:  Loss: 0.031491007655858994 Validation Accuracy: 0.5379999279975891\n",
      "Epoch 266, CIFAR-10 Batch 1:  Loss: 0.031532347202301025 Validation Accuracy: 0.5415999293327332\n",
      "Epoch 267, CIFAR-10 Batch 1:  Loss: 0.0314788892865181   Validation Accuracy: 0.540399968624115\n",
      "Epoch 268, CIFAR-10 Batch 1:  Loss: 0.03147554770112038  Validation Accuracy: 0.5407999753952026\n",
      "Epoch 269, CIFAR-10 Batch 1:  Loss: 0.0314955934882164   Validation Accuracy: 0.5437999367713928\n",
      "Epoch 270, CIFAR-10 Batch 1:  Loss: 0.03146729618310928  Validation Accuracy: 0.5395998954772949\n",
      "Epoch 271, CIFAR-10 Batch 1:  Loss: 0.03146905452013016  Validation Accuracy: 0.5401999950408936\n",
      "Epoch 272, CIFAR-10 Batch 1:  Loss: 0.031479962170124054 Validation Accuracy: 0.5375999212265015\n",
      "Epoch 273, CIFAR-10 Batch 1:  Loss: 0.03153076022863388  Validation Accuracy: 0.5417999625205994\n",
      "Epoch 274, CIFAR-10 Batch 1:  Loss: 0.03153672069311142  Validation Accuracy: 0.5419999361038208\n",
      "Epoch 275, CIFAR-10 Batch 1:  Loss: 0.03149111196398735  Validation Accuracy: 0.5389999151229858\n",
      "Epoch 276, CIFAR-10 Batch 1:  Loss: 0.03155657649040222  Validation Accuracy: 0.5427999496459961\n",
      "Epoch 277, CIFAR-10 Batch 1:  Loss: 0.031541742384433746 Validation Accuracy: 0.5419999361038208\n",
      "Epoch 278, CIFAR-10 Batch 1:  Loss: 0.03154420480132103  Validation Accuracy: 0.5411999225616455\n",
      "Epoch 279, CIFAR-10 Batch 1:  Loss: 0.031549327075481415 Validation Accuracy: 0.5395999550819397\n",
      "Epoch 280, CIFAR-10 Batch 1:  Loss: 0.031509317457675934 Validation Accuracy: 0.538599967956543\n",
      "Epoch 281, CIFAR-10 Batch 1:  Loss: 0.03158176317811012  Validation Accuracy: 0.53739994764328\n",
      "Epoch 282, CIFAR-10 Batch 1:  Loss: 0.031567879021167755 Validation Accuracy: 0.5357999205589294\n",
      "Epoch 283, CIFAR-10 Batch 1:  Loss: 0.03158145397901535  Validation Accuracy: 0.5321999788284302\n",
      "Epoch 284, CIFAR-10 Batch 1:  Loss: 0.03169817849993706  Validation Accuracy: 0.5413999557495117\n",
      "Epoch 285, CIFAR-10 Batch 1:  Loss: 0.03159612417221069  Validation Accuracy: 0.5357999205589294\n",
      "Epoch 286, CIFAR-10 Batch 1:  Loss: 0.03170100972056389  Validation Accuracy: 0.535599946975708\n",
      "Epoch 287, CIFAR-10 Batch 1:  Loss: 0.031768202781677246 Validation Accuracy: 0.5341999530792236\n",
      "Epoch 288, CIFAR-10 Batch 1:  Loss: 0.031637389212846756 Validation Accuracy: 0.5379999279975891\n",
      "Epoch 289, CIFAR-10 Batch 1:  Loss: 0.031646937131881714 Validation Accuracy: 0.5399999618530273\n",
      "Epoch 290, CIFAR-10 Batch 1:  Loss: 0.03176336735486984  Validation Accuracy: 0.5395999550819397\n",
      "Epoch 291, CIFAR-10 Batch 1:  Loss: 0.03201122209429741  Validation Accuracy: 0.5375999212265015\n",
      "Epoch 292, CIFAR-10 Batch 1:  Loss: 0.03211377561092377  Validation Accuracy: 0.5397999286651611\n",
      "Epoch 293, CIFAR-10 Batch 1:  Loss: 0.031878069043159485 Validation Accuracy: 0.5409998893737793\n",
      "Epoch 294, CIFAR-10 Batch 1:  Loss: 0.03179854527115822  Validation Accuracy: 0.5443999767303467\n",
      "Epoch 295, CIFAR-10 Batch 1:  Loss: 0.03163909167051315  Validation Accuracy: 0.538599967956543\n",
      "Epoch 296, CIFAR-10 Batch 1:  Loss: 0.03165670856833458  Validation Accuracy: 0.5397999286651611\n",
      "Epoch 297, CIFAR-10 Batch 1:  Loss: 0.03265497460961342  Validation Accuracy: 0.535599946975708\n",
      "Epoch 298, CIFAR-10 Batch 1:  Loss: 0.03252808377146721  Validation Accuracy: 0.539199948310852\n",
      "Epoch 299, CIFAR-10 Batch 1:  Loss: 0.032823920249938965 Validation Accuracy: 0.5349999666213989\n",
      "Epoch 300, CIFAR-10 Batch 1:  Loss: 0.032770827412605286 Validation Accuracy: 0.5353999137878418\n",
      "Epoch 301, CIFAR-10 Batch 1:  Loss: 0.033550925552845    Validation Accuracy: 0.5335999727249146\n",
      "Epoch 302, CIFAR-10 Batch 1:  Loss: 0.03279471397399902  Validation Accuracy: 0.5329998731613159\n",
      "Epoch 303, CIFAR-10 Batch 1:  Loss: 0.03255997598171234  Validation Accuracy: 0.5365999341011047\n",
      "Epoch 304, CIFAR-10 Batch 1:  Loss: 0.03302330896258354  Validation Accuracy: 0.5247999429702759\n",
      "Epoch 305, CIFAR-10 Batch 1:  Loss: 0.034227848052978516 Validation Accuracy: 0.5363999605178833\n",
      "Epoch 306, CIFAR-10 Batch 1:  Loss: 0.03986627608537674  Validation Accuracy: 0.5311999320983887\n",
      "Epoch 307, CIFAR-10 Batch 1:  Loss: 0.03929247334599495  Validation Accuracy: 0.5193999409675598\n",
      "Epoch 308, CIFAR-10 Batch 1:  Loss: 0.03468305617570877  Validation Accuracy: 0.5281999111175537\n",
      "Epoch 309, CIFAR-10 Batch 1:  Loss: 0.033941470086574554 Validation Accuracy: 0.5219999551773071\n",
      "Epoch 310, CIFAR-10 Batch 1:  Loss: 0.03347975015640259  Validation Accuracy: 0.5249999761581421\n",
      "Epoch 311, CIFAR-10 Batch 1:  Loss: 0.033567726612091064 Validation Accuracy: 0.5297999382019043\n",
      "Epoch 312, CIFAR-10 Batch 1:  Loss: 0.03313317894935608  Validation Accuracy: 0.527999997138977\n",
      "Epoch 313, CIFAR-10 Batch 1:  Loss: 0.033826373517513275 Validation Accuracy: 0.5189999341964722\n",
      "Epoch 314, CIFAR-10 Batch 1:  Loss: 0.033283889293670654 Validation Accuracy: 0.533799946308136\n",
      "Epoch 315, CIFAR-10 Batch 1:  Loss: 0.03259875625371933  Validation Accuracy: 0.5323999524116516\n",
      "Epoch 316, CIFAR-10 Batch 1:  Loss: 0.03254813328385353  Validation Accuracy: 0.5361999273300171\n",
      "Epoch 317, CIFAR-10 Batch 1:  Loss: 0.032420262694358826 Validation Accuracy: 0.5285999178886414\n",
      "Epoch 318, CIFAR-10 Batch 1:  Loss: 0.03225133568048477  Validation Accuracy: 0.5359998941421509\n",
      "Epoch 319, CIFAR-10 Batch 1:  Loss: 0.03190026432275772  Validation Accuracy: 0.5351999402046204\n",
      "Epoch 320, CIFAR-10 Batch 1:  Loss: 0.03176049515604973  Validation Accuracy: 0.5371999144554138\n",
      "Epoch 321, CIFAR-10 Batch 1:  Loss: 0.03176292032003403  Validation Accuracy: 0.5347999334335327\n",
      "Epoch 322, CIFAR-10 Batch 1:  Loss: 0.0316472202539444   Validation Accuracy: 0.5373998880386353\n",
      "Epoch 323, CIFAR-10 Batch 1:  Loss: 0.0316346175968647   Validation Accuracy: 0.5331999659538269\n",
      "Epoch 324, CIFAR-10 Batch 1:  Loss: 0.03203132376074791  Validation Accuracy: 0.5379999876022339\n",
      "Epoch 325, CIFAR-10 Batch 1:  Loss: 0.03168215602636337  Validation Accuracy: 0.5345999598503113\n",
      "Epoch 326, CIFAR-10 Batch 1:  Loss: 0.031674984842538834 Validation Accuracy: 0.5353999137878418\n",
      "Epoch 327, CIFAR-10 Batch 1:  Loss: 0.0316411629319191   Validation Accuracy: 0.5335999727249146\n",
      "Epoch 328, CIFAR-10 Batch 1:  Loss: 0.0318581685423851   Validation Accuracy: 0.5341999530792236\n",
      "Epoch 329, CIFAR-10 Batch 1:  Loss: 0.03185366839170456  Validation Accuracy: 0.539199948310852\n",
      "Epoch 330, CIFAR-10 Batch 1:  Loss: 0.03158273547887802  Validation Accuracy: 0.5357999801635742\n",
      "Epoch 331, CIFAR-10 Batch 1:  Loss: 0.031617045402526855 Validation Accuracy: 0.5353999733924866\n",
      "Epoch 332, CIFAR-10 Batch 1:  Loss: 0.03153826296329498  Validation Accuracy: 0.5413999557495117\n",
      "Epoch 333, CIFAR-10 Batch 1:  Loss: 0.03151259198784828  Validation Accuracy: 0.5413998961448669\n",
      "Epoch 334, CIFAR-10 Batch 1:  Loss: 0.03151247650384903  Validation Accuracy: 0.5417999625205994\n",
      "Epoch 335, CIFAR-10 Batch 1:  Loss: 0.03157595545053482  Validation Accuracy: 0.5361999273300171\n",
      "Epoch 336, CIFAR-10 Batch 1:  Loss: 0.03166116029024124  Validation Accuracy: 0.5341999530792236\n",
      "Epoch 337, CIFAR-10 Batch 1:  Loss: 0.03188161924481392  Validation Accuracy: 0.5313999652862549\n",
      "Epoch 338, CIFAR-10 Batch 1:  Loss: 0.031696632504463196 Validation Accuracy: 0.5335999727249146\n",
      "Epoch 339, CIFAR-10 Batch 1:  Loss: 0.03170708194375038  Validation Accuracy: 0.5323998928070068\n",
      "Epoch 340, CIFAR-10 Batch 1:  Loss: 0.03191536292433739  Validation Accuracy: 0.531999945640564\n",
      "Epoch 341, CIFAR-10 Batch 1:  Loss: 0.03165852651000023  Validation Accuracy: 0.5319998860359192\n",
      "Epoch 342, CIFAR-10 Batch 1:  Loss: 0.032919302582740784 Validation Accuracy: 0.5229999423027039\n",
      "Epoch 343, CIFAR-10 Batch 1:  Loss: 0.03317222744226456  Validation Accuracy: 0.5349999070167542\n",
      "Epoch 344, CIFAR-10 Batch 1:  Loss: 0.03285551071166992  Validation Accuracy: 0.528999924659729\n",
      "Epoch 345, CIFAR-10 Batch 1:  Loss: 0.03405855596065521  Validation Accuracy: 0.5175999402999878\n",
      "Epoch 346, CIFAR-10 Batch 1:  Loss: 0.03414003551006317  Validation Accuracy: 0.5281999707221985\n",
      "Epoch 347, CIFAR-10 Batch 1:  Loss: 0.03695528954267502  Validation Accuracy: 0.5315999388694763\n",
      "Epoch 348, CIFAR-10 Batch 1:  Loss: 0.03375367820262909  Validation Accuracy: 0.5301998853683472\n",
      "Epoch 349, CIFAR-10 Batch 1:  Loss: 0.033830441534519196 Validation Accuracy: 0.5301999449729919\n",
      "Epoch 350, CIFAR-10 Batch 1:  Loss: 0.036470040678977966 Validation Accuracy: 0.5225999355316162\n",
      "Epoch 351, CIFAR-10 Batch 1:  Loss: 0.03384904935956001  Validation Accuracy: 0.5307999849319458\n",
      "Epoch 352, CIFAR-10 Batch 1:  Loss: 0.035573795437812805 Validation Accuracy: 0.5277999639511108\n",
      "Epoch 353, CIFAR-10 Batch 1:  Loss: 0.03667251020669937  Validation Accuracy: 0.5301999449729919\n",
      "Epoch 354, CIFAR-10 Batch 1:  Loss: 0.033721499145030975 Validation Accuracy: 0.5275999307632446\n",
      "Epoch 355, CIFAR-10 Batch 1:  Loss: 0.03690265491604805  Validation Accuracy: 0.5163999795913696\n",
      "Epoch 356, CIFAR-10 Batch 1:  Loss: 0.0343669131398201   Validation Accuracy: 0.5245999097824097\n",
      "Epoch 357, CIFAR-10 Batch 1:  Loss: 0.03713007643818855  Validation Accuracy: 0.521399974822998\n",
      "Epoch 358, CIFAR-10 Batch 1:  Loss: 0.035236041992902756 Validation Accuracy: 0.521399974822998\n",
      "Epoch 359, CIFAR-10 Batch 1:  Loss: 0.03813663125038147  Validation Accuracy: 0.5219999551773071\n",
      "Epoch 360, CIFAR-10 Batch 1:  Loss: 0.03849128633737564  Validation Accuracy: 0.5203999876976013\n",
      "Epoch 361, CIFAR-10 Batch 1:  Loss: 0.06706582009792328  Validation Accuracy: 0.5135999917984009\n",
      "Epoch 362, CIFAR-10 Batch 1:  Loss: 0.03808716684579849  Validation Accuracy: 0.5281999707221985\n",
      "Epoch 363, CIFAR-10 Batch 1:  Loss: 0.0380263477563858   Validation Accuracy: 0.5285999774932861\n",
      "Epoch 364, CIFAR-10 Batch 1:  Loss: 0.03411842882633209  Validation Accuracy: 0.5235999822616577\n",
      "Epoch 365, CIFAR-10 Batch 1:  Loss: 0.034206099808216095 Validation Accuracy: 0.5285999178886414\n",
      "Epoch 366, CIFAR-10 Batch 1:  Loss: 0.03542093560099602  Validation Accuracy: 0.5293998718261719\n",
      "Epoch 367, CIFAR-10 Batch 1:  Loss: 0.03576994687318802  Validation Accuracy: 0.5323999524116516\n",
      "Epoch 368, CIFAR-10 Batch 1:  Loss: 0.03291543200612068  Validation Accuracy: 0.5271999835968018\n",
      "Epoch 369, CIFAR-10 Batch 1:  Loss: 0.03265216574072838  Validation Accuracy: 0.5279999375343323\n",
      "Epoch 370, CIFAR-10 Batch 1:  Loss: 0.032360877841711044 Validation Accuracy: 0.5353999137878418\n",
      "Epoch 371, CIFAR-10 Batch 1:  Loss: 0.03208112716674805  Validation Accuracy: 0.5353999733924866\n",
      "Epoch 372, CIFAR-10 Batch 1:  Loss: 0.032638899981975555 Validation Accuracy: 0.5291999578475952\n",
      "Epoch 373, CIFAR-10 Batch 1:  Loss: 0.0327567532658577   Validation Accuracy: 0.5257999300956726\n",
      "Epoch 374, CIFAR-10 Batch 1:  Loss: 0.03201218694448471  Validation Accuracy: 0.5309999585151672\n",
      "Epoch 375, CIFAR-10 Batch 1:  Loss: 0.03201989084482193  Validation Accuracy: 0.5331999063491821\n",
      "Epoch 376, CIFAR-10 Batch 1:  Loss: 0.03196462243795395  Validation Accuracy: 0.5341999530792236\n",
      "Epoch 377, CIFAR-10 Batch 1:  Loss: 0.031621623784303665 Validation Accuracy: 0.5357999801635742\n",
      "Epoch 378, CIFAR-10 Batch 1:  Loss: 0.03152505308389664  Validation Accuracy: 0.5377999544143677\n",
      "Epoch 379, CIFAR-10 Batch 1:  Loss: 0.03152330964803696  Validation Accuracy: 0.5333998799324036\n",
      "Epoch 380, CIFAR-10 Batch 1:  Loss: 0.031464897096157074 Validation Accuracy: 0.5359999537467957\n",
      "Epoch 381, CIFAR-10 Batch 1:  Loss: 0.031493641436100006 Validation Accuracy: 0.5359998941421509\n",
      "Epoch 382, CIFAR-10 Batch 1:  Loss: 0.03156986087560654  Validation Accuracy: 0.5377999544143677\n",
      "Epoch 383, CIFAR-10 Batch 1:  Loss: 0.031527310609817505 Validation Accuracy: 0.5371999740600586\n",
      "Epoch 384, CIFAR-10 Batch 1:  Loss: 0.031447578221559525 Validation Accuracy: 0.540399968624115\n",
      "Epoch 385, CIFAR-10 Batch 1:  Loss: 0.03146935626864433  Validation Accuracy: 0.5385999083518982\n",
      "Epoch 386, CIFAR-10 Batch 1:  Loss: 0.031422052532434464 Validation Accuracy: 0.5381999015808105\n",
      "Epoch 387, CIFAR-10 Batch 1:  Loss: 0.03142527490854263  Validation Accuracy: 0.5377999544143677\n",
      "Epoch 388, CIFAR-10 Batch 1:  Loss: 0.031427524983882904 Validation Accuracy: 0.536799967288971\n",
      "Epoch 389, CIFAR-10 Batch 1:  Loss: 0.0314166285097599   Validation Accuracy: 0.5383999347686768\n",
      "Epoch 390, CIFAR-10 Batch 1:  Loss: 0.031405653804540634 Validation Accuracy: 0.5369999408721924\n",
      "Epoch 391, CIFAR-10 Batch 1:  Loss: 0.03153093531727791  Validation Accuracy: 0.5373998880386353\n",
      "Epoch 392, CIFAR-10 Batch 1:  Loss: 0.03151605278253555  Validation Accuracy: 0.5389999747276306\n",
      "Epoch 393, CIFAR-10 Batch 1:  Loss: 0.03142871707677841  Validation Accuracy: 0.5415999889373779\n",
      "Epoch 394, CIFAR-10 Batch 1:  Loss: 0.031475890427827835 Validation Accuracy: 0.5379999876022339\n",
      "Epoch 395, CIFAR-10 Batch 1:  Loss: 0.03144948184490204  Validation Accuracy: 0.5453999042510986\n",
      "Epoch 396, CIFAR-10 Batch 1:  Loss: 0.03145372122526169  Validation Accuracy: 0.5429999828338623\n",
      "Epoch 397, CIFAR-10 Batch 1:  Loss: 0.031455762684345245 Validation Accuracy: 0.5425999164581299\n",
      "Epoch 398, CIFAR-10 Batch 1:  Loss: 0.03143330663442612  Validation Accuracy: 0.5427999496459961\n",
      "Epoch 399, CIFAR-10 Batch 1:  Loss: 0.03140440210700035  Validation Accuracy: 0.5425999164581299\n",
      "Epoch 400, CIFAR-10 Batch 1:  Loss: 0.03141557052731514  Validation Accuracy: 0.5403999090194702\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "print('Checking the Training on a Single Batch...')\n",
    "with tf.Session() as sess:\n",
    "    # Initializing the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Training cycle\n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        batch_i = 1\n",
    "        for batch_features, batch_labels in helper.load_preprocess_training_batch(batch_i, batch_size):\n",
    "            train_neural_network(sess, optimizer, keep_probability, batch_features, batch_labels)\n",
    "        print('Epoch {:>2}, CIFAR-10 Batch {}:  '.format(epoch + 1, batch_i), end='')\n",
    "        print_stats(sess, batch_features, batch_labels, cost, accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Fully Train the Model\n",
    "Now that you got a good accuracy with a single CIFAR-10 batch, try it with all five batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Epoch  1, CIFAR-10 Batch 1:  Loss: 2.297081470489502    Validation Accuracy: 0.12779998779296875\n",
      "Epoch  1, CIFAR-10 Batch 2:  Loss: 2.247490882873535    Validation Accuracy: 0.18719998002052307\n",
      "Epoch  1, CIFAR-10 Batch 3:  Loss: 2.249315023422241    Validation Accuracy: 0.1746000051498413\n",
      "Epoch  1, CIFAR-10 Batch 4:  Loss: 2.2287259101867676   Validation Accuracy: 0.21699997782707214\n",
      "Epoch  1, CIFAR-10 Batch 5:  Loss: 2.1917643547058105   Validation Accuracy: 0.1972000002861023\n",
      "Epoch  2, CIFAR-10 Batch 1:  Loss: 2.1745707988739014   Validation Accuracy: 0.21899999678134918\n",
      "Epoch  2, CIFAR-10 Batch 2:  Loss: 2.184399366378784    Validation Accuracy: 0.2465999871492386\n",
      "Epoch  2, CIFAR-10 Batch 3:  Loss: 2.1631178855895996   Validation Accuracy: 0.25\n",
      "Epoch  2, CIFAR-10 Batch 4:  Loss: 2.186377763748169    Validation Accuracy: 0.26179999113082886\n",
      "Epoch  2, CIFAR-10 Batch 5:  Loss: 2.0887491703033447   Validation Accuracy: 0.26979997754096985\n",
      "Epoch  3, CIFAR-10 Batch 1:  Loss: 2.073012351989746    Validation Accuracy: 0.2709999978542328\n",
      "Epoch  3, CIFAR-10 Batch 2:  Loss: 2.0910446643829346   Validation Accuracy: 0.2888000011444092\n",
      "Epoch  3, CIFAR-10 Batch 3:  Loss: 2.101137161254883    Validation Accuracy: 0.2946000099182129\n",
      "Epoch  3, CIFAR-10 Batch 4:  Loss: 2.0952446460723877   Validation Accuracy: 0.30660000443458557\n",
      "Epoch  3, CIFAR-10 Batch 5:  Loss: 2.0109314918518066   Validation Accuracy: 0.3001999855041504\n",
      "Epoch  4, CIFAR-10 Batch 1:  Loss: 2.010218381881714    Validation Accuracy: 0.29819998145103455\n",
      "Epoch  4, CIFAR-10 Batch 2:  Loss: 2.041743278503418    Validation Accuracy: 0.31040000915527344\n",
      "Epoch  4, CIFAR-10 Batch 3:  Loss: 2.057950496673584    Validation Accuracy: 0.3187999725341797\n",
      "Epoch  4, CIFAR-10 Batch 4:  Loss: 2.0373806953430176   Validation Accuracy: 0.32359999418258667\n",
      "Epoch  4, CIFAR-10 Batch 5:  Loss: 1.96284818649292     Validation Accuracy: 0.32419997453689575\n",
      "Epoch  5, CIFAR-10 Batch 1:  Loss: 1.9642904996871948   Validation Accuracy: 0.31700000166893005\n",
      "Epoch  5, CIFAR-10 Batch 2:  Loss: 2.0023727416992188   Validation Accuracy: 0.319599986076355\n",
      "Epoch  5, CIFAR-10 Batch 3:  Loss: 2.003817558288574    Validation Accuracy: 0.33740001916885376\n",
      "Epoch  5, CIFAR-10 Batch 4:  Loss: 1.9170297384262085   Validation Accuracy: 0.3473999500274658\n",
      "Epoch  5, CIFAR-10 Batch 5:  Loss: 1.83376145362854     Validation Accuracy: 0.3985999822616577\n",
      "Epoch  6, CIFAR-10 Batch 1:  Loss: 1.810931921005249    Validation Accuracy: 0.3863999545574188\n",
      "Epoch  6, CIFAR-10 Batch 2:  Loss: 1.8843425512313843   Validation Accuracy: 0.3946000039577484\n",
      "Epoch  6, CIFAR-10 Batch 3:  Loss: 1.7471295595169067   Validation Accuracy: 0.43219998478889465\n",
      "Epoch  6, CIFAR-10 Batch 4:  Loss: 1.7366814613342285   Validation Accuracy: 0.44999995827674866\n",
      "Epoch  6, CIFAR-10 Batch 5:  Loss: 1.7205947637557983   Validation Accuracy: 0.43299996852874756\n",
      "Epoch  7, CIFAR-10 Batch 1:  Loss: 1.6986562013626099   Validation Accuracy: 0.437999963760376\n",
      "Epoch  7, CIFAR-10 Batch 2:  Loss: 1.7285022735595703   Validation Accuracy: 0.4479999542236328\n",
      "Epoch  7, CIFAR-10 Batch 3:  Loss: 1.6552143096923828   Validation Accuracy: 0.44359999895095825\n",
      "Epoch  7, CIFAR-10 Batch 4:  Loss: 1.664461612701416    Validation Accuracy: 0.45719999074935913\n",
      "Epoch  7, CIFAR-10 Batch 5:  Loss: 1.6296600103378296   Validation Accuracy: 0.46059995889663696\n",
      "Epoch  8, CIFAR-10 Batch 1:  Loss: 1.6275110244750977   Validation Accuracy: 0.4697999954223633\n",
      "Epoch  8, CIFAR-10 Batch 2:  Loss: 1.6718720197677612   Validation Accuracy: 0.46459996700286865\n",
      "Epoch  8, CIFAR-10 Batch 3:  Loss: 1.6153019666671753   Validation Accuracy: 0.4553999602794647\n",
      "Epoch  8, CIFAR-10 Batch 4:  Loss: 1.596490740776062    Validation Accuracy: 0.48240000009536743\n",
      "Epoch  8, CIFAR-10 Batch 5:  Loss: 1.5763471126556396   Validation Accuracy: 0.46759992837905884\n",
      "Epoch  9, CIFAR-10 Batch 1:  Loss: 1.5903218984603882   Validation Accuracy: 0.48240000009536743\n",
      "Epoch  9, CIFAR-10 Batch 2:  Loss: 1.6175227165222168   Validation Accuracy: 0.48099997639656067\n",
      "Epoch  9, CIFAR-10 Batch 3:  Loss: 1.5780398845672607   Validation Accuracy: 0.4687999188899994\n",
      "Epoch  9, CIFAR-10 Batch 4:  Loss: 1.5850436687469482   Validation Accuracy: 0.4833999276161194\n",
      "Epoch  9, CIFAR-10 Batch 5:  Loss: 1.5528291463851929   Validation Accuracy: 0.4819999635219574\n",
      "Epoch 10, CIFAR-10 Batch 1:  Loss: 1.5463905334472656   Validation Accuracy: 0.4873999357223511\n",
      "Epoch 10, CIFAR-10 Batch 2:  Loss: 1.5808980464935303   Validation Accuracy: 0.49139994382858276\n",
      "Epoch 10, CIFAR-10 Batch 3:  Loss: 1.5147030353546143   Validation Accuracy: 0.48899996280670166\n",
      "Epoch 10, CIFAR-10 Batch 4:  Loss: 1.5307891368865967   Validation Accuracy: 0.5039999485015869\n",
      "Epoch 10, CIFAR-10 Batch 5:  Loss: 1.4921376705169678   Validation Accuracy: 0.49859994649887085\n",
      "Epoch 11, CIFAR-10 Batch 1:  Loss: 1.5068628787994385   Validation Accuracy: 0.5021999478340149\n",
      "Epoch 11, CIFAR-10 Batch 2:  Loss: 1.5418332815170288   Validation Accuracy: 0.5\n",
      "Epoch 11, CIFAR-10 Batch 3:  Loss: 1.4878227710723877   Validation Accuracy: 0.4903999865055084\n",
      "Epoch 11, CIFAR-10 Batch 4:  Loss: 1.5020794868469238   Validation Accuracy: 0.502799928188324\n",
      "Epoch 11, CIFAR-10 Batch 5:  Loss: 1.460038423538208    Validation Accuracy: 0.5019999146461487\n",
      "Epoch 12, CIFAR-10 Batch 1:  Loss: 1.4781436920166016   Validation Accuracy: 0.5071999430656433\n",
      "Epoch 12, CIFAR-10 Batch 2:  Loss: 1.4991464614868164   Validation Accuracy: 0.5113999843597412\n",
      "Epoch 12, CIFAR-10 Batch 3:  Loss: 1.4496889114379883   Validation Accuracy: 0.5035999417304993\n",
      "Epoch 12, CIFAR-10 Batch 4:  Loss: 1.4747669696807861   Validation Accuracy: 0.5019999146461487\n",
      "Epoch 12, CIFAR-10 Batch 5:  Loss: 1.4259778261184692   Validation Accuracy: 0.5095999836921692\n",
      "Epoch 13, CIFAR-10 Batch 1:  Loss: 1.442979335784912    Validation Accuracy: 0.5097999572753906\n",
      "Epoch 13, CIFAR-10 Batch 2:  Loss: 1.5266273021697998   Validation Accuracy: 0.4957999587059021\n",
      "Epoch 13, CIFAR-10 Batch 3:  Loss: 1.4163193702697754   Validation Accuracy: 0.5171999335289001\n",
      "Epoch 13, CIFAR-10 Batch 4:  Loss: 1.4424017667770386   Validation Accuracy: 0.5065999031066895\n",
      "Epoch 13, CIFAR-10 Batch 5:  Loss: 1.4127552509307861   Validation Accuracy: 0.514799952507019\n",
      "Epoch 14, CIFAR-10 Batch 1:  Loss: 1.4159557819366455   Validation Accuracy: 0.5215999484062195\n",
      "Epoch 14, CIFAR-10 Batch 2:  Loss: 1.462930679321289    Validation Accuracy: 0.5103999376296997\n",
      "Epoch 14, CIFAR-10 Batch 3:  Loss: 1.380846619606018    Validation Accuracy: 0.5205999612808228\n",
      "Epoch 14, CIFAR-10 Batch 4:  Loss: 1.4036533832550049   Validation Accuracy: 0.5230000019073486\n",
      "Epoch 14, CIFAR-10 Batch 5:  Loss: 1.3942698240280151   Validation Accuracy: 0.5237999558448792\n",
      "Epoch 15, CIFAR-10 Batch 1:  Loss: 1.389764428138733    Validation Accuracy: 0.5235999226570129\n",
      "Epoch 15, CIFAR-10 Batch 2:  Loss: 1.417406678199768    Validation Accuracy: 0.5211999416351318\n",
      "Epoch 15, CIFAR-10 Batch 3:  Loss: 1.3507511615753174   Validation Accuracy: 0.5194000005722046\n",
      "Epoch 15, CIFAR-10 Batch 4:  Loss: 1.4049303531646729   Validation Accuracy: 0.5265999436378479\n",
      "Epoch 15, CIFAR-10 Batch 5:  Loss: 1.376747488975525    Validation Accuracy: 0.5157999396324158\n",
      "Epoch 16, CIFAR-10 Batch 1:  Loss: 1.3660619258880615   Validation Accuracy: 0.5287999510765076\n",
      "Epoch 16, CIFAR-10 Batch 2:  Loss: 1.4069254398345947   Validation Accuracy: 0.5215999484062195\n",
      "Epoch 16, CIFAR-10 Batch 3:  Loss: 1.3877094984054565   Validation Accuracy: 0.4987999498844147\n",
      "Epoch 16, CIFAR-10 Batch 4:  Loss: 1.4243171215057373   Validation Accuracy: 0.5037999749183655\n",
      "Epoch 16, CIFAR-10 Batch 5:  Loss: 1.3258740901947021   Validation Accuracy: 0.5289999842643738\n",
      "Epoch 17, CIFAR-10 Batch 1:  Loss: 1.3501501083374023   Validation Accuracy: 0.5261999368667603\n",
      "Epoch 17, CIFAR-10 Batch 2:  Loss: 1.406132698059082    Validation Accuracy: 0.5203999876976013\n",
      "Epoch 17, CIFAR-10 Batch 3:  Loss: 1.343835711479187    Validation Accuracy: 0.5145999789237976\n",
      "Epoch 17, CIFAR-10 Batch 4:  Loss: 1.346458911895752    Validation Accuracy: 0.5243999361991882\n",
      "Epoch 17, CIFAR-10 Batch 5:  Loss: 1.3219388723373413   Validation Accuracy: 0.5247999429702759\n",
      "Epoch 18, CIFAR-10 Batch 1:  Loss: 1.3225476741790771   Validation Accuracy: 0.532599925994873\n",
      "Epoch 18, CIFAR-10 Batch 2:  Loss: 1.3602780103683472   Validation Accuracy: 0.539199948310852\n",
      "Epoch 18, CIFAR-10 Batch 3:  Loss: 1.2809628248214722   Validation Accuracy: 0.5309999585151672\n",
      "Epoch 18, CIFAR-10 Batch 4:  Loss: 1.3311452865600586   Validation Accuracy: 0.5297999382019043\n",
      "Epoch 18, CIFAR-10 Batch 5:  Loss: 1.2963330745697021   Validation Accuracy: 0.517799973487854\n",
      "Epoch 19, CIFAR-10 Batch 1:  Loss: 1.3308616876602173   Validation Accuracy: 0.5247999429702759\n",
      "Epoch 19, CIFAR-10 Batch 2:  Loss: 1.3206082582473755   Validation Accuracy: 0.5347999334335327\n",
      "Epoch 19, CIFAR-10 Batch 3:  Loss: 1.2600960731506348   Validation Accuracy: 0.5273998975753784\n",
      "Epoch 19, CIFAR-10 Batch 4:  Loss: 1.2874951362609863   Validation Accuracy: 0.5365999341011047\n",
      "Epoch 19, CIFAR-10 Batch 5:  Loss: 1.284393310546875    Validation Accuracy: 0.5159999132156372\n",
      "Epoch 20, CIFAR-10 Batch 1:  Loss: 1.2921264171600342   Validation Accuracy: 0.5215999484062195\n",
      "Epoch 20, CIFAR-10 Batch 2:  Loss: 1.3140668869018555   Validation Accuracy: 0.5331999063491821\n",
      "Epoch 20, CIFAR-10 Batch 3:  Loss: 1.263651728630066    Validation Accuracy: 0.5295999646186829\n",
      "Epoch 20, CIFAR-10 Batch 4:  Loss: 1.2667057514190674   Validation Accuracy: 0.5389999151229858\n",
      "Epoch 20, CIFAR-10 Batch 5:  Loss: 1.2716652154922485   Validation Accuracy: 0.527199923992157\n",
      "Epoch 21, CIFAR-10 Batch 1:  Loss: 1.2805250883102417   Validation Accuracy: 0.5251999497413635\n",
      "Epoch 21, CIFAR-10 Batch 2:  Loss: 1.3196816444396973   Validation Accuracy: 0.5233998894691467\n",
      "Epoch 21, CIFAR-10 Batch 3:  Loss: 1.2635430097579956   Validation Accuracy: 0.5255999565124512\n",
      "Epoch 21, CIFAR-10 Batch 4:  Loss: 1.2539966106414795   Validation Accuracy: 0.5381999611854553\n",
      "Epoch 21, CIFAR-10 Batch 5:  Loss: 1.2272300720214844   Validation Accuracy: 0.5409999489784241\n",
      "Epoch 22, CIFAR-10 Batch 1:  Loss: 1.2619822025299072   Validation Accuracy: 0.5139999389648438\n",
      "Epoch 22, CIFAR-10 Batch 2:  Loss: 1.279118537902832    Validation Accuracy: 0.5343999862670898\n",
      "Epoch 22, CIFAR-10 Batch 3:  Loss: 1.2281924486160278   Validation Accuracy: 0.5301999449729919\n",
      "Epoch 22, CIFAR-10 Batch 4:  Loss: 1.2167699337005615   Validation Accuracy: 0.5383999347686768\n",
      "Epoch 22, CIFAR-10 Batch 5:  Loss: 1.2269355058670044   Validation Accuracy: 0.5363999605178833\n",
      "Epoch 23, CIFAR-10 Batch 1:  Loss: 1.2111148834228516   Validation Accuracy: 0.5243999361991882\n",
      "Epoch 23, CIFAR-10 Batch 2:  Loss: 1.2906004190444946   Validation Accuracy: 0.5257999300956726\n",
      "Epoch 23, CIFAR-10 Batch 3:  Loss: 1.266408920288086    Validation Accuracy: 0.5149999260902405\n",
      "Epoch 23, CIFAR-10 Batch 4:  Loss: 1.2172207832336426   Validation Accuracy: 0.5333999395370483\n",
      "Epoch 23, CIFAR-10 Batch 5:  Loss: 1.2043097019195557   Validation Accuracy: 0.5389999151229858\n",
      "Epoch 24, CIFAR-10 Batch 1:  Loss: 1.1849325895309448   Validation Accuracy: 0.5413998961448669\n",
      "Epoch 24, CIFAR-10 Batch 2:  Loss: 1.2545840740203857   Validation Accuracy: 0.528999924659729\n",
      "Epoch 24, CIFAR-10 Batch 3:  Loss: 1.2673208713531494   Validation Accuracy: 0.5043999552726746\n",
      "Epoch 24, CIFAR-10 Batch 4:  Loss: 1.2359652519226074   Validation Accuracy: 0.5293999314308167\n",
      "Epoch 24, CIFAR-10 Batch 5:  Loss: 1.2055387496948242   Validation Accuracy: 0.5329999327659607\n",
      "Epoch 25, CIFAR-10 Batch 1:  Loss: 1.1917587518692017   Validation Accuracy: 0.5311999320983887\n",
      "Epoch 25, CIFAR-10 Batch 2:  Loss: 1.2527437210083008   Validation Accuracy: 0.5285999774932861\n",
      "Epoch 25, CIFAR-10 Batch 3:  Loss: 1.214605689048767    Validation Accuracy: 0.5223999619483948\n",
      "Epoch 25, CIFAR-10 Batch 4:  Loss: 1.1909364461898804   Validation Accuracy: 0.5229998826980591\n",
      "Epoch 25, CIFAR-10 Batch 5:  Loss: 1.2047511339187622   Validation Accuracy: 0.5143999457359314\n",
      "Epoch 26, CIFAR-10 Batch 1:  Loss: 1.1759072542190552   Validation Accuracy: 0.5215999484062195\n",
      "Epoch 26, CIFAR-10 Batch 2:  Loss: 1.2109274864196777   Validation Accuracy: 0.5365999937057495\n",
      "Epoch 26, CIFAR-10 Batch 3:  Loss: 1.189327597618103    Validation Accuracy: 0.5221999287605286\n",
      "Epoch 26, CIFAR-10 Batch 4:  Loss: 1.1645641326904297   Validation Accuracy: 0.5191999673843384\n",
      "Epoch 26, CIFAR-10 Batch 5:  Loss: 1.1975528001785278   Validation Accuracy: 0.5105999708175659\n",
      "Epoch 27, CIFAR-10 Batch 1:  Loss: 1.1635758876800537   Validation Accuracy: 0.5239999294281006\n",
      "Epoch 27, CIFAR-10 Batch 2:  Loss: 1.1741054058074951   Validation Accuracy: 0.542199969291687\n",
      "Epoch 27, CIFAR-10 Batch 3:  Loss: 1.1400697231292725   Validation Accuracy: 0.5301999449729919\n",
      "Epoch 27, CIFAR-10 Batch 4:  Loss: 1.1463135480880737   Validation Accuracy: 0.525399923324585\n",
      "Epoch 27, CIFAR-10 Batch 5:  Loss: 1.172532320022583    Validation Accuracy: 0.5143998861312866\n",
      "Epoch 28, CIFAR-10 Batch 1:  Loss: 1.1698307991027832   Validation Accuracy: 0.5167999863624573\n",
      "Epoch 28, CIFAR-10 Batch 2:  Loss: 1.2158540487289429   Validation Accuracy: 0.5223999619483948\n",
      "Epoch 28, CIFAR-10 Batch 3:  Loss: 1.154813289642334    Validation Accuracy: 0.5265998840332031\n",
      "Epoch 28, CIFAR-10 Batch 4:  Loss: 1.1252949237823486   Validation Accuracy: 0.5339999198913574\n",
      "Epoch 28, CIFAR-10 Batch 5:  Loss: 1.1538913249969482   Validation Accuracy: 0.5225999355316162\n",
      "Epoch 29, CIFAR-10 Batch 1:  Loss: 1.1446750164031982   Validation Accuracy: 0.5213999152183533\n",
      "Epoch 29, CIFAR-10 Batch 2:  Loss: 1.1616637706756592   Validation Accuracy: 0.5253999829292297\n",
      "Epoch 29, CIFAR-10 Batch 3:  Loss: 1.1408216953277588   Validation Accuracy: 0.5307999849319458\n",
      "Epoch 29, CIFAR-10 Batch 4:  Loss: 1.1161413192749023   Validation Accuracy: 0.5309999585151672\n",
      "Epoch 29, CIFAR-10 Batch 5:  Loss: 1.1318144798278809   Validation Accuracy: 0.5383999347686768\n",
      "Epoch 30, CIFAR-10 Batch 1:  Loss: 1.121402621269226    Validation Accuracy: 0.528999924659729\n",
      "Epoch 30, CIFAR-10 Batch 2:  Loss: 1.1687589883804321   Validation Accuracy: 0.5211999416351318\n",
      "Epoch 30, CIFAR-10 Batch 3:  Loss: 1.1271862983703613   Validation Accuracy: 0.5349999070167542\n",
      "Epoch 30, CIFAR-10 Batch 4:  Loss: 1.1404039859771729   Validation Accuracy: 0.5227999687194824\n",
      "Epoch 30, CIFAR-10 Batch 5:  Loss: 1.1813700199127197   Validation Accuracy: 0.5165999531745911\n",
      "Epoch 31, CIFAR-10 Batch 1:  Loss: 1.1301201581954956   Validation Accuracy: 0.5333999395370483\n",
      "Epoch 31, CIFAR-10 Batch 2:  Loss: 1.1334123611450195   Validation Accuracy: 0.5317999720573425\n",
      "Epoch 31, CIFAR-10 Batch 3:  Loss: 1.1127569675445557   Validation Accuracy: 0.5353999137878418\n",
      "Epoch 31, CIFAR-10 Batch 4:  Loss: 1.1018829345703125   Validation Accuracy: 0.5351999402046204\n",
      "Epoch 31, CIFAR-10 Batch 5:  Loss: 1.1273550987243652   Validation Accuracy: 0.519599974155426\n",
      "Epoch 32, CIFAR-10 Batch 1:  Loss: 1.1070894002914429   Validation Accuracy: 0.5267999172210693\n",
      "Epoch 32, CIFAR-10 Batch 2:  Loss: 1.1567912101745605   Validation Accuracy: 0.5207999348640442\n",
      "Epoch 32, CIFAR-10 Batch 3:  Loss: 1.115362524986267    Validation Accuracy: 0.5255999565124512\n",
      "Epoch 32, CIFAR-10 Batch 4:  Loss: 1.0943613052368164   Validation Accuracy: 0.5343999266624451\n",
      "Epoch 32, CIFAR-10 Batch 5:  Loss: 1.1117167472839355   Validation Accuracy: 0.5370000004768372\n",
      "Epoch 33, CIFAR-10 Batch 1:  Loss: 1.091554045677185    Validation Accuracy: 0.5363999009132385\n",
      "Epoch 33, CIFAR-10 Batch 2:  Loss: 1.1514256000518799   Validation Accuracy: 0.52239990234375\n",
      "Epoch 33, CIFAR-10 Batch 3:  Loss: 1.1259739398956299   Validation Accuracy: 0.528999924659729\n",
      "Epoch 33, CIFAR-10 Batch 4:  Loss: 1.09157395362854     Validation Accuracy: 0.533799946308136\n",
      "Epoch 33, CIFAR-10 Batch 5:  Loss: 1.1297156810760498   Validation Accuracy: 0.5269999504089355\n",
      "Epoch 34, CIFAR-10 Batch 1:  Loss: 1.1078920364379883   Validation Accuracy: 0.5265999436378479\n",
      "Epoch 34, CIFAR-10 Batch 2:  Loss: 1.1240043640136719   Validation Accuracy: 0.5329999327659607\n",
      "Epoch 34, CIFAR-10 Batch 3:  Loss: 1.1261099576950073   Validation Accuracy: 0.5313999652862549\n",
      "Epoch 34, CIFAR-10 Batch 4:  Loss: 1.090584397315979    Validation Accuracy: 0.5399999022483826\n",
      "Epoch 34, CIFAR-10 Batch 5:  Loss: 1.1130141019821167   Validation Accuracy: 0.5341999530792236\n",
      "Epoch 35, CIFAR-10 Batch 1:  Loss: 1.0735760927200317   Validation Accuracy: 0.5237999558448792\n",
      "Epoch 35, CIFAR-10 Batch 2:  Loss: 1.1063482761383057   Validation Accuracy: 0.5361999273300171\n",
      "Epoch 35, CIFAR-10 Batch 3:  Loss: 1.1073534488677979   Validation Accuracy: 0.5343999266624451\n",
      "Epoch 35, CIFAR-10 Batch 4:  Loss: 1.0588390827178955   Validation Accuracy: 0.5363999605178833\n",
      "Epoch 35, CIFAR-10 Batch 5:  Loss: 1.110601544380188    Validation Accuracy: 0.5219999551773071\n",
      "Epoch 36, CIFAR-10 Batch 1:  Loss: 1.0668734312057495   Validation Accuracy: 0.5263999700546265\n",
      "Epoch 36, CIFAR-10 Batch 2:  Loss: 1.1093745231628418   Validation Accuracy: 0.5295999050140381\n",
      "Epoch 36, CIFAR-10 Batch 3:  Loss: 1.0672588348388672   Validation Accuracy: 0.5403999090194702\n",
      "Epoch 36, CIFAR-10 Batch 4:  Loss: 1.0707025527954102   Validation Accuracy: 0.5171999931335449\n",
      "Epoch 36, CIFAR-10 Batch 5:  Loss: 1.1072015762329102   Validation Accuracy: 0.5133999586105347\n",
      "Epoch 37, CIFAR-10 Batch 1:  Loss: 1.0533332824707031   Validation Accuracy: 0.5287999510765076\n",
      "Epoch 37, CIFAR-10 Batch 2:  Loss: 1.0912362337112427   Validation Accuracy: 0.5379999279975891\n",
      "Epoch 37, CIFAR-10 Batch 3:  Loss: 1.085296392440796    Validation Accuracy: 0.5243999361991882\n",
      "Epoch 37, CIFAR-10 Batch 4:  Loss: 1.0487473011016846   Validation Accuracy: 0.5301999449729919\n",
      "Epoch 37, CIFAR-10 Batch 5:  Loss: 1.1099838018417358   Validation Accuracy: 0.5113999843597412\n",
      "Epoch 38, CIFAR-10 Batch 1:  Loss: 1.0817582607269287   Validation Accuracy: 0.5161999464035034\n",
      "Epoch 38, CIFAR-10 Batch 2:  Loss: 1.1470115184783936   Validation Accuracy: 0.5155999660491943\n",
      "Epoch 38, CIFAR-10 Batch 3:  Loss: 1.091401219367981    Validation Accuracy: 0.5163999795913696\n",
      "Epoch 38, CIFAR-10 Batch 4:  Loss: 1.0715713500976562   Validation Accuracy: 0.5153999328613281\n",
      "Epoch 38, CIFAR-10 Batch 5:  Loss: 1.0771950483322144   Validation Accuracy: 0.5225999355316162\n",
      "Epoch 39, CIFAR-10 Batch 1:  Loss: 1.0584145784378052   Validation Accuracy: 0.5183999538421631\n",
      "Epoch 39, CIFAR-10 Batch 2:  Loss: 1.1346697807312012   Validation Accuracy: 0.5109999775886536\n",
      "Epoch 39, CIFAR-10 Batch 3:  Loss: 1.0975470542907715   Validation Accuracy: 0.525999903678894\n",
      "Epoch 39, CIFAR-10 Batch 4:  Loss: 1.0382850170135498   Validation Accuracy: 0.5293999910354614\n",
      "Epoch 39, CIFAR-10 Batch 5:  Loss: 1.0591319799423218   Validation Accuracy: 0.5297999382019043\n",
      "Epoch 40, CIFAR-10 Batch 1:  Loss: 1.0303529500961304   Validation Accuracy: 0.527199923992157\n",
      "Epoch 40, CIFAR-10 Batch 2:  Loss: 1.0877761840820312   Validation Accuracy: 0.5167999267578125\n",
      "Epoch 40, CIFAR-10 Batch 3:  Loss: 1.0750761032104492   Validation Accuracy: 0.5189999341964722\n",
      "Epoch 40, CIFAR-10 Batch 4:  Loss: 1.0551961660385132   Validation Accuracy: 0.5157999396324158\n",
      "Epoch 40, CIFAR-10 Batch 5:  Loss: 1.0646723508834839   Validation Accuracy: 0.5227999687194824\n",
      "Epoch 41, CIFAR-10 Batch 1:  Loss: 1.0269525051116943   Validation Accuracy: 0.5275999307632446\n",
      "Epoch 41, CIFAR-10 Batch 2:  Loss: 1.075736165046692    Validation Accuracy: 0.5189999341964722\n",
      "Epoch 41, CIFAR-10 Batch 3:  Loss: 1.0517150163650513   Validation Accuracy: 0.52239990234375\n",
      "Epoch 41, CIFAR-10 Batch 4:  Loss: 1.0437586307525635   Validation Accuracy: 0.5217999219894409\n",
      "Epoch 41, CIFAR-10 Batch 5:  Loss: 1.0641772747039795   Validation Accuracy: 0.5125999450683594\n",
      "Epoch 42, CIFAR-10 Batch 1:  Loss: 0.9301227331161499   Validation Accuracy: 0.5243999361991882\n",
      "Epoch 42, CIFAR-10 Batch 2:  Loss: 0.9526435136795044   Validation Accuracy: 0.5181999802589417\n",
      "Epoch 42, CIFAR-10 Batch 3:  Loss: 0.9594876170158386   Validation Accuracy: 0.5371999740600586\n",
      "Epoch 42, CIFAR-10 Batch 4:  Loss: 0.8749381303787231   Validation Accuracy: 0.5293999314308167\n",
      "Epoch 42, CIFAR-10 Batch 5:  Loss: 0.8984142541885376   Validation Accuracy: 0.5301999449729919\n",
      "Epoch 43, CIFAR-10 Batch 1:  Loss: 0.8684051632881165   Validation Accuracy: 0.5281999707221985\n",
      "Epoch 43, CIFAR-10 Batch 2:  Loss: 0.913497805595398    Validation Accuracy: 0.51419997215271\n",
      "Epoch 43, CIFAR-10 Batch 3:  Loss: 0.9073150157928467   Validation Accuracy: 0.5369999408721924\n",
      "Epoch 43, CIFAR-10 Batch 4:  Loss: 0.8493860363960266   Validation Accuracy: 0.5275999307632446\n",
      "Epoch 43, CIFAR-10 Batch 5:  Loss: 0.891756534576416    Validation Accuracy: 0.5223999619483948\n",
      "Epoch 44, CIFAR-10 Batch 1:  Loss: 0.8597452640533447   Validation Accuracy: 0.5231999158859253\n",
      "Epoch 44, CIFAR-10 Batch 2:  Loss: 0.895652174949646    Validation Accuracy: 0.5221999287605286\n",
      "Epoch 44, CIFAR-10 Batch 3:  Loss: 0.8920579552650452   Validation Accuracy: 0.5437999367713928\n",
      "Epoch 44, CIFAR-10 Batch 4:  Loss: 0.8289669156074524   Validation Accuracy: 0.5333999395370483\n",
      "Epoch 44, CIFAR-10 Batch 5:  Loss: 0.8801317811012268   Validation Accuracy: 0.5219999551773071\n",
      "Epoch 45, CIFAR-10 Batch 1:  Loss: 0.8629461526870728   Validation Accuracy: 0.5143999457359314\n",
      "Epoch 45, CIFAR-10 Batch 2:  Loss: 0.8950605392456055   Validation Accuracy: 0.5335999727249146\n",
      "Epoch 45, CIFAR-10 Batch 3:  Loss: 0.8906911611557007   Validation Accuracy: 0.5387999415397644\n",
      "Epoch 45, CIFAR-10 Batch 4:  Loss: 0.8297613859176636   Validation Accuracy: 0.5237998962402344\n",
      "Epoch 45, CIFAR-10 Batch 5:  Loss: 0.8559728264808655   Validation Accuracy: 0.5317999720573425\n",
      "Epoch 46, CIFAR-10 Batch 1:  Loss: 0.8261439204216003   Validation Accuracy: 0.531999945640564\n",
      "Epoch 46, CIFAR-10 Batch 2:  Loss: 0.8843273520469666   Validation Accuracy: 0.5323998928070068\n",
      "Epoch 46, CIFAR-10 Batch 3:  Loss: 0.8913918733596802   Validation Accuracy: 0.5321999788284302\n",
      "Epoch 46, CIFAR-10 Batch 4:  Loss: 0.81770259141922     Validation Accuracy: 0.515999972820282\n",
      "Epoch 46, CIFAR-10 Batch 5:  Loss: 0.8515499234199524   Validation Accuracy: 0.527199923992157\n",
      "Epoch 47, CIFAR-10 Batch 1:  Loss: 0.8176470398902893   Validation Accuracy: 0.5279999375343323\n",
      "Epoch 47, CIFAR-10 Batch 2:  Loss: 0.8640968203544617   Validation Accuracy: 0.5273999571800232\n",
      "Epoch 47, CIFAR-10 Batch 3:  Loss: 0.8765935897827148   Validation Accuracy: 0.5279999375343323\n",
      "Epoch 47, CIFAR-10 Batch 4:  Loss: 0.8196935057640076   Validation Accuracy: 0.5097999572753906\n",
      "Epoch 47, CIFAR-10 Batch 5:  Loss: 0.8707733750343323   Validation Accuracy: 0.5083999633789062\n",
      "Epoch 48, CIFAR-10 Batch 1:  Loss: 0.8088942170143127   Validation Accuracy: 0.5271999835968018\n",
      "Epoch 48, CIFAR-10 Batch 2:  Loss: 0.8692442178726196   Validation Accuracy: 0.5198000073432922\n",
      "Epoch 48, CIFAR-10 Batch 3:  Loss: 0.8936383128166199   Validation Accuracy: 0.511199951171875\n",
      "Epoch 48, CIFAR-10 Batch 4:  Loss: 0.816450297832489    Validation Accuracy: 0.4999999403953552\n",
      "Epoch 48, CIFAR-10 Batch 5:  Loss: 0.840830385684967    Validation Accuracy: 0.5245999097824097\n",
      "Epoch 49, CIFAR-10 Batch 1:  Loss: 0.7993266582489014   Validation Accuracy: 0.5331999659538269\n",
      "Epoch 49, CIFAR-10 Batch 2:  Loss: 0.8507093787193298   Validation Accuracy: 0.5271999835968018\n",
      "Epoch 49, CIFAR-10 Batch 3:  Loss: 0.8678789138793945   Validation Accuracy: 0.5216000080108643\n",
      "Epoch 49, CIFAR-10 Batch 4:  Loss: 0.8070639371871948   Validation Accuracy: 0.5041999220848083\n",
      "Epoch 49, CIFAR-10 Batch 5:  Loss: 0.8289034366607666   Validation Accuracy: 0.5413998961448669\n",
      "Epoch 50, CIFAR-10 Batch 1:  Loss: 0.7972216606140137   Validation Accuracy: 0.5237998962402344\n",
      "Epoch 50, CIFAR-10 Batch 2:  Loss: 0.8396869897842407   Validation Accuracy: 0.5347999334335327\n",
      "Epoch 50, CIFAR-10 Batch 3:  Loss: 0.8687146306037903   Validation Accuracy: 0.5159999132156372\n",
      "Epoch 50, CIFAR-10 Batch 4:  Loss: 0.8140493631362915   Validation Accuracy: 0.5049999356269836\n",
      "Epoch 50, CIFAR-10 Batch 5:  Loss: 0.8411354422569275   Validation Accuracy: 0.5351999998092651\n",
      "Epoch 51, CIFAR-10 Batch 1:  Loss: 0.7960236668586731   Validation Accuracy: 0.5239999294281006\n",
      "Epoch 51, CIFAR-10 Batch 2:  Loss: 0.8222084045410156   Validation Accuracy: 0.5317999124526978\n",
      "Epoch 51, CIFAR-10 Batch 3:  Loss: 0.835800051689148    Validation Accuracy: 0.5371999144554138\n",
      "Epoch 51, CIFAR-10 Batch 4:  Loss: 0.7778143286705017   Validation Accuracy: 0.5099999308586121\n",
      "Epoch 51, CIFAR-10 Batch 5:  Loss: 0.8294270634651184   Validation Accuracy: 0.5279999375343323\n",
      "Epoch 52, CIFAR-10 Batch 1:  Loss: 0.7870579361915588   Validation Accuracy: 0.5265999436378479\n",
      "Epoch 52, CIFAR-10 Batch 2:  Loss: 0.8232277035713196   Validation Accuracy: 0.5183999538421631\n",
      "Epoch 52, CIFAR-10 Batch 3:  Loss: 0.8380215167999268   Validation Accuracy: 0.5293999314308167\n",
      "Epoch 52, CIFAR-10 Batch 4:  Loss: 0.7689762711524963   Validation Accuracy: 0.5243999361991882\n",
      "Epoch 52, CIFAR-10 Batch 5:  Loss: 0.8180121779441833   Validation Accuracy: 0.5203999876976013\n",
      "Epoch 53, CIFAR-10 Batch 1:  Loss: 0.7770635485649109   Validation Accuracy: 0.5135999321937561\n",
      "Epoch 53, CIFAR-10 Batch 2:  Loss: 0.8337492346763611   Validation Accuracy: 0.51419997215271\n",
      "Epoch 53, CIFAR-10 Batch 3:  Loss: 0.8343234658241272   Validation Accuracy: 0.5241999626159668\n",
      "Epoch 53, CIFAR-10 Batch 4:  Loss: 0.7961025834083557   Validation Accuracy: 0.5149999856948853\n",
      "Epoch 53, CIFAR-10 Batch 5:  Loss: 0.8221822381019592   Validation Accuracy: 0.5171999335289001\n",
      "Epoch 54, CIFAR-10 Batch 1:  Loss: 0.7950032949447632   Validation Accuracy: 0.5203999876976013\n",
      "Epoch 54, CIFAR-10 Batch 2:  Loss: 0.8270033001899719   Validation Accuracy: 0.5305999517440796\n",
      "Epoch 54, CIFAR-10 Batch 3:  Loss: 0.8421830534934998   Validation Accuracy: 0.5169999599456787\n",
      "Epoch 54, CIFAR-10 Batch 4:  Loss: 0.8093572854995728   Validation Accuracy: 0.5031999349594116\n",
      "Epoch 54, CIFAR-10 Batch 5:  Loss: 0.8631075024604797   Validation Accuracy: 0.5119999647140503\n",
      "Epoch 55, CIFAR-10 Batch 1:  Loss: 0.7865009307861328   Validation Accuracy: 0.5249999165534973\n",
      "Epoch 55, CIFAR-10 Batch 2:  Loss: 0.8327946662902832   Validation Accuracy: 0.515999972820282\n",
      "Epoch 55, CIFAR-10 Batch 3:  Loss: 0.836288571357727    Validation Accuracy: 0.5173999667167664\n",
      "Epoch 55, CIFAR-10 Batch 4:  Loss: 0.7808880805969238   Validation Accuracy: 0.4987999200820923\n",
      "Epoch 55, CIFAR-10 Batch 5:  Loss: 0.8267548084259033   Validation Accuracy: 0.5127999186515808\n",
      "Epoch 56, CIFAR-10 Batch 1:  Loss: 0.7703632712364197   Validation Accuracy: 0.51419997215271\n",
      "Epoch 56, CIFAR-10 Batch 2:  Loss: 0.8275923728942871   Validation Accuracy: 0.5121999979019165\n",
      "Epoch 56, CIFAR-10 Batch 3:  Loss: 0.8438457250595093   Validation Accuracy: 0.51419997215271\n",
      "Epoch 56, CIFAR-10 Batch 4:  Loss: 0.7668908834457397   Validation Accuracy: 0.512999951839447\n",
      "Epoch 56, CIFAR-10 Batch 5:  Loss: 0.8097378015518188   Validation Accuracy: 0.5171999335289001\n",
      "Epoch 57, CIFAR-10 Batch 1:  Loss: 0.7584259510040283   Validation Accuracy: 0.5135999917984009\n",
      "Epoch 57, CIFAR-10 Batch 2:  Loss: 0.8053773045539856   Validation Accuracy: 0.5194000005722046\n",
      "Epoch 57, CIFAR-10 Batch 3:  Loss: 0.8266289234161377   Validation Accuracy: 0.5219999551773071\n",
      "Epoch 57, CIFAR-10 Batch 4:  Loss: 0.7569534778594971   Validation Accuracy: 0.5221999883651733\n",
      "Epoch 57, CIFAR-10 Batch 5:  Loss: 0.8055455088615417   Validation Accuracy: 0.5185999274253845\n",
      "Epoch 58, CIFAR-10 Batch 1:  Loss: 0.7464942932128906   Validation Accuracy: 0.5243999361991882\n",
      "Epoch 58, CIFAR-10 Batch 2:  Loss: 0.8000058531761169   Validation Accuracy: 0.5267999172210693\n",
      "Epoch 58, CIFAR-10 Batch 3:  Loss: 0.8262162208557129   Validation Accuracy: 0.5149999260902405\n",
      "Epoch 58, CIFAR-10 Batch 4:  Loss: 0.7572571039199829   Validation Accuracy: 0.5237999558448792\n",
      "Epoch 58, CIFAR-10 Batch 5:  Loss: 0.7905012369155884   Validation Accuracy: 0.5249999761581421\n",
      "Epoch 59, CIFAR-10 Batch 1:  Loss: 0.7475786209106445   Validation Accuracy: 0.5203999280929565\n",
      "Epoch 59, CIFAR-10 Batch 2:  Loss: 0.7963141202926636   Validation Accuracy: 0.5261999368667603\n",
      "Epoch 59, CIFAR-10 Batch 3:  Loss: 0.8192375898361206   Validation Accuracy: 0.5183999538421631\n",
      "Epoch 59, CIFAR-10 Batch 4:  Loss: 0.7570072412490845   Validation Accuracy: 0.5209999084472656\n",
      "Epoch 59, CIFAR-10 Batch 5:  Loss: 0.7980546355247498   Validation Accuracy: 0.5187999606132507\n",
      "Epoch 60, CIFAR-10 Batch 1:  Loss: 0.7393726110458374   Validation Accuracy: 0.5285999774932861\n",
      "Epoch 60, CIFAR-10 Batch 2:  Loss: 0.790791928768158    Validation Accuracy: 0.524399995803833\n",
      "Epoch 60, CIFAR-10 Batch 3:  Loss: 0.8141610026359558   Validation Accuracy: 0.5193999409675598\n",
      "Epoch 60, CIFAR-10 Batch 4:  Loss: 0.7535182237625122   Validation Accuracy: 0.5229999423027039\n",
      "Epoch 60, CIFAR-10 Batch 5:  Loss: 0.79377281665802     Validation Accuracy: 0.5135999321937561\n",
      "Epoch 61, CIFAR-10 Batch 1:  Loss: 0.7434950470924377   Validation Accuracy: 0.519599974155426\n",
      "Epoch 61, CIFAR-10 Batch 2:  Loss: 0.7920824289321899   Validation Accuracy: 0.5189999341964722\n",
      "Epoch 61, CIFAR-10 Batch 3:  Loss: 0.8134070634841919   Validation Accuracy: 0.5241999626159668\n",
      "Epoch 61, CIFAR-10 Batch 4:  Loss: 0.7482950091362      Validation Accuracy: 0.5203999280929565\n",
      "Epoch 61, CIFAR-10 Batch 5:  Loss: 0.7828041315078735   Validation Accuracy: 0.5147998929023743\n",
      "Epoch 62, CIFAR-10 Batch 1:  Loss: 0.7343618869781494   Validation Accuracy: 0.5247999429702759\n",
      "Epoch 62, CIFAR-10 Batch 2:  Loss: 0.7876327037811279   Validation Accuracy: 0.5211999416351318\n",
      "Epoch 62, CIFAR-10 Batch 3:  Loss: 0.8068325519561768   Validation Accuracy: 0.5247999429702759\n",
      "Epoch 62, CIFAR-10 Batch 4:  Loss: 0.7539465427398682   Validation Accuracy: 0.5143999457359314\n",
      "Epoch 62, CIFAR-10 Batch 5:  Loss: 0.7832238674163818   Validation Accuracy: 0.5101999640464783\n",
      "Epoch 63, CIFAR-10 Batch 1:  Loss: 0.7336721420288086   Validation Accuracy: 0.5243999361991882\n",
      "Epoch 63, CIFAR-10 Batch 2:  Loss: 0.7857780456542969   Validation Accuracy: 0.520799994468689\n",
      "Epoch 63, CIFAR-10 Batch 3:  Loss: 0.8059945106506348   Validation Accuracy: 0.5171999335289001\n",
      "Epoch 63, CIFAR-10 Batch 4:  Loss: 0.7485735416412354   Validation Accuracy: 0.514799952507019\n",
      "Epoch 63, CIFAR-10 Batch 5:  Loss: 0.7804838418960571   Validation Accuracy: 0.5195999145507812\n",
      "Epoch 64, CIFAR-10 Batch 1:  Loss: 0.7365687489509583   Validation Accuracy: 0.5137999653816223\n",
      "Epoch 64, CIFAR-10 Batch 2:  Loss: 0.7856195569038391   Validation Accuracy: 0.5183999538421631\n",
      "Epoch 64, CIFAR-10 Batch 3:  Loss: 0.8098386526107788   Validation Accuracy: 0.5183999538421631\n",
      "Epoch 64, CIFAR-10 Batch 4:  Loss: 0.7464101910591125   Validation Accuracy: 0.5211999416351318\n",
      "Epoch 64, CIFAR-10 Batch 5:  Loss: 0.779475748538971    Validation Accuracy: 0.5221999287605286\n",
      "Epoch 65, CIFAR-10 Batch 1:  Loss: 0.7343589663505554   Validation Accuracy: 0.5153999328613281\n",
      "Epoch 65, CIFAR-10 Batch 2:  Loss: 0.783359706401825    Validation Accuracy: 0.5235999822616577\n",
      "Epoch 65, CIFAR-10 Batch 3:  Loss: 0.8053874373435974   Validation Accuracy: 0.507599949836731\n",
      "Epoch 65, CIFAR-10 Batch 4:  Loss: 0.7480337619781494   Validation Accuracy: 0.525999903678894\n",
      "Epoch 65, CIFAR-10 Batch 5:  Loss: 0.7827755212783813   Validation Accuracy: 0.5145999789237976\n",
      "Epoch 66, CIFAR-10 Batch 1:  Loss: 0.7295810580253601   Validation Accuracy: 0.518799901008606\n",
      "Epoch 66, CIFAR-10 Batch 2:  Loss: 0.7819118499755859   Validation Accuracy: 0.5263999700546265\n",
      "Epoch 66, CIFAR-10 Batch 3:  Loss: 0.8015100359916687   Validation Accuracy: 0.5217999219894409\n",
      "Epoch 66, CIFAR-10 Batch 4:  Loss: 0.7503064274787903   Validation Accuracy: 0.5203999280929565\n",
      "Epoch 66, CIFAR-10 Batch 5:  Loss: 0.7789631485939026   Validation Accuracy: 0.5135999321937561\n",
      "Epoch 67, CIFAR-10 Batch 1:  Loss: 0.7371441721916199   Validation Accuracy: 0.5069999694824219\n",
      "Epoch 67, CIFAR-10 Batch 2:  Loss: 0.7840925455093384   Validation Accuracy: 0.5265999436378479\n",
      "Epoch 67, CIFAR-10 Batch 3:  Loss: 0.7996169924736023   Validation Accuracy: 0.5203999280929565\n",
      "Epoch 67, CIFAR-10 Batch 4:  Loss: 0.7506942749023438   Validation Accuracy: 0.5219999551773071\n",
      "Epoch 67, CIFAR-10 Batch 5:  Loss: 0.7789163589477539   Validation Accuracy: 0.5175999402999878\n",
      "Epoch 68, CIFAR-10 Batch 1:  Loss: 0.7308356761932373   Validation Accuracy: 0.5183999538421631\n",
      "Epoch 68, CIFAR-10 Batch 2:  Loss: 0.7771171927452087   Validation Accuracy: 0.5284000039100647\n",
      "Epoch 68, CIFAR-10 Batch 3:  Loss: 0.7991546392440796   Validation Accuracy: 0.509399950504303\n",
      "Epoch 68, CIFAR-10 Batch 4:  Loss: 0.7472140192985535   Validation Accuracy: 0.5211999416351318\n",
      "Epoch 68, CIFAR-10 Batch 5:  Loss: 0.7801207304000854   Validation Accuracy: 0.5211999416351318\n",
      "Epoch 69, CIFAR-10 Batch 1:  Loss: 0.7335346341133118   Validation Accuracy: 0.5115999579429626\n",
      "Epoch 69, CIFAR-10 Batch 2:  Loss: 0.7782808542251587   Validation Accuracy: 0.5211999416351318\n",
      "Epoch 69, CIFAR-10 Batch 3:  Loss: 0.80157870054245     Validation Accuracy: 0.5131999254226685\n",
      "Epoch 69, CIFAR-10 Batch 4:  Loss: 0.7464338541030884   Validation Accuracy: 0.5227999091148376\n",
      "Epoch 69, CIFAR-10 Batch 5:  Loss: 0.7801098823547363   Validation Accuracy: 0.5193999409675598\n",
      "Epoch 70, CIFAR-10 Batch 1:  Loss: 0.7349888682365417   Validation Accuracy: 0.5097999572753906\n",
      "Epoch 70, CIFAR-10 Batch 2:  Loss: 0.7775108814239502   Validation Accuracy: 0.5187999606132507\n",
      "Epoch 70, CIFAR-10 Batch 3:  Loss: 0.7995201945304871   Validation Accuracy: 0.5133999586105347\n",
      "Epoch 70, CIFAR-10 Batch 4:  Loss: 0.7469662427902222   Validation Accuracy: 0.5195999145507812\n",
      "Epoch 70, CIFAR-10 Batch 5:  Loss: 0.7803781032562256   Validation Accuracy: 0.512999951839447\n",
      "Epoch 71, CIFAR-10 Batch 1:  Loss: 0.7308485507965088   Validation Accuracy: 0.521399974822998\n",
      "Epoch 71, CIFAR-10 Batch 2:  Loss: 0.7763305306434631   Validation Accuracy: 0.521399974822998\n",
      "Epoch 71, CIFAR-10 Batch 3:  Loss: 0.7999454140663147   Validation Accuracy: 0.5127999186515808\n",
      "Epoch 71, CIFAR-10 Batch 4:  Loss: 0.7464408278465271   Validation Accuracy: 0.5167999267578125\n",
      "Epoch 71, CIFAR-10 Batch 5:  Loss: 0.7771060466766357   Validation Accuracy: 0.514799952507019\n",
      "Epoch 72, CIFAR-10 Batch 1:  Loss: 0.7322385311126709   Validation Accuracy: 0.5175999402999878\n",
      "Epoch 72, CIFAR-10 Batch 2:  Loss: 0.7760509252548218   Validation Accuracy: 0.5219999551773071\n",
      "Epoch 72, CIFAR-10 Batch 3:  Loss: 0.8007486462593079   Validation Accuracy: 0.5281999707221985\n",
      "Epoch 72, CIFAR-10 Batch 4:  Loss: 0.7446250915527344   Validation Accuracy: 0.5157999396324158\n",
      "Epoch 72, CIFAR-10 Batch 5:  Loss: 0.7769488096237183   Validation Accuracy: 0.5173999667167664\n",
      "Epoch 73, CIFAR-10 Batch 1:  Loss: 0.7313188910484314   Validation Accuracy: 0.5183999538421631\n",
      "Epoch 73, CIFAR-10 Batch 2:  Loss: 0.7713190317153931   Validation Accuracy: 0.522599995136261\n",
      "Epoch 73, CIFAR-10 Batch 3:  Loss: 0.7974423170089722   Validation Accuracy: 0.5217999219894409\n",
      "Epoch 73, CIFAR-10 Batch 4:  Loss: 0.746052086353302    Validation Accuracy: 0.506399929523468\n",
      "Epoch 73, CIFAR-10 Batch 5:  Loss: 0.7738634347915649   Validation Accuracy: 0.5153999328613281\n",
      "Epoch 74, CIFAR-10 Batch 1:  Loss: 0.7300499677658081   Validation Accuracy: 0.5173999667167664\n",
      "Epoch 74, CIFAR-10 Batch 2:  Loss: 0.77147376537323     Validation Accuracy: 0.5197999477386475\n",
      "Epoch 74, CIFAR-10 Batch 3:  Loss: 0.7977681159973145   Validation Accuracy: 0.5233999490737915\n",
      "Epoch 74, CIFAR-10 Batch 4:  Loss: 0.7433163523674011   Validation Accuracy: 0.5153999328613281\n",
      "Epoch 74, CIFAR-10 Batch 5:  Loss: 0.7754400372505188   Validation Accuracy: 0.5239999294281006\n",
      "Epoch 75, CIFAR-10 Batch 1:  Loss: 0.7320930361747742   Validation Accuracy: 0.5203999876976013\n",
      "Epoch 75, CIFAR-10 Batch 2:  Loss: 0.771471381187439    Validation Accuracy: 0.5197999477386475\n",
      "Epoch 75, CIFAR-10 Batch 3:  Loss: 0.7975040078163147   Validation Accuracy: 0.5163999199867249\n",
      "Epoch 75, CIFAR-10 Batch 4:  Loss: 0.7432228922843933   Validation Accuracy: 0.5211999416351318\n",
      "Epoch 75, CIFAR-10 Batch 5:  Loss: 0.7751709222793579   Validation Accuracy: 0.5169999003410339\n",
      "Epoch 76, CIFAR-10 Batch 1:  Loss: 0.7300386428833008   Validation Accuracy: 0.527999997138977\n",
      "Epoch 76, CIFAR-10 Batch 2:  Loss: 0.7725621461868286   Validation Accuracy: 0.519599974155426\n",
      "Epoch 76, CIFAR-10 Batch 3:  Loss: 0.7988852858543396   Validation Accuracy: 0.518799901008606\n",
      "Epoch 76, CIFAR-10 Batch 4:  Loss: 0.7437840700149536   Validation Accuracy: 0.5151999592781067\n",
      "Epoch 76, CIFAR-10 Batch 5:  Loss: 0.773636519908905    Validation Accuracy: 0.5157999396324158\n",
      "Epoch 77, CIFAR-10 Batch 1:  Loss: 0.7287729382514954   Validation Accuracy: 0.5237999558448792\n",
      "Epoch 77, CIFAR-10 Batch 2:  Loss: 0.7708734273910522   Validation Accuracy: 0.5199999809265137\n",
      "Epoch 77, CIFAR-10 Batch 3:  Loss: 0.7961934208869934   Validation Accuracy: 0.5297999382019043\n",
      "Epoch 77, CIFAR-10 Batch 4:  Loss: 0.7422249913215637   Validation Accuracy: 0.5155999660491943\n",
      "Epoch 77, CIFAR-10 Batch 5:  Loss: 0.7745460271835327   Validation Accuracy: 0.519599974155426\n",
      "Epoch 78, CIFAR-10 Batch 1:  Loss: 0.7277997732162476   Validation Accuracy: 0.5239999294281006\n",
      "Epoch 78, CIFAR-10 Batch 2:  Loss: 0.7726929783821106   Validation Accuracy: 0.5237998962402344\n",
      "Epoch 78, CIFAR-10 Batch 3:  Loss: 0.7977926135063171   Validation Accuracy: 0.5251999497413635\n",
      "Epoch 78, CIFAR-10 Batch 4:  Loss: 0.744614839553833    Validation Accuracy: 0.5269998908042908\n",
      "Epoch 78, CIFAR-10 Batch 5:  Loss: 0.7736873626708984   Validation Accuracy: 0.5183998942375183\n",
      "Epoch 79, CIFAR-10 Batch 1:  Loss: 0.7282825112342834   Validation Accuracy: 0.5255999565124512\n",
      "Epoch 79, CIFAR-10 Batch 2:  Loss: 0.7705368399620056   Validation Accuracy: 0.5216000080108643\n",
      "Epoch 79, CIFAR-10 Batch 3:  Loss: 0.7970153093338013   Validation Accuracy: 0.5235999226570129\n",
      "Epoch 79, CIFAR-10 Batch 4:  Loss: 0.741896390914917    Validation Accuracy: 0.5209999084472656\n",
      "Epoch 79, CIFAR-10 Batch 5:  Loss: 0.7731203436851501   Validation Accuracy: 0.5173999667167664\n",
      "Epoch 80, CIFAR-10 Batch 1:  Loss: 0.727359414100647    Validation Accuracy: 0.5221999883651733\n",
      "Epoch 80, CIFAR-10 Batch 2:  Loss: 0.771399199962616    Validation Accuracy: 0.5203999876976013\n",
      "Epoch 80, CIFAR-10 Batch 3:  Loss: 0.7960351705551147   Validation Accuracy: 0.5237999558448792\n",
      "Epoch 80, CIFAR-10 Batch 4:  Loss: 0.7422933578491211   Validation Accuracy: 0.5230000019073486\n",
      "Epoch 80, CIFAR-10 Batch 5:  Loss: 0.7730892300605774   Validation Accuracy: 0.5233999490737915\n",
      "Epoch 81, CIFAR-10 Batch 1:  Loss: 0.7275077104568481   Validation Accuracy: 0.5195999145507812\n",
      "Epoch 81, CIFAR-10 Batch 2:  Loss: 0.7716574668884277   Validation Accuracy: 0.5235999822616577\n",
      "Epoch 81, CIFAR-10 Batch 3:  Loss: 0.7963980436325073   Validation Accuracy: 0.528999924659729\n",
      "Epoch 81, CIFAR-10 Batch 4:  Loss: 0.743133008480072    Validation Accuracy: 0.5175999402999878\n",
      "Epoch 81, CIFAR-10 Batch 5:  Loss: 0.7738829851150513   Validation Accuracy: 0.5201998949050903\n",
      "Epoch 82, CIFAR-10 Batch 1:  Loss: 0.7267788648605347   Validation Accuracy: 0.5203999280929565\n",
      "Epoch 82, CIFAR-10 Batch 2:  Loss: 0.7705410122871399   Validation Accuracy: 0.5249999165534973\n",
      "Epoch 82, CIFAR-10 Batch 3:  Loss: 0.7964512705802917   Validation Accuracy: 0.5295999646186829\n",
      "Epoch 82, CIFAR-10 Batch 4:  Loss: 0.7426748275756836   Validation Accuracy: 0.5163999199867249\n",
      "Epoch 82, CIFAR-10 Batch 5:  Loss: 0.7733521461486816   Validation Accuracy: 0.525999903678894\n",
      "Epoch 83, CIFAR-10 Batch 1:  Loss: 0.7265450954437256   Validation Accuracy: 0.5153999924659729\n",
      "Epoch 83, CIFAR-10 Batch 2:  Loss: 0.7705742120742798   Validation Accuracy: 0.5235999226570129\n",
      "Epoch 83, CIFAR-10 Batch 3:  Loss: 0.7966760396957397   Validation Accuracy: 0.5131999254226685\n",
      "Epoch 83, CIFAR-10 Batch 4:  Loss: 0.7413468360900879   Validation Accuracy: 0.5247999429702759\n",
      "Epoch 83, CIFAR-10 Batch 5:  Loss: 0.773107647895813    Validation Accuracy: 0.5291999578475952\n",
      "Epoch 84, CIFAR-10 Batch 1:  Loss: 0.7246888875961304   Validation Accuracy: 0.5233998894691467\n",
      "Epoch 84, CIFAR-10 Batch 2:  Loss: 0.7709012031555176   Validation Accuracy: 0.5161999464035034\n",
      "Epoch 84, CIFAR-10 Batch 3:  Loss: 0.7959609627723694   Validation Accuracy: 0.5257999897003174\n",
      "Epoch 84, CIFAR-10 Batch 4:  Loss: 0.7418098449707031   Validation Accuracy: 0.5123999118804932\n",
      "Epoch 84, CIFAR-10 Batch 5:  Loss: 0.7736870050430298   Validation Accuracy: 0.5265999436378479\n",
      "Epoch 85, CIFAR-10 Batch 1:  Loss: 0.7247170805931091   Validation Accuracy: 0.5133998990058899\n",
      "Epoch 85, CIFAR-10 Batch 2:  Loss: 0.7702490091323853   Validation Accuracy: 0.5221999287605286\n",
      "Epoch 85, CIFAR-10 Batch 3:  Loss: 0.7957874536514282   Validation Accuracy: 0.5269999504089355\n",
      "Epoch 85, CIFAR-10 Batch 4:  Loss: 0.7418760061264038   Validation Accuracy: 0.5157999396324158\n",
      "Epoch 85, CIFAR-10 Batch 5:  Loss: 0.7726825475692749   Validation Accuracy: 0.5251999497413635\n",
      "Epoch 86, CIFAR-10 Batch 1:  Loss: 0.7251585721969604   Validation Accuracy: 0.5133999586105347\n",
      "Epoch 86, CIFAR-10 Batch 2:  Loss: 0.7701427340507507   Validation Accuracy: 0.519599974155426\n",
      "Epoch 86, CIFAR-10 Batch 3:  Loss: 0.795958399772644    Validation Accuracy: 0.5171998739242554\n",
      "Epoch 86, CIFAR-10 Batch 4:  Loss: 0.7439038753509521   Validation Accuracy: 0.5169999599456787\n",
      "Epoch 86, CIFAR-10 Batch 5:  Loss: 0.7730773687362671   Validation Accuracy: 0.5225999355316162\n",
      "Epoch 87, CIFAR-10 Batch 1:  Loss: 0.7250146269798279   Validation Accuracy: 0.5209999680519104\n",
      "Epoch 87, CIFAR-10 Batch 2:  Loss: 0.7706813812255859   Validation Accuracy: 0.5239999294281006\n",
      "Epoch 87, CIFAR-10 Batch 3:  Loss: 0.7957744002342224   Validation Accuracy: 0.5195999145507812\n",
      "Epoch 87, CIFAR-10 Batch 4:  Loss: 0.7424477338790894   Validation Accuracy: 0.5155999660491943\n",
      "Epoch 87, CIFAR-10 Batch 5:  Loss: 0.7730177640914917   Validation Accuracy: 0.5217999219894409\n",
      "Epoch 88, CIFAR-10 Batch 1:  Loss: 0.7242497205734253   Validation Accuracy: 0.5197999477386475\n",
      "Epoch 88, CIFAR-10 Batch 2:  Loss: 0.7707982659339905   Validation Accuracy: 0.5217999815940857\n",
      "Epoch 88, CIFAR-10 Batch 3:  Loss: 0.7967751026153564   Validation Accuracy: 0.5251999497413635\n",
      "Epoch 88, CIFAR-10 Batch 4:  Loss: 0.7418953776359558   Validation Accuracy: 0.5099999308586121\n",
      "Epoch 88, CIFAR-10 Batch 5:  Loss: 0.7729769945144653   Validation Accuracy: 0.5273998975753784\n",
      "Epoch 89, CIFAR-10 Batch 1:  Loss: 0.7244215607643127   Validation Accuracy: 0.5157999396324158\n",
      "Epoch 89, CIFAR-10 Batch 2:  Loss: 0.7698358297348022   Validation Accuracy: 0.5225999355316162\n",
      "Epoch 89, CIFAR-10 Batch 3:  Loss: 0.7957951426506042   Validation Accuracy: 0.5257999897003174\n",
      "Epoch 89, CIFAR-10 Batch 4:  Loss: 0.7417080998420715   Validation Accuracy: 0.5165999531745911\n",
      "Epoch 89, CIFAR-10 Batch 5:  Loss: 0.7727198004722595   Validation Accuracy: 0.5213999152183533\n",
      "Epoch 90, CIFAR-10 Batch 1:  Loss: 0.7253492474555969   Validation Accuracy: 0.5093998908996582\n",
      "Epoch 90, CIFAR-10 Batch 2:  Loss: 0.7704067826271057   Validation Accuracy: 0.5181999206542969\n",
      "Epoch 90, CIFAR-10 Batch 3:  Loss: 0.796450674533844    Validation Accuracy: 0.5267999172210693\n",
      "Epoch 90, CIFAR-10 Batch 4:  Loss: 0.7422140836715698   Validation Accuracy: 0.514799952507019\n",
      "Epoch 90, CIFAR-10 Batch 5:  Loss: 0.7727718353271484   Validation Accuracy: 0.5227999091148376\n",
      "Epoch 91, CIFAR-10 Batch 1:  Loss: 0.7250686883926392   Validation Accuracy: 0.5148000121116638\n",
      "Epoch 91, CIFAR-10 Batch 2:  Loss: 0.7699491381645203   Validation Accuracy: 0.5195999145507812\n",
      "Epoch 91, CIFAR-10 Batch 3:  Loss: 0.7959492206573486   Validation Accuracy: 0.5179999470710754\n",
      "Epoch 91, CIFAR-10 Batch 4:  Loss: 0.7432115077972412   Validation Accuracy: 0.5207999348640442\n",
      "Epoch 91, CIFAR-10 Batch 5:  Loss: 0.7729558944702148   Validation Accuracy: 0.5219999551773071\n",
      "Epoch 92, CIFAR-10 Batch 1:  Loss: 0.7254078984260559   Validation Accuracy: 0.5139999389648438\n",
      "Epoch 92, CIFAR-10 Batch 2:  Loss: 0.7705012559890747   Validation Accuracy: 0.527199923992157\n",
      "Epoch 92, CIFAR-10 Batch 3:  Loss: 0.7964475154876709   Validation Accuracy: 0.5179999470710754\n",
      "Epoch 92, CIFAR-10 Batch 4:  Loss: 0.7437408566474915   Validation Accuracy: 0.5181999206542969\n",
      "Epoch 92, CIFAR-10 Batch 5:  Loss: 0.7734414935112      Validation Accuracy: 0.5251999497413635\n",
      "Epoch 93, CIFAR-10 Batch 1:  Loss: 0.7252700328826904   Validation Accuracy: 0.5155999660491943\n",
      "Epoch 93, CIFAR-10 Batch 2:  Loss: 0.7701812386512756   Validation Accuracy: 0.5215999484062195\n",
      "Epoch 93, CIFAR-10 Batch 3:  Loss: 0.7961359024047852   Validation Accuracy: 0.5163999795913696\n",
      "Epoch 93, CIFAR-10 Batch 4:  Loss: 0.7421609163284302   Validation Accuracy: 0.5131999850273132\n",
      "Epoch 93, CIFAR-10 Batch 5:  Loss: 0.7732776403427124   Validation Accuracy: 0.5219998955726624\n",
      "Epoch 94, CIFAR-10 Batch 1:  Loss: 0.7243079543113708   Validation Accuracy: 0.5077999234199524\n",
      "Epoch 94, CIFAR-10 Batch 2:  Loss: 0.7716616988182068   Validation Accuracy: 0.5251999497413635\n",
      "Epoch 94, CIFAR-10 Batch 3:  Loss: 0.7963590025901794   Validation Accuracy: 0.521399974822998\n",
      "Epoch 94, CIFAR-10 Batch 4:  Loss: 0.743670642375946    Validation Accuracy: 0.5137999653816223\n",
      "Epoch 94, CIFAR-10 Batch 5:  Loss: 0.7755696177482605   Validation Accuracy: 0.5231999158859253\n",
      "Epoch 95, CIFAR-10 Batch 1:  Loss: 0.7222983241081238   Validation Accuracy: 0.5209999680519104\n",
      "Epoch 95, CIFAR-10 Batch 2:  Loss: 0.770251452922821    Validation Accuracy: 0.5275999307632446\n",
      "Epoch 95, CIFAR-10 Batch 3:  Loss: 0.7960788607597351   Validation Accuracy: 0.5189999341964722\n",
      "Epoch 95, CIFAR-10 Batch 4:  Loss: 0.7420039176940918   Validation Accuracy: 0.517799973487854\n",
      "Epoch 95, CIFAR-10 Batch 5:  Loss: 0.7733410000801086   Validation Accuracy: 0.5219999551773071\n",
      "Epoch 96, CIFAR-10 Batch 1:  Loss: 0.7226914167404175   Validation Accuracy: 0.5181999206542969\n",
      "Epoch 96, CIFAR-10 Batch 2:  Loss: 0.7704458236694336   Validation Accuracy: 0.5263999700546265\n",
      "Epoch 96, CIFAR-10 Batch 3:  Loss: 0.7958401441574097   Validation Accuracy: 0.5230000019073486\n",
      "Epoch 96, CIFAR-10 Batch 4:  Loss: 0.7426667213439941   Validation Accuracy: 0.514799952507019\n",
      "Epoch 96, CIFAR-10 Batch 5:  Loss: 0.7735921144485474   Validation Accuracy: 0.5205999612808228\n",
      "Epoch 97, CIFAR-10 Batch 1:  Loss: 0.7223331928253174   Validation Accuracy: 0.5193999409675598\n",
      "Epoch 97, CIFAR-10 Batch 2:  Loss: 0.7703572511672974   Validation Accuracy: 0.5217999815940857\n",
      "Epoch 97, CIFAR-10 Batch 3:  Loss: 0.7961745858192444   Validation Accuracy: 0.5213999152183533\n",
      "Epoch 97, CIFAR-10 Batch 4:  Loss: 0.742928147315979    Validation Accuracy: 0.5089999437332153\n",
      "Epoch 97, CIFAR-10 Batch 5:  Loss: 0.7735260725021362   Validation Accuracy: 0.5229999423027039\n",
      "Epoch 98, CIFAR-10 Batch 1:  Loss: 0.7234649658203125   Validation Accuracy: 0.5171999335289001\n",
      "Epoch 98, CIFAR-10 Batch 2:  Loss: 0.7711231112480164   Validation Accuracy: 0.5247999429702759\n",
      "Epoch 98, CIFAR-10 Batch 3:  Loss: 0.795657217502594    Validation Accuracy: 0.5193999409675598\n",
      "Epoch 98, CIFAR-10 Batch 4:  Loss: 0.7422804832458496   Validation Accuracy: 0.5181999802589417\n",
      "Epoch 98, CIFAR-10 Batch 5:  Loss: 0.7729789614677429   Validation Accuracy: 0.5293999314308167\n",
      "Epoch 99, CIFAR-10 Batch 1:  Loss: 0.7250965237617493   Validation Accuracy: 0.5103999376296997\n",
      "Epoch 99, CIFAR-10 Batch 2:  Loss: 0.7706356048583984   Validation Accuracy: 0.5301998853683472\n",
      "Epoch 99, CIFAR-10 Batch 3:  Loss: 0.7968384027481079   Validation Accuracy: 0.5213999152183533\n",
      "Epoch 99, CIFAR-10 Batch 4:  Loss: 0.7434921860694885   Validation Accuracy: 0.5161999464035034\n",
      "Epoch 99, CIFAR-10 Batch 5:  Loss: 0.7737592458724976   Validation Accuracy: 0.5135999321937561\n",
      "Epoch 100, CIFAR-10 Batch 1:  Loss: 0.7263359427452087   Validation Accuracy: 0.5201999545097351\n",
      "Epoch 100, CIFAR-10 Batch 2:  Loss: 0.7707229256629944   Validation Accuracy: 0.5235999822616577\n",
      "Epoch 100, CIFAR-10 Batch 3:  Loss: 0.7979234457015991   Validation Accuracy: 0.5161999464035034\n",
      "Epoch 100, CIFAR-10 Batch 4:  Loss: 0.7420666813850403   Validation Accuracy: 0.5205999612808228\n",
      "Epoch 100, CIFAR-10 Batch 5:  Loss: 0.7733836770057678   Validation Accuracy: 0.5221999287605286\n",
      "Epoch 101, CIFAR-10 Batch 1:  Loss: 0.722247302532196    Validation Accuracy: 0.5235999822616577\n",
      "Epoch 101, CIFAR-10 Batch 2:  Loss: 0.7709969878196716   Validation Accuracy: 0.5237999558448792\n",
      "Epoch 101, CIFAR-10 Batch 3:  Loss: 0.7989494800567627   Validation Accuracy: 0.5145999193191528\n",
      "Epoch 101, CIFAR-10 Batch 4:  Loss: 0.7423904538154602   Validation Accuracy: 0.5195999145507812\n",
      "Epoch 101, CIFAR-10 Batch 5:  Loss: 0.7750360369682312   Validation Accuracy: 0.5153999924659729\n",
      "Epoch 102, CIFAR-10 Batch 1:  Loss: 0.7233428955078125   Validation Accuracy: 0.5109999179840088\n",
      "Epoch 102, CIFAR-10 Batch 2:  Loss: 0.7730398774147034   Validation Accuracy: 0.5163999795913696\n",
      "Epoch 102, CIFAR-10 Batch 3:  Loss: 0.7979221343994141   Validation Accuracy: 0.5209999680519104\n",
      "Epoch 102, CIFAR-10 Batch 4:  Loss: 0.7425535917282104   Validation Accuracy: 0.5181999802589417\n",
      "Epoch 102, CIFAR-10 Batch 5:  Loss: 0.773752748966217    Validation Accuracy: 0.5194000005722046\n",
      "Epoch 103, CIFAR-10 Batch 1:  Loss: 0.7228912711143494   Validation Accuracy: 0.5099999308586121\n",
      "Epoch 103, CIFAR-10 Batch 2:  Loss: 0.7709051966667175   Validation Accuracy: 0.5189999341964722\n",
      "Epoch 103, CIFAR-10 Batch 3:  Loss: 0.7963833808898926   Validation Accuracy: 0.5191999673843384\n",
      "Epoch 103, CIFAR-10 Batch 4:  Loss: 0.7424910068511963   Validation Accuracy: 0.5141999125480652\n",
      "Epoch 103, CIFAR-10 Batch 5:  Loss: 0.7734025716781616   Validation Accuracy: 0.5139999389648438\n",
      "Epoch 104, CIFAR-10 Batch 1:  Loss: 0.7238187789916992   Validation Accuracy: 0.5223999619483948\n",
      "Epoch 104, CIFAR-10 Batch 2:  Loss: 0.7729591131210327   Validation Accuracy: 0.5203999876976013\n",
      "Epoch 104, CIFAR-10 Batch 3:  Loss: 0.7996931076049805   Validation Accuracy: 0.5157999396324158\n",
      "Epoch 104, CIFAR-10 Batch 4:  Loss: 0.7411943674087524   Validation Accuracy: 0.5095999836921692\n",
      "Epoch 104, CIFAR-10 Batch 5:  Loss: 0.7721142172813416   Validation Accuracy: 0.5173999667167664\n",
      "Epoch 105, CIFAR-10 Batch 1:  Loss: 0.7238105535507202   Validation Accuracy: 0.5105999708175659\n",
      "Epoch 105, CIFAR-10 Batch 2:  Loss: 0.7709481716156006   Validation Accuracy: 0.5191999673843384\n",
      "Epoch 105, CIFAR-10 Batch 3:  Loss: 0.8002564907073975   Validation Accuracy: 0.5165999531745911\n",
      "Epoch 105, CIFAR-10 Batch 4:  Loss: 0.7469028234481812   Validation Accuracy: 0.506399929523468\n",
      "Epoch 105, CIFAR-10 Batch 5:  Loss: 0.772267758846283    Validation Accuracy: 0.5161999464035034\n",
      "Epoch 106, CIFAR-10 Batch 1:  Loss: 0.7231007218360901   Validation Accuracy: 0.5133999586105347\n",
      "Epoch 106, CIFAR-10 Batch 2:  Loss: 0.7727977633476257   Validation Accuracy: 0.5211999416351318\n",
      "Epoch 106, CIFAR-10 Batch 3:  Loss: 0.7969545125961304   Validation Accuracy: 0.5197999477386475\n",
      "Epoch 106, CIFAR-10 Batch 4:  Loss: 0.7414072751998901   Validation Accuracy: 0.511199951171875\n",
      "Epoch 106, CIFAR-10 Batch 5:  Loss: 0.7714088559150696   Validation Accuracy: 0.5231999158859253\n",
      "Epoch 107, CIFAR-10 Batch 1:  Loss: 0.7234861850738525   Validation Accuracy: 0.5137999057769775\n",
      "Epoch 107, CIFAR-10 Batch 2:  Loss: 0.7734336853027344   Validation Accuracy: 0.5257998704910278\n",
      "Epoch 107, CIFAR-10 Batch 3:  Loss: 0.797832727432251    Validation Accuracy: 0.5221999287605286\n",
      "Epoch 107, CIFAR-10 Batch 4:  Loss: 0.7468754053115845   Validation Accuracy: 0.4965999722480774\n",
      "Epoch 107, CIFAR-10 Batch 5:  Loss: 0.7754451036453247   Validation Accuracy: 0.5153999328613281\n",
      "Epoch 108, CIFAR-10 Batch 1:  Loss: 0.7232803106307983   Validation Accuracy: 0.5117999315261841\n",
      "Epoch 108, CIFAR-10 Batch 2:  Loss: 0.772476851940155    Validation Accuracy: 0.5207999348640442\n",
      "Epoch 108, CIFAR-10 Batch 3:  Loss: 0.7975489497184753   Validation Accuracy: 0.5125999450683594\n",
      "Epoch 108, CIFAR-10 Batch 4:  Loss: 0.7400845289230347   Validation Accuracy: 0.5123999714851379\n",
      "Epoch 108, CIFAR-10 Batch 5:  Loss: 0.772895097732544    Validation Accuracy: 0.5207999348640442\n",
      "Epoch 109, CIFAR-10 Batch 1:  Loss: 0.7274006009101868   Validation Accuracy: 0.5097999572753906\n",
      "Epoch 109, CIFAR-10 Batch 2:  Loss: 0.7721510529518127   Validation Accuracy: 0.5203999280929565\n",
      "Epoch 109, CIFAR-10 Batch 3:  Loss: 0.8022117018699646   Validation Accuracy: 0.52239990234375\n",
      "Epoch 109, CIFAR-10 Batch 4:  Loss: 0.7405426502227783   Validation Accuracy: 0.5143998861312866\n",
      "Epoch 109, CIFAR-10 Batch 5:  Loss: 0.7778423428535461   Validation Accuracy: 0.5177999138832092\n",
      "Epoch 110, CIFAR-10 Batch 1:  Loss: 0.7318679094314575   Validation Accuracy: 0.5095999240875244\n",
      "Epoch 110, CIFAR-10 Batch 2:  Loss: 0.7729921340942383   Validation Accuracy: 0.5167999267578125\n",
      "Epoch 110, CIFAR-10 Batch 3:  Loss: 0.7989881634712219   Validation Accuracy: 0.5231999158859253\n",
      "Epoch 110, CIFAR-10 Batch 4:  Loss: 0.746100902557373    Validation Accuracy: 0.5163999795913696\n",
      "Epoch 110, CIFAR-10 Batch 5:  Loss: 0.7745745778083801   Validation Accuracy: 0.5231999754905701\n",
      "Epoch 111, CIFAR-10 Batch 1:  Loss: 0.7236630916595459   Validation Accuracy: 0.5197999477386475\n",
      "Epoch 111, CIFAR-10 Batch 2:  Loss: 0.7685978412628174   Validation Accuracy: 0.5201999545097351\n",
      "Epoch 111, CIFAR-10 Batch 3:  Loss: 0.8006528615951538   Validation Accuracy: 0.5145999789237976\n",
      "Epoch 111, CIFAR-10 Batch 4:  Loss: 0.7397150993347168   Validation Accuracy: 0.5145999193191528\n",
      "Epoch 111, CIFAR-10 Batch 5:  Loss: 0.7725778818130493   Validation Accuracy: 0.5171999335289001\n",
      "Epoch 112, CIFAR-10 Batch 1:  Loss: 0.7244986891746521   Validation Accuracy: 0.5071999430656433\n",
      "Epoch 112, CIFAR-10 Batch 2:  Loss: 0.7695004940032959   Validation Accuracy: 0.5259999632835388\n",
      "Epoch 112, CIFAR-10 Batch 3:  Loss: 0.799797534942627    Validation Accuracy: 0.5223999619483948\n",
      "Epoch 112, CIFAR-10 Batch 4:  Loss: 0.7391372919082642   Validation Accuracy: 0.507599949836731\n",
      "Epoch 112, CIFAR-10 Batch 5:  Loss: 0.7731451392173767   Validation Accuracy: 0.5133999586105347\n",
      "Epoch 113, CIFAR-10 Batch 1:  Loss: 0.7220081090927124   Validation Accuracy: 0.5139999389648438\n",
      "Epoch 113, CIFAR-10 Batch 2:  Loss: 0.7715150117874146   Validation Accuracy: 0.5237999558448792\n",
      "Epoch 113, CIFAR-10 Batch 3:  Loss: 0.7966741323471069   Validation Accuracy: 0.5179999470710754\n",
      "Epoch 113, CIFAR-10 Batch 4:  Loss: 0.7441338300704956   Validation Accuracy: 0.5007999539375305\n",
      "Epoch 113, CIFAR-10 Batch 5:  Loss: 0.7720635533332825   Validation Accuracy: 0.5219999551773071\n",
      "Epoch 114, CIFAR-10 Batch 1:  Loss: 0.723143458366394    Validation Accuracy: 0.5065999627113342\n",
      "Epoch 114, CIFAR-10 Batch 2:  Loss: 0.7681332230567932   Validation Accuracy: 0.525399923324585\n",
      "Epoch 114, CIFAR-10 Batch 3:  Loss: 0.7984628081321716   Validation Accuracy: 0.5125999450683594\n",
      "Epoch 114, CIFAR-10 Batch 4:  Loss: 0.7436359524726868   Validation Accuracy: 0.511199951171875\n",
      "Epoch 114, CIFAR-10 Batch 5:  Loss: 0.7710911631584167   Validation Accuracy: 0.5225998759269714\n",
      "Epoch 115, CIFAR-10 Batch 1:  Loss: 0.7286376953125      Validation Accuracy: 0.5025999546051025\n",
      "Epoch 115, CIFAR-10 Batch 2:  Loss: 0.7695043087005615   Validation Accuracy: 0.5107999444007874\n",
      "Epoch 115, CIFAR-10 Batch 3:  Loss: 0.7967793941497803   Validation Accuracy: 0.5161999464035034\n",
      "Epoch 115, CIFAR-10 Batch 4:  Loss: 0.7396469712257385   Validation Accuracy: 0.5181999206542969\n",
      "Epoch 115, CIFAR-10 Batch 5:  Loss: 0.7680458426475525   Validation Accuracy: 0.5151999592781067\n",
      "Epoch 116, CIFAR-10 Batch 1:  Loss: 0.7240127921104431   Validation Accuracy: 0.5051999688148499\n",
      "Epoch 116, CIFAR-10 Batch 2:  Loss: 0.7690379619598389   Validation Accuracy: 0.5203999280929565\n",
      "Epoch 116, CIFAR-10 Batch 3:  Loss: 0.7984044551849365   Validation Accuracy: 0.5151999592781067\n",
      "Epoch 116, CIFAR-10 Batch 4:  Loss: 0.7484114170074463   Validation Accuracy: 0.4949999451637268\n",
      "Epoch 116, CIFAR-10 Batch 5:  Loss: 0.7895767688751221   Validation Accuracy: 0.4973999857902527\n",
      "Epoch 117, CIFAR-10 Batch 1:  Loss: 0.724452555179596    Validation Accuracy: 0.49619996547698975\n",
      "Epoch 117, CIFAR-10 Batch 2:  Loss: 0.7836382389068604   Validation Accuracy: 0.5123999714851379\n",
      "Epoch 117, CIFAR-10 Batch 3:  Loss: 0.796338677406311    Validation Accuracy: 0.518799901008606\n",
      "Epoch 117, CIFAR-10 Batch 4:  Loss: 0.7396240234375      Validation Accuracy: 0.5187999606132507\n",
      "Epoch 117, CIFAR-10 Batch 5:  Loss: 0.7773706912994385   Validation Accuracy: 0.512999951839447\n",
      "Epoch 118, CIFAR-10 Batch 1:  Loss: 0.7245544195175171   Validation Accuracy: 0.514799952507019\n",
      "Epoch 118, CIFAR-10 Batch 2:  Loss: 0.7682052254676819   Validation Accuracy: 0.5257999897003174\n",
      "Epoch 118, CIFAR-10 Batch 3:  Loss: 0.7960696220397949   Validation Accuracy: 0.515999972820282\n",
      "Epoch 118, CIFAR-10 Batch 4:  Loss: 0.7454796433448792   Validation Accuracy: 0.5144000053405762\n",
      "Epoch 118, CIFAR-10 Batch 5:  Loss: 0.7694923281669617   Validation Accuracy: 0.51419997215271\n",
      "Epoch 119, CIFAR-10 Batch 1:  Loss: 0.7221630811691284   Validation Accuracy: 0.5239999294281006\n",
      "Epoch 119, CIFAR-10 Batch 2:  Loss: 0.7684828639030457   Validation Accuracy: 0.5211999416351318\n",
      "Epoch 119, CIFAR-10 Batch 3:  Loss: 0.7941212058067322   Validation Accuracy: 0.5283999443054199\n",
      "Epoch 119, CIFAR-10 Batch 4:  Loss: 0.7394143342971802   Validation Accuracy: 0.5143998861312866\n",
      "Epoch 119, CIFAR-10 Batch 5:  Loss: 0.7671940922737122   Validation Accuracy: 0.5197999477386475\n",
      "Epoch 120, CIFAR-10 Batch 1:  Loss: 0.7231166362762451   Validation Accuracy: 0.5265999436378479\n",
      "Epoch 120, CIFAR-10 Batch 2:  Loss: 0.7677465677261353   Validation Accuracy: 0.519599974155426\n",
      "Epoch 120, CIFAR-10 Batch 3:  Loss: 0.7938113212585449   Validation Accuracy: 0.5219999551773071\n",
      "Epoch 120, CIFAR-10 Batch 4:  Loss: 0.739383339881897    Validation Accuracy: 0.5149999260902405\n",
      "Epoch 120, CIFAR-10 Batch 5:  Loss: 0.7670283317565918   Validation Accuracy: 0.5131999850273132\n",
      "Epoch 121, CIFAR-10 Batch 1:  Loss: 0.7259411811828613   Validation Accuracy: 0.511199951171875\n",
      "Epoch 121, CIFAR-10 Batch 2:  Loss: 0.7731798887252808   Validation Accuracy: 0.5179999470710754\n",
      "Epoch 121, CIFAR-10 Batch 3:  Loss: 0.7984208464622498   Validation Accuracy: 0.5175999402999878\n",
      "Epoch 121, CIFAR-10 Batch 4:  Loss: 0.7405475378036499   Validation Accuracy: 0.5099999904632568\n",
      "Epoch 121, CIFAR-10 Batch 5:  Loss: 0.7681016325950623   Validation Accuracy: 0.5135999321937561\n",
      "Epoch 122, CIFAR-10 Batch 1:  Loss: 0.7229604721069336   Validation Accuracy: 0.5133999586105347\n",
      "Epoch 122, CIFAR-10 Batch 2:  Loss: 0.7687676548957825   Validation Accuracy: 0.5153999328613281\n",
      "Epoch 122, CIFAR-10 Batch 3:  Loss: 0.7945798635482788   Validation Accuracy: 0.5247999429702759\n",
      "Epoch 122, CIFAR-10 Batch 4:  Loss: 0.7396678924560547   Validation Accuracy: 0.5097999572753906\n",
      "Epoch 122, CIFAR-10 Batch 5:  Loss: 0.7672507166862488   Validation Accuracy: 0.5235999822616577\n",
      "Epoch 123, CIFAR-10 Batch 1:  Loss: 0.7218241691589355   Validation Accuracy: 0.5065999627113342\n",
      "Epoch 123, CIFAR-10 Batch 2:  Loss: 0.7730706334114075   Validation Accuracy: 0.5149999856948853\n",
      "Epoch 123, CIFAR-10 Batch 3:  Loss: 0.7999238967895508   Validation Accuracy: 0.519599974155426\n",
      "Epoch 123, CIFAR-10 Batch 4:  Loss: 0.741398811340332    Validation Accuracy: 0.5025999546051025\n",
      "Epoch 123, CIFAR-10 Batch 5:  Loss: 0.768552303314209    Validation Accuracy: 0.5183999538421631\n",
      "Epoch 124, CIFAR-10 Batch 1:  Loss: 0.7236292362213135   Validation Accuracy: 0.5123999714851379\n",
      "Epoch 124, CIFAR-10 Batch 2:  Loss: 0.7704046368598938   Validation Accuracy: 0.5173999667167664\n",
      "Epoch 124, CIFAR-10 Batch 3:  Loss: 0.7915038466453552   Validation Accuracy: 0.5225999355316162\n",
      "Epoch 124, CIFAR-10 Batch 4:  Loss: 0.7403290867805481   Validation Accuracy: 0.4949999749660492\n",
      "Epoch 124, CIFAR-10 Batch 5:  Loss: 0.769325852394104    Validation Accuracy: 0.5187999606132507\n",
      "Epoch 125, CIFAR-10 Batch 1:  Loss: 0.7228742241859436   Validation Accuracy: 0.5127999782562256\n",
      "Epoch 125, CIFAR-10 Batch 2:  Loss: 0.7705715894699097   Validation Accuracy: 0.5107999444007874\n",
      "Epoch 125, CIFAR-10 Batch 3:  Loss: 0.7937650680541992   Validation Accuracy: 0.5303998589515686\n",
      "Epoch 125, CIFAR-10 Batch 4:  Loss: 0.7416803240776062   Validation Accuracy: 0.49919992685317993\n",
      "Epoch 125, CIFAR-10 Batch 5:  Loss: 0.7672359943389893   Validation Accuracy: 0.5249999761581421\n",
      "Epoch 126, CIFAR-10 Batch 1:  Loss: 0.7221429944038391   Validation Accuracy: 0.5083999633789062\n",
      "Epoch 126, CIFAR-10 Batch 2:  Loss: 0.7674898505210876   Validation Accuracy: 0.512199878692627\n",
      "Epoch 126, CIFAR-10 Batch 3:  Loss: 0.7920371294021606   Validation Accuracy: 0.5230000019073486\n",
      "Epoch 126, CIFAR-10 Batch 4:  Loss: 0.7394036054611206   Validation Accuracy: 0.5105999708175659\n",
      "Epoch 126, CIFAR-10 Batch 5:  Loss: 0.7679517269134521   Validation Accuracy: 0.517799973487854\n",
      "Epoch 127, CIFAR-10 Batch 1:  Loss: 0.723351240158081    Validation Accuracy: 0.5113999247550964\n",
      "Epoch 127, CIFAR-10 Batch 2:  Loss: 0.7707697153091431   Validation Accuracy: 0.5087999701499939\n",
      "Epoch 127, CIFAR-10 Batch 3:  Loss: 0.7927159070968628   Validation Accuracy: 0.5307999849319458\n",
      "Epoch 127, CIFAR-10 Batch 4:  Loss: 0.7412079572677612   Validation Accuracy: 0.5001999139785767\n",
      "Epoch 127, CIFAR-10 Batch 5:  Loss: 0.7684398889541626   Validation Accuracy: 0.5271999835968018\n",
      "Epoch 128, CIFAR-10 Batch 1:  Loss: 0.7241213321685791   Validation Accuracy: 0.5039999485015869\n",
      "Epoch 128, CIFAR-10 Batch 2:  Loss: 0.7670639753341675   Validation Accuracy: 0.5179999470710754\n",
      "Epoch 128, CIFAR-10 Batch 3:  Loss: 0.7925800085067749   Validation Accuracy: 0.5197999477386475\n",
      "Epoch 128, CIFAR-10 Batch 4:  Loss: 0.7442338466644287   Validation Accuracy: 0.506399929523468\n",
      "Epoch 128, CIFAR-10 Batch 5:  Loss: 0.7686215043067932   Validation Accuracy: 0.5155999064445496\n",
      "Epoch 129, CIFAR-10 Batch 1:  Loss: 0.7224189043045044   Validation Accuracy: 0.5143999457359314\n",
      "Epoch 129, CIFAR-10 Batch 2:  Loss: 0.7674293518066406   Validation Accuracy: 0.5175999402999878\n",
      "Epoch 129, CIFAR-10 Batch 3:  Loss: 0.7899712920188904   Validation Accuracy: 0.5261999368667603\n",
      "Epoch 129, CIFAR-10 Batch 4:  Loss: 0.7400383949279785   Validation Accuracy: 0.5121999382972717\n",
      "Epoch 129, CIFAR-10 Batch 5:  Loss: 0.7671352028846741   Validation Accuracy: 0.522599995136261\n",
      "Epoch 130, CIFAR-10 Batch 1:  Loss: 0.7221643924713135   Validation Accuracy: 0.519399881362915\n",
      "Epoch 130, CIFAR-10 Batch 2:  Loss: 0.7681633234024048   Validation Accuracy: 0.5149999260902405\n",
      "Epoch 130, CIFAR-10 Batch 3:  Loss: 0.7905223369598389   Validation Accuracy: 0.517799973487854\n",
      "Epoch 130, CIFAR-10 Batch 4:  Loss: 0.7411084771156311   Validation Accuracy: 0.49939996004104614\n",
      "Epoch 130, CIFAR-10 Batch 5:  Loss: 0.7689201235771179   Validation Accuracy: 0.5191999077796936\n",
      "Epoch 131, CIFAR-10 Batch 1:  Loss: 0.7232339382171631   Validation Accuracy: 0.5149999260902405\n",
      "Epoch 131, CIFAR-10 Batch 2:  Loss: 0.7693818807601929   Validation Accuracy: 0.5099999308586121\n",
      "Epoch 131, CIFAR-10 Batch 3:  Loss: 0.7930707931518555   Validation Accuracy: 0.517799973487854\n",
      "Epoch 131, CIFAR-10 Batch 4:  Loss: 0.7384922504425049   Validation Accuracy: 0.5124000310897827\n",
      "Epoch 131, CIFAR-10 Batch 5:  Loss: 0.7675182819366455   Validation Accuracy: 0.5175999402999878\n",
      "Epoch 132, CIFAR-10 Batch 1:  Loss: 0.7243711948394775   Validation Accuracy: 0.5184000134468079\n",
      "Epoch 132, CIFAR-10 Batch 2:  Loss: 0.7669869065284729   Validation Accuracy: 0.51419997215271\n",
      "Epoch 132, CIFAR-10 Batch 3:  Loss: 0.7896050810813904   Validation Accuracy: 0.5234000086784363\n",
      "Epoch 132, CIFAR-10 Batch 4:  Loss: 0.7386699318885803   Validation Accuracy: 0.5165999531745911\n",
      "Epoch 132, CIFAR-10 Batch 5:  Loss: 0.7675960063934326   Validation Accuracy: 0.5127999782562256\n",
      "Epoch 133, CIFAR-10 Batch 1:  Loss: 0.7202534079551697   Validation Accuracy: 0.5213999152183533\n",
      "Epoch 133, CIFAR-10 Batch 2:  Loss: 0.7686477899551392   Validation Accuracy: 0.5123999118804932\n",
      "Epoch 133, CIFAR-10 Batch 3:  Loss: 0.7900586128234863   Validation Accuracy: 0.5203999280929565\n",
      "Epoch 133, CIFAR-10 Batch 4:  Loss: 0.7400527596473694   Validation Accuracy: 0.5171999335289001\n",
      "Epoch 133, CIFAR-10 Batch 5:  Loss: 0.7678312063217163   Validation Accuracy: 0.50819993019104\n",
      "Epoch 134, CIFAR-10 Batch 1:  Loss: 0.7214937806129456   Validation Accuracy: 0.5105999112129211\n",
      "Epoch 134, CIFAR-10 Batch 2:  Loss: 0.7679817080497742   Validation Accuracy: 0.5125999450683594\n",
      "Epoch 134, CIFAR-10 Batch 3:  Loss: 0.7905760407447815   Validation Accuracy: 0.5149999260902405\n",
      "Epoch 134, CIFAR-10 Batch 4:  Loss: 0.7400388121604919   Validation Accuracy: 0.5175999402999878\n",
      "Epoch 134, CIFAR-10 Batch 5:  Loss: 0.7675235271453857   Validation Accuracy: 0.5105999112129211\n",
      "Epoch 135, CIFAR-10 Batch 1:  Loss: 0.7189221382141113   Validation Accuracy: 0.517799973487854\n",
      "Epoch 135, CIFAR-10 Batch 2:  Loss: 0.7680304050445557   Validation Accuracy: 0.5097999572753906\n",
      "Epoch 135, CIFAR-10 Batch 3:  Loss: 0.7906396985054016   Validation Accuracy: 0.5241999626159668\n",
      "Epoch 135, CIFAR-10 Batch 4:  Loss: 0.7384507656097412   Validation Accuracy: 0.5097999572753906\n",
      "Epoch 135, CIFAR-10 Batch 5:  Loss: 0.7671250104904175   Validation Accuracy: 0.5051999688148499\n",
      "Epoch 136, CIFAR-10 Batch 1:  Loss: 0.720618724822998    Validation Accuracy: 0.5083999633789062\n",
      "Epoch 136, CIFAR-10 Batch 2:  Loss: 0.7671257257461548   Validation Accuracy: 0.5179999470710754\n",
      "Epoch 136, CIFAR-10 Batch 3:  Loss: 0.7896378040313721   Validation Accuracy: 0.5189999341964722\n",
      "Epoch 136, CIFAR-10 Batch 4:  Loss: 0.7388623356819153   Validation Accuracy: 0.5163999795913696\n",
      "Epoch 136, CIFAR-10 Batch 5:  Loss: 0.7670224905014038   Validation Accuracy: 0.5069999694824219\n",
      "Epoch 137, CIFAR-10 Batch 1:  Loss: 0.7189969420433044   Validation Accuracy: 0.5139999389648438\n",
      "Epoch 137, CIFAR-10 Batch 2:  Loss: 0.7673841714859009   Validation Accuracy: 0.5131999254226685\n",
      "Epoch 137, CIFAR-10 Batch 3:  Loss: 0.7903748154640198   Validation Accuracy: 0.5201999545097351\n",
      "Epoch 137, CIFAR-10 Batch 4:  Loss: 0.7395314574241638   Validation Accuracy: 0.5043999552726746\n",
      "Epoch 137, CIFAR-10 Batch 5:  Loss: 0.7669336795806885   Validation Accuracy: 0.5207999348640442\n",
      "Epoch 138, CIFAR-10 Batch 1:  Loss: 0.7187880277633667   Validation Accuracy: 0.507599949836731\n",
      "Epoch 138, CIFAR-10 Batch 2:  Loss: 0.7668692469596863   Validation Accuracy: 0.5131999850273132\n",
      "Epoch 138, CIFAR-10 Batch 3:  Loss: 0.7906351685523987   Validation Accuracy: 0.5153999328613281\n",
      "Epoch 138, CIFAR-10 Batch 4:  Loss: 0.7445465922355652   Validation Accuracy: 0.5075998902320862\n",
      "Epoch 138, CIFAR-10 Batch 5:  Loss: 0.7648166418075562   Validation Accuracy: 0.5117999315261841\n",
      "Epoch 139, CIFAR-10 Batch 1:  Loss: 0.7200040221214294   Validation Accuracy: 0.5183999538421631\n",
      "Epoch 139, CIFAR-10 Batch 2:  Loss: 0.7687032222747803   Validation Accuracy: 0.504599928855896\n",
      "Epoch 139, CIFAR-10 Batch 3:  Loss: 0.7921204566955566   Validation Accuracy: 0.5193999409675598\n",
      "Epoch 139, CIFAR-10 Batch 4:  Loss: 0.739788293838501    Validation Accuracy: 0.5023999214172363\n",
      "Epoch 139, CIFAR-10 Batch 5:  Loss: 0.76764976978302     Validation Accuracy: 0.514799952507019\n",
      "Epoch 140, CIFAR-10 Batch 1:  Loss: 0.719823956489563    Validation Accuracy: 0.502799928188324\n",
      "Epoch 140, CIFAR-10 Batch 2:  Loss: 0.769280195236206    Validation Accuracy: 0.5007999539375305\n",
      "Epoch 140, CIFAR-10 Batch 3:  Loss: 0.7900527119636536   Validation Accuracy: 0.5221999883651733\n",
      "Epoch 140, CIFAR-10 Batch 4:  Loss: 0.7395075559616089   Validation Accuracy: 0.5005999803543091\n",
      "Epoch 140, CIFAR-10 Batch 5:  Loss: 0.7691390514373779   Validation Accuracy: 0.5127999186515808\n",
      "Epoch 141, CIFAR-10 Batch 1:  Loss: 0.7240079045295715   Validation Accuracy: 0.5165999531745911\n",
      "Epoch 141, CIFAR-10 Batch 2:  Loss: 0.7688307762145996   Validation Accuracy: 0.5054000020027161\n",
      "Epoch 141, CIFAR-10 Batch 3:  Loss: 0.7905282378196716   Validation Accuracy: 0.5203999280929565\n",
      "Epoch 141, CIFAR-10 Batch 4:  Loss: 0.7392017841339111   Validation Accuracy: 0.5057999491691589\n",
      "Epoch 141, CIFAR-10 Batch 5:  Loss: 0.7683057188987732   Validation Accuracy: 0.5071999430656433\n",
      "Epoch 142, CIFAR-10 Batch 1:  Loss: 0.7193493247032166   Validation Accuracy: 0.5091999769210815\n",
      "Epoch 142, CIFAR-10 Batch 2:  Loss: 0.7674935460090637   Validation Accuracy: 0.5079999566078186\n",
      "Epoch 142, CIFAR-10 Batch 3:  Loss: 0.7904989719390869   Validation Accuracy: 0.5194000005722046\n",
      "Epoch 142, CIFAR-10 Batch 4:  Loss: 0.7413532733917236   Validation Accuracy: 0.5021999478340149\n",
      "Epoch 142, CIFAR-10 Batch 5:  Loss: 0.7682983875274658   Validation Accuracy: 0.5087999105453491\n",
      "Epoch 143, CIFAR-10 Batch 1:  Loss: 0.7195703387260437   Validation Accuracy: 0.5091999173164368\n",
      "Epoch 143, CIFAR-10 Batch 2:  Loss: 0.7700565457344055   Validation Accuracy: 0.5031999349594116\n",
      "Epoch 143, CIFAR-10 Batch 3:  Loss: 0.7911617159843445   Validation Accuracy: 0.5145999789237976\n",
      "Epoch 143, CIFAR-10 Batch 4:  Loss: 0.7388102412223816   Validation Accuracy: 0.4983999729156494\n",
      "Epoch 143, CIFAR-10 Batch 5:  Loss: 0.7690432667732239   Validation Accuracy: 0.5115999579429626\n",
      "Epoch 144, CIFAR-10 Batch 1:  Loss: 0.7198889255523682   Validation Accuracy: 0.5031999349594116\n",
      "Epoch 144, CIFAR-10 Batch 2:  Loss: 0.769123375415802    Validation Accuracy: 0.5145999193191528\n",
      "Epoch 144, CIFAR-10 Batch 3:  Loss: 0.7907456159591675   Validation Accuracy: 0.5113999247550964\n",
      "Epoch 144, CIFAR-10 Batch 4:  Loss: 0.7390104532241821   Validation Accuracy: 0.5083999633789062\n",
      "Epoch 144, CIFAR-10 Batch 5:  Loss: 0.7672386169433594   Validation Accuracy: 0.5115999579429626\n",
      "Epoch 145, CIFAR-10 Batch 1:  Loss: 0.7205308079719543   Validation Accuracy: 0.5063999891281128\n",
      "Epoch 145, CIFAR-10 Batch 2:  Loss: 0.7706305980682373   Validation Accuracy: 0.5071999430656433\n",
      "Epoch 145, CIFAR-10 Batch 3:  Loss: 0.790338933467865    Validation Accuracy: 0.5191999673843384\n",
      "Epoch 145, CIFAR-10 Batch 4:  Loss: 0.738752543926239    Validation Accuracy: 0.5063999891281128\n",
      "Epoch 145, CIFAR-10 Batch 5:  Loss: 0.7699903249740601   Validation Accuracy: 0.5109999179840088\n",
      "Epoch 146, CIFAR-10 Batch 1:  Loss: 0.7243900299072266   Validation Accuracy: 0.5149999856948853\n",
      "Epoch 146, CIFAR-10 Batch 2:  Loss: 0.7708113789558411   Validation Accuracy: 0.5043998956680298\n",
      "Epoch 146, CIFAR-10 Batch 3:  Loss: 0.7924926280975342   Validation Accuracy: 0.5191999673843384\n",
      "Epoch 146, CIFAR-10 Batch 4:  Loss: 0.7402920722961426   Validation Accuracy: 0.5153999328613281\n",
      "Epoch 146, CIFAR-10 Batch 5:  Loss: 0.7731533646583557   Validation Accuracy: 0.5089999437332153\n",
      "Epoch 147, CIFAR-10 Batch 1:  Loss: 0.7230693101882935   Validation Accuracy: 0.5165998935699463\n",
      "Epoch 147, CIFAR-10 Batch 2:  Loss: 0.7692589163780212   Validation Accuracy: 0.511199951171875\n",
      "Epoch 147, CIFAR-10 Batch 3:  Loss: 0.7902676463127136   Validation Accuracy: 0.524399995803833\n",
      "Epoch 147, CIFAR-10 Batch 4:  Loss: 0.7390048503875732   Validation Accuracy: 0.5083999633789062\n",
      "Epoch 147, CIFAR-10 Batch 5:  Loss: 0.7676420211791992   Validation Accuracy: 0.50819993019104\n",
      "Epoch 148, CIFAR-10 Batch 1:  Loss: 0.7195019125938416   Validation Accuracy: 0.5057999491691589\n",
      "Epoch 148, CIFAR-10 Batch 2:  Loss: 0.7676147222518921   Validation Accuracy: 0.5119999647140503\n",
      "Epoch 148, CIFAR-10 Batch 3:  Loss: 0.7944940328598022   Validation Accuracy: 0.5199999809265137\n",
      "Epoch 148, CIFAR-10 Batch 4:  Loss: 0.7405045628547668   Validation Accuracy: 0.5099999904632568\n",
      "Epoch 148, CIFAR-10 Batch 5:  Loss: 0.7673296928405762   Validation Accuracy: 0.5161999464035034\n",
      "Epoch 149, CIFAR-10 Batch 1:  Loss: 0.7191092371940613   Validation Accuracy: 0.5113999247550964\n",
      "Epoch 149, CIFAR-10 Batch 2:  Loss: 0.7709846496582031   Validation Accuracy: 0.5021999478340149\n",
      "Epoch 149, CIFAR-10 Batch 3:  Loss: 0.7910556793212891   Validation Accuracy: 0.5233999490737915\n",
      "Epoch 149, CIFAR-10 Batch 4:  Loss: 0.7418091297149658   Validation Accuracy: 0.507599949836731\n",
      "Epoch 149, CIFAR-10 Batch 5:  Loss: 0.7687219977378845   Validation Accuracy: 0.5103999376296997\n",
      "Epoch 150, CIFAR-10 Batch 1:  Loss: 0.7186102867126465   Validation Accuracy: 0.5215999484062195\n",
      "Epoch 150, CIFAR-10 Batch 2:  Loss: 0.7690484523773193   Validation Accuracy: 0.5083999037742615\n",
      "Epoch 150, CIFAR-10 Batch 3:  Loss: 0.7899852991104126   Validation Accuracy: 0.5203999280929565\n",
      "Epoch 150, CIFAR-10 Batch 4:  Loss: 0.7385535836219788   Validation Accuracy: 0.5003999471664429\n",
      "Epoch 150, CIFAR-10 Batch 5:  Loss: 0.7680848836898804   Validation Accuracy: 0.5157999992370605\n",
      "Epoch 151, CIFAR-10 Batch 1:  Loss: 0.7197601795196533   Validation Accuracy: 0.5043998956680298\n",
      "Epoch 151, CIFAR-10 Batch 2:  Loss: 0.7681903839111328   Validation Accuracy: 0.5077999234199524\n",
      "Epoch 151, CIFAR-10 Batch 3:  Loss: 0.7889419794082642   Validation Accuracy: 0.5181999206542969\n",
      "Epoch 151, CIFAR-10 Batch 4:  Loss: 0.7392160296440125   Validation Accuracy: 0.5067999362945557\n",
      "Epoch 151, CIFAR-10 Batch 5:  Loss: 0.7684869766235352   Validation Accuracy: 0.5094000101089478\n",
      "Epoch 152, CIFAR-10 Batch 1:  Loss: 0.7200620174407959   Validation Accuracy: 0.5065999627113342\n",
      "Epoch 152, CIFAR-10 Batch 2:  Loss: 0.7671526074409485   Validation Accuracy: 0.5107999444007874\n",
      "Epoch 152, CIFAR-10 Batch 3:  Loss: 0.7924013733863831   Validation Accuracy: 0.5113999247550964\n",
      "Epoch 152, CIFAR-10 Batch 4:  Loss: 0.7385177612304688   Validation Accuracy: 0.5135999321937561\n",
      "Epoch 152, CIFAR-10 Batch 5:  Loss: 0.7700400948524475   Validation Accuracy: 0.504599928855896\n",
      "Epoch 153, CIFAR-10 Batch 1:  Loss: 0.7206994295120239   Validation Accuracy: 0.5119999647140503\n",
      "Epoch 153, CIFAR-10 Batch 2:  Loss: 0.7668195962905884   Validation Accuracy: 0.5097999572753906\n",
      "Epoch 153, CIFAR-10 Batch 3:  Loss: 0.7911407351493835   Validation Accuracy: 0.5097999572753906\n",
      "Epoch 153, CIFAR-10 Batch 4:  Loss: 0.7407765984535217   Validation Accuracy: 0.5067999362945557\n",
      "Epoch 153, CIFAR-10 Batch 5:  Loss: 0.7716248631477356   Validation Accuracy: 0.4981999695301056\n",
      "Epoch 154, CIFAR-10 Batch 1:  Loss: 0.7219910025596619   Validation Accuracy: 0.512999951839447\n",
      "Epoch 154, CIFAR-10 Batch 2:  Loss: 0.771552562713623    Validation Accuracy: 0.4989998936653137\n",
      "Epoch 154, CIFAR-10 Batch 3:  Loss: 0.7878596186637878   Validation Accuracy: 0.5125999450683594\n",
      "Epoch 154, CIFAR-10 Batch 4:  Loss: 0.7383632659912109   Validation Accuracy: 0.5049999356269836\n",
      "Epoch 154, CIFAR-10 Batch 5:  Loss: 0.7708953022956848   Validation Accuracy: 0.5076000094413757\n",
      "Epoch 155, CIFAR-10 Batch 1:  Loss: 0.7197810411453247   Validation Accuracy: 0.5079999566078186\n",
      "Epoch 155, CIFAR-10 Batch 2:  Loss: 0.7692587375640869   Validation Accuracy: 0.5039999485015869\n",
      "Epoch 155, CIFAR-10 Batch 3:  Loss: 0.7907727956771851   Validation Accuracy: 0.5099999308586121\n",
      "Epoch 155, CIFAR-10 Batch 4:  Loss: 0.7384331822395325   Validation Accuracy: 0.5105999708175659\n",
      "Epoch 155, CIFAR-10 Batch 5:  Loss: 0.7685545682907104   Validation Accuracy: 0.5025999546051025\n",
      "Epoch 156, CIFAR-10 Batch 1:  Loss: 0.7192962169647217   Validation Accuracy: 0.5147998929023743\n",
      "Epoch 156, CIFAR-10 Batch 2:  Loss: 0.7681692242622375   Validation Accuracy: 0.5087999701499939\n",
      "Epoch 156, CIFAR-10 Batch 3:  Loss: 0.7938764691352844   Validation Accuracy: 0.5144000053405762\n",
      "Epoch 156, CIFAR-10 Batch 4:  Loss: 0.7399446964263916   Validation Accuracy: 0.5053999423980713\n",
      "Epoch 156, CIFAR-10 Batch 5:  Loss: 0.7758823037147522   Validation Accuracy: 0.49959996342658997\n",
      "Epoch 157, CIFAR-10 Batch 1:  Loss: 0.7196323275566101   Validation Accuracy: 0.5137999057769775\n",
      "Epoch 157, CIFAR-10 Batch 2:  Loss: 0.7727193832397461   Validation Accuracy: 0.5001999139785767\n",
      "Epoch 157, CIFAR-10 Batch 3:  Loss: 0.7894229292869568   Validation Accuracy: 0.5167999267578125\n",
      "Epoch 157, CIFAR-10 Batch 4:  Loss: 0.7456580400466919   Validation Accuracy: 0.49379998445510864\n",
      "Epoch 157, CIFAR-10 Batch 5:  Loss: 0.7792708873748779   Validation Accuracy: 0.49699997901916504\n",
      "Epoch 158, CIFAR-10 Batch 1:  Loss: 0.7288751602172852   Validation Accuracy: 0.5109999179840088\n",
      "Epoch 158, CIFAR-10 Batch 2:  Loss: 0.7680684328079224   Validation Accuracy: 0.5077999830245972\n",
      "Epoch 158, CIFAR-10 Batch 3:  Loss: 0.7894924283027649   Validation Accuracy: 0.5123999714851379\n",
      "Epoch 158, CIFAR-10 Batch 4:  Loss: 0.7393429279327393   Validation Accuracy: 0.5191999077796936\n",
      "Epoch 158, CIFAR-10 Batch 5:  Loss: 0.7684191465377808   Validation Accuracy: 0.5037999749183655\n",
      "Epoch 159, CIFAR-10 Batch 1:  Loss: 0.7259072065353394   Validation Accuracy: 0.5130000114440918\n",
      "Epoch 159, CIFAR-10 Batch 2:  Loss: 0.7691382169723511   Validation Accuracy: 0.5039999485015869\n",
      "Epoch 159, CIFAR-10 Batch 3:  Loss: 0.7887320518493652   Validation Accuracy: 0.5095999240875244\n",
      "Epoch 159, CIFAR-10 Batch 4:  Loss: 0.7423626780509949   Validation Accuracy: 0.5095999240875244\n",
      "Epoch 159, CIFAR-10 Batch 5:  Loss: 0.7680407166481018   Validation Accuracy: 0.4995999336242676\n",
      "Epoch 160, CIFAR-10 Batch 1:  Loss: 0.7205950617790222   Validation Accuracy: 0.5125999450683594\n",
      "Epoch 160, CIFAR-10 Batch 2:  Loss: 0.7800236344337463   Validation Accuracy: 0.49939996004104614\n",
      "Epoch 160, CIFAR-10 Batch 3:  Loss: 0.7889438271522522   Validation Accuracy: 0.5065999627113342\n",
      "Epoch 160, CIFAR-10 Batch 4:  Loss: 0.7414392232894897   Validation Accuracy: 0.5001999735832214\n",
      "Epoch 160, CIFAR-10 Batch 5:  Loss: 0.7737932801246643   Validation Accuracy: 0.5079999566078186\n",
      "Epoch 161, CIFAR-10 Batch 1:  Loss: 0.7220837473869324   Validation Accuracy: 0.5047999620437622\n",
      "Epoch 161, CIFAR-10 Batch 2:  Loss: 0.7684847712516785   Validation Accuracy: 0.5013999342918396\n",
      "Epoch 161, CIFAR-10 Batch 3:  Loss: 0.7930722832679749   Validation Accuracy: 0.5213999152183533\n",
      "Epoch 161, CIFAR-10 Batch 4:  Loss: 0.7397207021713257   Validation Accuracy: 0.4975999593734741\n",
      "Epoch 161, CIFAR-10 Batch 5:  Loss: 0.7679072022438049   Validation Accuracy: 0.5035999417304993\n",
      "Epoch 162, CIFAR-10 Batch 1:  Loss: 0.7185075283050537   Validation Accuracy: 0.509399950504303\n",
      "Epoch 162, CIFAR-10 Batch 2:  Loss: 0.7695794105529785   Validation Accuracy: 0.5089999437332153\n",
      "Epoch 162, CIFAR-10 Batch 3:  Loss: 0.7899736762046814   Validation Accuracy: 0.5231999158859253\n",
      "Epoch 162, CIFAR-10 Batch 4:  Loss: 0.7417944669723511   Validation Accuracy: 0.4975999593734741\n",
      "Epoch 162, CIFAR-10 Batch 5:  Loss: 0.7672222852706909   Validation Accuracy: 0.5071999430656433\n",
      "Epoch 163, CIFAR-10 Batch 1:  Loss: 0.7195946574211121   Validation Accuracy: 0.509399950504303\n",
      "Epoch 163, CIFAR-10 Batch 2:  Loss: 0.7681142687797546   Validation Accuracy: 0.5089999437332153\n",
      "Epoch 163, CIFAR-10 Batch 3:  Loss: 0.7883014678955078   Validation Accuracy: 0.5167999267578125\n",
      "Epoch 163, CIFAR-10 Batch 4:  Loss: 0.7435898184776306   Validation Accuracy: 0.4931999742984772\n",
      "Epoch 163, CIFAR-10 Batch 5:  Loss: 0.7674226760864258   Validation Accuracy: 0.5133999586105347\n",
      "Epoch 164, CIFAR-10 Batch 1:  Loss: 0.7236417531967163   Validation Accuracy: 0.49779993295669556\n",
      "Epoch 164, CIFAR-10 Batch 2:  Loss: 0.7710264921188354   Validation Accuracy: 0.5103999376296997\n",
      "Epoch 164, CIFAR-10 Batch 3:  Loss: 0.7890812158584595   Validation Accuracy: 0.5141999125480652\n",
      "Epoch 164, CIFAR-10 Batch 4:  Loss: 0.741848886013031    Validation Accuracy: 0.5067999362945557\n",
      "Epoch 164, CIFAR-10 Batch 5:  Loss: 0.7654102444648743   Validation Accuracy: 0.509399950504303\n",
      "Epoch 165, CIFAR-10 Batch 1:  Loss: 0.7360284328460693   Validation Accuracy: 0.5011999607086182\n",
      "Epoch 165, CIFAR-10 Batch 2:  Loss: 0.7758949995040894   Validation Accuracy: 0.5065999031066895\n",
      "Epoch 165, CIFAR-10 Batch 3:  Loss: 0.7877864241600037   Validation Accuracy: 0.5029999613761902\n",
      "Epoch 165, CIFAR-10 Batch 4:  Loss: 0.7405945062637329   Validation Accuracy: 0.5059999823570251\n",
      "Epoch 165, CIFAR-10 Batch 5:  Loss: 0.7694284915924072   Validation Accuracy: 0.4975999593734741\n",
      "Epoch 166, CIFAR-10 Batch 1:  Loss: 0.7192764282226562   Validation Accuracy: 0.5085999965667725\n",
      "Epoch 166, CIFAR-10 Batch 2:  Loss: 0.7669456601142883   Validation Accuracy: 0.5041999816894531\n",
      "Epoch 166, CIFAR-10 Batch 3:  Loss: 0.7867063879966736   Validation Accuracy: 0.5179999470710754\n",
      "Epoch 166, CIFAR-10 Batch 4:  Loss: 0.7385553121566772   Validation Accuracy: 0.5183999538421631\n",
      "Epoch 166, CIFAR-10 Batch 5:  Loss: 0.7707523703575134   Validation Accuracy: 0.5003999471664429\n",
      "Epoch 167, CIFAR-10 Batch 1:  Loss: 0.7193042039871216   Validation Accuracy: 0.5145999789237976\n",
      "Epoch 167, CIFAR-10 Batch 2:  Loss: 0.7682129740715027   Validation Accuracy: 0.5085999965667725\n",
      "Epoch 167, CIFAR-10 Batch 3:  Loss: 0.7892652750015259   Validation Accuracy: 0.5097999572753906\n",
      "Epoch 167, CIFAR-10 Batch 4:  Loss: 0.7391809821128845   Validation Accuracy: 0.5121999979019165\n",
      "Epoch 167, CIFAR-10 Batch 5:  Loss: 0.7709134221076965   Validation Accuracy: 0.499799907207489\n",
      "Epoch 168, CIFAR-10 Batch 1:  Loss: 0.7196760177612305   Validation Accuracy: 0.4989999830722809\n",
      "Epoch 168, CIFAR-10 Batch 2:  Loss: 0.7673255801200867   Validation Accuracy: 0.5079998970031738\n",
      "Epoch 168, CIFAR-10 Batch 3:  Loss: 0.7868082523345947   Validation Accuracy: 0.5043998956680298\n",
      "Epoch 168, CIFAR-10 Batch 4:  Loss: 0.7385234832763672   Validation Accuracy: 0.5037999749183655\n",
      "Epoch 168, CIFAR-10 Batch 5:  Loss: 0.7673507928848267   Validation Accuracy: 0.49719998240470886\n",
      "Epoch 169, CIFAR-10 Batch 1:  Loss: 0.7217552661895752   Validation Accuracy: 0.5073999762535095\n",
      "Epoch 169, CIFAR-10 Batch 2:  Loss: 0.768343985080719    Validation Accuracy: 0.5043999552726746\n",
      "Epoch 169, CIFAR-10 Batch 3:  Loss: 0.789855420589447    Validation Accuracy: 0.5005999803543091\n",
      "Epoch 169, CIFAR-10 Batch 4:  Loss: 0.7390428185462952   Validation Accuracy: 0.5165999531745911\n",
      "Epoch 169, CIFAR-10 Batch 5:  Loss: 0.7667178511619568   Validation Accuracy: 0.5125999450683594\n",
      "Epoch 170, CIFAR-10 Batch 1:  Loss: 0.7211759090423584   Validation Accuracy: 0.5073999762535095\n",
      "Epoch 170, CIFAR-10 Batch 2:  Loss: 0.7667784690856934   Validation Accuracy: 0.5145999193191528\n",
      "Epoch 170, CIFAR-10 Batch 3:  Loss: 0.7897492051124573   Validation Accuracy: 0.509399950504303\n",
      "Epoch 170, CIFAR-10 Batch 4:  Loss: 0.7394676208496094   Validation Accuracy: 0.5137999653816223\n",
      "Epoch 170, CIFAR-10 Batch 5:  Loss: 0.7668477296829224   Validation Accuracy: 0.5023999214172363\n",
      "Epoch 171, CIFAR-10 Batch 1:  Loss: 0.7185834646224976   Validation Accuracy: 0.5063999891281128\n",
      "Epoch 171, CIFAR-10 Batch 2:  Loss: 0.7674779891967773   Validation Accuracy: 0.5039999485015869\n",
      "Epoch 171, CIFAR-10 Batch 3:  Loss: 0.7879515886306763   Validation Accuracy: 0.5041999816894531\n",
      "Epoch 171, CIFAR-10 Batch 4:  Loss: 0.7386431097984314   Validation Accuracy: 0.5115999579429626\n",
      "Epoch 171, CIFAR-10 Batch 5:  Loss: 0.767754316329956    Validation Accuracy: 0.4959999918937683\n",
      "Epoch 172, CIFAR-10 Batch 1:  Loss: 0.7209740877151489   Validation Accuracy: 0.5077999234199524\n",
      "Epoch 172, CIFAR-10 Batch 2:  Loss: 0.7715529203414917   Validation Accuracy: 0.49699994921684265\n",
      "Epoch 172, CIFAR-10 Batch 3:  Loss: 0.7886996269226074   Validation Accuracy: 0.5054000020027161\n",
      "Epoch 172, CIFAR-10 Batch 4:  Loss: 0.7415948510169983   Validation Accuracy: 0.5031999349594116\n",
      "Epoch 172, CIFAR-10 Batch 5:  Loss: 0.7682583928108215   Validation Accuracy: 0.4959999918937683\n",
      "Epoch 173, CIFAR-10 Batch 1:  Loss: 0.720777153968811    Validation Accuracy: 0.49859994649887085\n",
      "Epoch 173, CIFAR-10 Batch 2:  Loss: 0.7669185400009155   Validation Accuracy: 0.5141999125480652\n",
      "Epoch 173, CIFAR-10 Batch 3:  Loss: 0.7873750329017639   Validation Accuracy: 0.5043999552726746\n",
      "Epoch 173, CIFAR-10 Batch 4:  Loss: 0.7386077642440796   Validation Accuracy: 0.5097999572753906\n",
      "Epoch 173, CIFAR-10 Batch 5:  Loss: 0.7681239247322083   Validation Accuracy: 0.4981999397277832\n",
      "Epoch 174, CIFAR-10 Batch 1:  Loss: 0.7190324068069458   Validation Accuracy: 0.5065999627113342\n",
      "Epoch 174, CIFAR-10 Batch 2:  Loss: 0.7667081356048584   Validation Accuracy: 0.5131999850273132\n",
      "Epoch 174, CIFAR-10 Batch 3:  Loss: 0.7891055345535278   Validation Accuracy: 0.5041999816894531\n",
      "Epoch 174, CIFAR-10 Batch 4:  Loss: 0.7390465140342712   Validation Accuracy: 0.5085999965667725\n",
      "Epoch 174, CIFAR-10 Batch 5:  Loss: 0.7723364233970642   Validation Accuracy: 0.4997999370098114\n",
      "Epoch 175, CIFAR-10 Batch 1:  Loss: 0.7186633348464966   Validation Accuracy: 0.5135999917984009\n",
      "Epoch 175, CIFAR-10 Batch 2:  Loss: 0.7677350640296936   Validation Accuracy: 0.5001999139785767\n",
      "Epoch 175, CIFAR-10 Batch 3:  Loss: 0.786699652671814    Validation Accuracy: 0.5133999586105347\n",
      "Epoch 175, CIFAR-10 Batch 4:  Loss: 0.7400804162025452   Validation Accuracy: 0.50819993019104\n",
      "Epoch 175, CIFAR-10 Batch 5:  Loss: 0.7674270272254944   Validation Accuracy: 0.5015999674797058\n",
      "Epoch 176, CIFAR-10 Batch 1:  Loss: 0.7182518839836121   Validation Accuracy: 0.5127999782562256\n",
      "Epoch 176, CIFAR-10 Batch 2:  Loss: 0.7668483257293701   Validation Accuracy: 0.5085999965667725\n",
      "Epoch 176, CIFAR-10 Batch 3:  Loss: 0.7911879420280457   Validation Accuracy: 0.5083999633789062\n",
      "Epoch 176, CIFAR-10 Batch 4:  Loss: 0.7394311428070068   Validation Accuracy: 0.509399950504303\n",
      "Epoch 176, CIFAR-10 Batch 5:  Loss: 0.7673694491386414   Validation Accuracy: 0.5085999965667725\n",
      "Epoch 177, CIFAR-10 Batch 1:  Loss: 0.7185877561569214   Validation Accuracy: 0.5117999911308289\n",
      "Epoch 177, CIFAR-10 Batch 2:  Loss: 0.7670210003852844   Validation Accuracy: 0.5085999369621277\n",
      "Epoch 177, CIFAR-10 Batch 3:  Loss: 0.7870892882347107   Validation Accuracy: 0.509399950504303\n",
      "Epoch 177, CIFAR-10 Batch 4:  Loss: 0.7401676774024963   Validation Accuracy: 0.5091999173164368\n",
      "Epoch 177, CIFAR-10 Batch 5:  Loss: 0.7679044008255005   Validation Accuracy: 0.4989999532699585\n",
      "Epoch 178, CIFAR-10 Batch 1:  Loss: 0.7187353372573853   Validation Accuracy: 0.5107999444007874\n",
      "Epoch 178, CIFAR-10 Batch 2:  Loss: 0.770393967628479    Validation Accuracy: 0.496599942445755\n",
      "Epoch 178, CIFAR-10 Batch 3:  Loss: 0.7877697944641113   Validation Accuracy: 0.5071999430656433\n",
      "Epoch 178, CIFAR-10 Batch 4:  Loss: 0.7432949542999268   Validation Accuracy: 0.49939996004104614\n",
      "Epoch 178, CIFAR-10 Batch 5:  Loss: 0.7682846188545227   Validation Accuracy: 0.5061999559402466\n",
      "Epoch 179, CIFAR-10 Batch 1:  Loss: 0.7189409136772156   Validation Accuracy: 0.5013999938964844\n",
      "Epoch 179, CIFAR-10 Batch 2:  Loss: 0.7689396739006042   Validation Accuracy: 0.5089999437332153\n",
      "Epoch 179, CIFAR-10 Batch 3:  Loss: 0.7870418429374695   Validation Accuracy: 0.5167999863624573\n",
      "Epoch 179, CIFAR-10 Batch 4:  Loss: 0.7409947514533997   Validation Accuracy: 0.4971999526023865\n",
      "Epoch 179, CIFAR-10 Batch 5:  Loss: 0.7698631286621094   Validation Accuracy: 0.506399929523468\n",
      "Epoch 180, CIFAR-10 Batch 1:  Loss: 0.7302340269088745   Validation Accuracy: 0.5037999153137207\n",
      "Epoch 180, CIFAR-10 Batch 2:  Loss: 0.7696007490158081   Validation Accuracy: 0.5047999620437622\n",
      "Epoch 180, CIFAR-10 Batch 3:  Loss: 0.7869656085968018   Validation Accuracy: 0.502799928188324\n",
      "Epoch 180, CIFAR-10 Batch 4:  Loss: 0.7406657338142395   Validation Accuracy: 0.5077999830245972\n",
      "Epoch 180, CIFAR-10 Batch 5:  Loss: 0.7674883008003235   Validation Accuracy: 0.5005999207496643\n",
      "Epoch 181, CIFAR-10 Batch 1:  Loss: 0.7187672853469849   Validation Accuracy: 0.5069999694824219\n",
      "Epoch 181, CIFAR-10 Batch 2:  Loss: 0.7675948143005371   Validation Accuracy: 0.5017999410629272\n",
      "Epoch 181, CIFAR-10 Batch 3:  Loss: 0.7869917154312134   Validation Accuracy: 0.5179999470710754\n",
      "Epoch 181, CIFAR-10 Batch 4:  Loss: 0.7385014891624451   Validation Accuracy: 0.5037999749183655\n",
      "Epoch 181, CIFAR-10 Batch 5:  Loss: 0.7667941451072693   Validation Accuracy: 0.5049999356269836\n",
      "Epoch 182, CIFAR-10 Batch 1:  Loss: 0.7210732102394104   Validation Accuracy: 0.5131999850273132\n",
      "Epoch 182, CIFAR-10 Batch 2:  Loss: 0.7680418491363525   Validation Accuracy: 0.507599949836731\n",
      "Epoch 182, CIFAR-10 Batch 3:  Loss: 0.7873527407646179   Validation Accuracy: 0.5191999673843384\n",
      "Epoch 182, CIFAR-10 Batch 4:  Loss: 0.7383167743682861   Validation Accuracy: 0.5039999485015869\n",
      "Epoch 182, CIFAR-10 Batch 5:  Loss: 0.7697121500968933   Validation Accuracy: 0.4963999390602112\n",
      "Epoch 183, CIFAR-10 Batch 1:  Loss: 0.7185274362564087   Validation Accuracy: 0.5097999572753906\n",
      "Epoch 183, CIFAR-10 Batch 2:  Loss: 0.7686091661453247   Validation Accuracy: 0.5139999389648438\n",
      "Epoch 183, CIFAR-10 Batch 3:  Loss: 0.7870693802833557   Validation Accuracy: 0.5061999559402466\n",
      "Epoch 183, CIFAR-10 Batch 4:  Loss: 0.7329175472259521   Validation Accuracy: 0.5035999417304993\n",
      "Epoch 183, CIFAR-10 Batch 5:  Loss: 0.7445565462112427   Validation Accuracy: 0.5047999024391174\n",
      "Epoch 184, CIFAR-10 Batch 1:  Loss: 0.6572530269622803   Validation Accuracy: 0.5423999428749084\n",
      "Epoch 184, CIFAR-10 Batch 2:  Loss: 0.739203929901123    Validation Accuracy: 0.5273999571800232\n",
      "Epoch 184, CIFAR-10 Batch 3:  Loss: 0.6913664937019348   Validation Accuracy: 0.5453999042510986\n",
      "Epoch 184, CIFAR-10 Batch 4:  Loss: 0.6558407545089722   Validation Accuracy: 0.5223999619483948\n",
      "Epoch 184, CIFAR-10 Batch 5:  Loss: 0.7010776400566101   Validation Accuracy: 0.5411999225616455\n",
      "Epoch 185, CIFAR-10 Batch 1:  Loss: 0.6032273173332214   Validation Accuracy: 0.5487998723983765\n",
      "Epoch 185, CIFAR-10 Batch 2:  Loss: 0.668694257736206    Validation Accuracy: 0.5553999543190002\n",
      "Epoch 185, CIFAR-10 Batch 3:  Loss: 0.6332448720932007   Validation Accuracy: 0.5533999800682068\n",
      "Epoch 185, CIFAR-10 Batch 4:  Loss: 0.6114928722381592   Validation Accuracy: 0.5423999428749084\n",
      "Epoch 185, CIFAR-10 Batch 5:  Loss: 0.6517611742019653   Validation Accuracy: 0.5411999225616455\n",
      "Epoch 186, CIFAR-10 Batch 1:  Loss: 0.5779465436935425   Validation Accuracy: 0.5537999272346497\n",
      "Epoch 186, CIFAR-10 Batch 2:  Loss: 0.6357230544090271   Validation Accuracy: 0.5577999353408813\n",
      "Epoch 186, CIFAR-10 Batch 3:  Loss: 0.6173502206802368   Validation Accuracy: 0.5611999034881592\n",
      "Epoch 186, CIFAR-10 Batch 4:  Loss: 0.5872511267662048   Validation Accuracy: 0.547999918460846\n",
      "Epoch 186, CIFAR-10 Batch 5:  Loss: 0.6279586553573608   Validation Accuracy: 0.545799970626831\n",
      "Epoch 187, CIFAR-10 Batch 1:  Loss: 0.560735821723938    Validation Accuracy: 0.5505999326705933\n",
      "Epoch 187, CIFAR-10 Batch 2:  Loss: 0.623884916305542    Validation Accuracy: 0.5521999597549438\n",
      "Epoch 187, CIFAR-10 Batch 3:  Loss: 0.6132909059524536   Validation Accuracy: 0.5577998757362366\n",
      "Epoch 187, CIFAR-10 Batch 4:  Loss: 0.5689371228218079   Validation Accuracy: 0.5547999143600464\n",
      "Epoch 187, CIFAR-10 Batch 5:  Loss: 0.611950159072876    Validation Accuracy: 0.5393999218940735\n",
      "Epoch 188, CIFAR-10 Batch 1:  Loss: 0.5478699803352356   Validation Accuracy: 0.5546000003814697\n",
      "Epoch 188, CIFAR-10 Batch 2:  Loss: 0.605925977230072    Validation Accuracy: 0.5543999075889587\n",
      "Epoch 188, CIFAR-10 Batch 3:  Loss: 0.6017218232154846   Validation Accuracy: 0.5583999156951904\n",
      "Epoch 188, CIFAR-10 Batch 4:  Loss: 0.5539120435714722   Validation Accuracy: 0.5609999299049377\n",
      "Epoch 188, CIFAR-10 Batch 5:  Loss: 0.6093383431434631   Validation Accuracy: 0.5317999124526978\n",
      "Epoch 189, CIFAR-10 Batch 1:  Loss: 0.5470240712165833   Validation Accuracy: 0.5501999258995056\n",
      "Epoch 189, CIFAR-10 Batch 2:  Loss: 0.6193801164627075   Validation Accuracy: 0.5439999103546143\n",
      "Epoch 189, CIFAR-10 Batch 3:  Loss: 0.6002271175384521   Validation Accuracy: 0.547999918460846\n",
      "Epoch 189, CIFAR-10 Batch 4:  Loss: 0.5423411726951599   Validation Accuracy: 0.5577999353408813\n",
      "Epoch 189, CIFAR-10 Batch 5:  Loss: 0.5834832191467285   Validation Accuracy: 0.5451999306678772\n",
      "Epoch 190, CIFAR-10 Batch 1:  Loss: 0.5454651713371277   Validation Accuracy: 0.5447999238967896\n",
      "Epoch 190, CIFAR-10 Batch 2:  Loss: 0.5983858704566956   Validation Accuracy: 0.5441998839378357\n",
      "Epoch 190, CIFAR-10 Batch 3:  Loss: 0.5801950097084045   Validation Accuracy: 0.5561999678611755\n",
      "Epoch 190, CIFAR-10 Batch 4:  Loss: 0.5560476183891296   Validation Accuracy: 0.5519999265670776\n",
      "Epoch 190, CIFAR-10 Batch 5:  Loss: 0.5695370435714722   Validation Accuracy: 0.5505999326705933\n",
      "Epoch 191, CIFAR-10 Batch 1:  Loss: 0.5411443114280701   Validation Accuracy: 0.5461999177932739\n",
      "Epoch 191, CIFAR-10 Batch 2:  Loss: 0.5860272645950317   Validation Accuracy: 0.5597999095916748\n",
      "Epoch 191, CIFAR-10 Batch 3:  Loss: 0.5804632306098938   Validation Accuracy: 0.5495999455451965\n",
      "Epoch 191, CIFAR-10 Batch 4:  Loss: 0.5531561970710754   Validation Accuracy: 0.5445999503135681\n",
      "Epoch 191, CIFAR-10 Batch 5:  Loss: 0.5672407150268555   Validation Accuracy: 0.5443999767303467\n",
      "Epoch 192, CIFAR-10 Batch 1:  Loss: 0.5295453071594238   Validation Accuracy: 0.5567999482154846\n",
      "Epoch 192, CIFAR-10 Batch 2:  Loss: 0.559330403804779    Validation Accuracy: 0.5489999651908875\n",
      "Epoch 192, CIFAR-10 Batch 3:  Loss: 0.5618308186531067   Validation Accuracy: 0.5613999366760254\n",
      "Epoch 192, CIFAR-10 Batch 4:  Loss: 0.5370649099349976   Validation Accuracy: 0.5483999252319336\n",
      "Epoch 192, CIFAR-10 Batch 5:  Loss: 0.5573153495788574   Validation Accuracy: 0.5439999103546143\n",
      "Epoch 193, CIFAR-10 Batch 1:  Loss: 0.5198747515678406   Validation Accuracy: 0.5565999150276184\n",
      "Epoch 193, CIFAR-10 Batch 2:  Loss: 0.5497897267341614   Validation Accuracy: 0.5467999577522278\n",
      "Epoch 193, CIFAR-10 Batch 3:  Loss: 0.560344934463501    Validation Accuracy: 0.554599940776825\n",
      "Epoch 193, CIFAR-10 Batch 4:  Loss: 0.5273419618606567   Validation Accuracy: 0.5471999645233154\n",
      "Epoch 193, CIFAR-10 Batch 5:  Loss: 0.5520174503326416   Validation Accuracy: 0.55159991979599\n",
      "Epoch 194, CIFAR-10 Batch 1:  Loss: 0.5163682699203491   Validation Accuracy: 0.5495999455451965\n",
      "Epoch 194, CIFAR-10 Batch 2:  Loss: 0.5424571633338928   Validation Accuracy: 0.5521999001502991\n",
      "Epoch 194, CIFAR-10 Batch 3:  Loss: 0.5514306426048279   Validation Accuracy: 0.554599940776825\n",
      "Epoch 194, CIFAR-10 Batch 4:  Loss: 0.5232990384101868   Validation Accuracy: 0.5487998723983765\n",
      "Epoch 194, CIFAR-10 Batch 5:  Loss: 0.5521074533462524   Validation Accuracy: 0.5437999367713928\n",
      "Epoch 195, CIFAR-10 Batch 1:  Loss: 0.5165771245956421   Validation Accuracy: 0.5461999773979187\n",
      "Epoch 195, CIFAR-10 Batch 2:  Loss: 0.5442373752593994   Validation Accuracy: 0.5539999604225159\n",
      "Epoch 195, CIFAR-10 Batch 3:  Loss: 0.5502732992172241   Validation Accuracy: 0.5481999516487122\n",
      "Epoch 195, CIFAR-10 Batch 4:  Loss: 0.5251278877258301   Validation Accuracy: 0.5507999062538147\n",
      "Epoch 195, CIFAR-10 Batch 5:  Loss: 0.5511813759803772   Validation Accuracy: 0.5331999659538269\n",
      "Epoch 196, CIFAR-10 Batch 1:  Loss: 0.5172028541564941   Validation Accuracy: 0.5479999780654907\n",
      "Epoch 196, CIFAR-10 Batch 2:  Loss: 0.5436586141586304   Validation Accuracy: 0.553399920463562\n",
      "Epoch 196, CIFAR-10 Batch 3:  Loss: 0.5468372106552124   Validation Accuracy: 0.5535999536514282\n",
      "Epoch 196, CIFAR-10 Batch 4:  Loss: 0.5194317698478699   Validation Accuracy: 0.5561999082565308\n",
      "Epoch 196, CIFAR-10 Batch 5:  Loss: 0.5556991696357727   Validation Accuracy: 0.5287998914718628\n",
      "Epoch 197, CIFAR-10 Batch 1:  Loss: 0.5111145973205566   Validation Accuracy: 0.5471999645233154\n",
      "Epoch 197, CIFAR-10 Batch 2:  Loss: 0.5478878021240234   Validation Accuracy: 0.5499998927116394\n",
      "Epoch 197, CIFAR-10 Batch 3:  Loss: 0.5524395704269409   Validation Accuracy: 0.5511999130249023\n",
      "Epoch 197, CIFAR-10 Batch 4:  Loss: 0.5232406258583069   Validation Accuracy: 0.5575999021530151\n",
      "Epoch 197, CIFAR-10 Batch 5:  Loss: 0.5670194625854492   Validation Accuracy: 0.5217999219894409\n",
      "Epoch 198, CIFAR-10 Batch 1:  Loss: 0.5122523307800293   Validation Accuracy: 0.5447999835014343\n",
      "Epoch 198, CIFAR-10 Batch 2:  Loss: 0.5339964032173157   Validation Accuracy: 0.5465999245643616\n",
      "Epoch 198, CIFAR-10 Batch 3:  Loss: 0.5469204783439636   Validation Accuracy: 0.55159991979599\n",
      "Epoch 198, CIFAR-10 Batch 4:  Loss: 0.516433835029602    Validation Accuracy: 0.5593999624252319\n",
      "Epoch 198, CIFAR-10 Batch 5:  Loss: 0.5501707196235657   Validation Accuracy: 0.5323998928070068\n",
      "Epoch 199, CIFAR-10 Batch 1:  Loss: 0.5161629915237427   Validation Accuracy: 0.5469999313354492\n",
      "Epoch 199, CIFAR-10 Batch 2:  Loss: 0.5353541374206543   Validation Accuracy: 0.5485999584197998\n",
      "Epoch 199, CIFAR-10 Batch 3:  Loss: 0.5465658903121948   Validation Accuracy: 0.5567999482154846\n",
      "Epoch 199, CIFAR-10 Batch 4:  Loss: 0.5180461406707764   Validation Accuracy: 0.5511999130249023\n",
      "Epoch 199, CIFAR-10 Batch 5:  Loss: 0.5443276166915894   Validation Accuracy: 0.5369999408721924\n",
      "Epoch 200, CIFAR-10 Batch 1:  Loss: 0.5192737579345703   Validation Accuracy: 0.5409999489784241\n",
      "Epoch 200, CIFAR-10 Batch 2:  Loss: 0.5371894240379333   Validation Accuracy: 0.5447999238967896\n",
      "Epoch 200, CIFAR-10 Batch 3:  Loss: 0.5472804307937622   Validation Accuracy: 0.5483999252319336\n",
      "Epoch 200, CIFAR-10 Batch 4:  Loss: 0.512455403804779    Validation Accuracy: 0.5565999746322632\n",
      "Epoch 200, CIFAR-10 Batch 5:  Loss: 0.5396924018859863   Validation Accuracy: 0.5503999590873718\n",
      "Epoch 201, CIFAR-10 Batch 1:  Loss: 0.5099549293518066   Validation Accuracy: 0.5465999245643616\n",
      "Epoch 201, CIFAR-10 Batch 2:  Loss: 0.5335060358047485   Validation Accuracy: 0.5555999279022217\n",
      "Epoch 201, CIFAR-10 Batch 3:  Loss: 0.5523668527603149   Validation Accuracy: 0.545799970626831\n",
      "Epoch 201, CIFAR-10 Batch 4:  Loss: 0.5107040405273438   Validation Accuracy: 0.562999963760376\n",
      "Epoch 201, CIFAR-10 Batch 5:  Loss: 0.5399686098098755   Validation Accuracy: 0.5479999780654907\n",
      "Epoch 202, CIFAR-10 Batch 1:  Loss: 0.5050991773605347   Validation Accuracy: 0.547999918460846\n",
      "Epoch 202, CIFAR-10 Batch 2:  Loss: 0.5336377620697021   Validation Accuracy: 0.5445998907089233\n",
      "Epoch 202, CIFAR-10 Batch 3:  Loss: 0.5466088056564331   Validation Accuracy: 0.5549999475479126\n",
      "Epoch 202, CIFAR-10 Batch 4:  Loss: 0.5119962692260742   Validation Accuracy: 0.5549999475479126\n",
      "Epoch 202, CIFAR-10 Batch 5:  Loss: 0.5415345430374146   Validation Accuracy: 0.5409999489784241\n",
      "Epoch 203, CIFAR-10 Batch 1:  Loss: 0.5076541304588318   Validation Accuracy: 0.5455999374389648\n",
      "Epoch 203, CIFAR-10 Batch 2:  Loss: 0.5291964411735535   Validation Accuracy: 0.5449999570846558\n",
      "Epoch 203, CIFAR-10 Batch 3:  Loss: 0.5476037263870239   Validation Accuracy: 0.5549999475479126\n",
      "Epoch 203, CIFAR-10 Batch 4:  Loss: 0.5114185810089111   Validation Accuracy: 0.5417999625205994\n",
      "Epoch 203, CIFAR-10 Batch 5:  Loss: 0.5382537841796875   Validation Accuracy: 0.5503999590873718\n",
      "Epoch 204, CIFAR-10 Batch 1:  Loss: 0.5195788145065308   Validation Accuracy: 0.5463999509811401\n",
      "Epoch 204, CIFAR-10 Batch 2:  Loss: 0.5394303798675537   Validation Accuracy: 0.5433999300003052\n",
      "Epoch 204, CIFAR-10 Batch 3:  Loss: 0.5486823320388794   Validation Accuracy: 0.5519999265670776\n",
      "Epoch 204, CIFAR-10 Batch 4:  Loss: 0.5080194473266602   Validation Accuracy: 0.5553999543190002\n",
      "Epoch 204, CIFAR-10 Batch 5:  Loss: 0.540182888507843    Validation Accuracy: 0.5539999604225159\n",
      "Epoch 205, CIFAR-10 Batch 1:  Loss: 0.5013111233711243   Validation Accuracy: 0.5501999855041504\n",
      "Epoch 205, CIFAR-10 Batch 2:  Loss: 0.5284390449523926   Validation Accuracy: 0.5433999300003052\n",
      "Epoch 205, CIFAR-10 Batch 3:  Loss: 0.5727053880691528   Validation Accuracy: 0.5535999536514282\n",
      "Epoch 205, CIFAR-10 Batch 4:  Loss: 0.5084604620933533   Validation Accuracy: 0.5509998798370361\n",
      "Epoch 205, CIFAR-10 Batch 5:  Loss: 0.5455160737037659   Validation Accuracy: 0.5531999468803406\n",
      "Epoch 206, CIFAR-10 Batch 1:  Loss: 0.5074358582496643   Validation Accuracy: 0.5487999320030212\n",
      "Epoch 206, CIFAR-10 Batch 2:  Loss: 0.5256417989730835   Validation Accuracy: 0.5371999144554138\n",
      "Epoch 206, CIFAR-10 Batch 3:  Loss: 0.5418627858161926   Validation Accuracy: 0.5543999671936035\n",
      "Epoch 206, CIFAR-10 Batch 4:  Loss: 0.5139935612678528   Validation Accuracy: 0.5499999523162842\n",
      "Epoch 206, CIFAR-10 Batch 5:  Loss: 0.5482237935066223   Validation Accuracy: 0.5505999326705933\n",
      "Epoch 207, CIFAR-10 Batch 1:  Loss: 0.5090103149414062   Validation Accuracy: 0.5477999448776245\n",
      "Epoch 207, CIFAR-10 Batch 2:  Loss: 0.5230988264083862   Validation Accuracy: 0.5469999313354492\n",
      "Epoch 207, CIFAR-10 Batch 3:  Loss: 0.544353723526001    Validation Accuracy: 0.5547999143600464\n",
      "Epoch 207, CIFAR-10 Batch 4:  Loss: 0.5108816027641296   Validation Accuracy: 0.5499999523162842\n",
      "Epoch 207, CIFAR-10 Batch 5:  Loss: 0.5453341007232666   Validation Accuracy: 0.5485999584197998\n",
      "Epoch 208, CIFAR-10 Batch 1:  Loss: 0.49989551305770874  Validation Accuracy: 0.5460000038146973\n",
      "Epoch 208, CIFAR-10 Batch 2:  Loss: 0.5244709849357605   Validation Accuracy: 0.5459999442100525\n",
      "Epoch 208, CIFAR-10 Batch 3:  Loss: 0.5379952192306519   Validation Accuracy: 0.5565999150276184\n",
      "Epoch 208, CIFAR-10 Batch 4:  Loss: 0.5082569718360901   Validation Accuracy: 0.5449999570846558\n",
      "Epoch 208, CIFAR-10 Batch 5:  Loss: 0.5406933426856995   Validation Accuracy: 0.5473999381065369\n",
      "Epoch 209, CIFAR-10 Batch 1:  Loss: 0.49662384390830994  Validation Accuracy: 0.5539999008178711\n",
      "Epoch 209, CIFAR-10 Batch 2:  Loss: 0.5330307483673096   Validation Accuracy: 0.5301999449729919\n",
      "Epoch 209, CIFAR-10 Batch 3:  Loss: 0.5456407070159912   Validation Accuracy: 0.5515998601913452\n",
      "Epoch 209, CIFAR-10 Batch 4:  Loss: 0.507752001285553    Validation Accuracy: 0.5453999638557434\n",
      "Epoch 209, CIFAR-10 Batch 5:  Loss: 0.5408738255500793   Validation Accuracy: 0.542199969291687\n",
      "Epoch 210, CIFAR-10 Batch 1:  Loss: 0.4979085922241211   Validation Accuracy: 0.5487999320030212\n",
      "Epoch 210, CIFAR-10 Batch 2:  Loss: 0.5224445462226868   Validation Accuracy: 0.5463999509811401\n",
      "Epoch 210, CIFAR-10 Batch 3:  Loss: 0.5367302298545837   Validation Accuracy: 0.5459998846054077\n",
      "Epoch 210, CIFAR-10 Batch 4:  Loss: 0.5107569694519043   Validation Accuracy: 0.5511999130249023\n",
      "Epoch 210, CIFAR-10 Batch 5:  Loss: 0.5405936241149902   Validation Accuracy: 0.5437999367713928\n",
      "Epoch 211, CIFAR-10 Batch 1:  Loss: 0.4951633810997009   Validation Accuracy: 0.5553999543190002\n",
      "Epoch 211, CIFAR-10 Batch 2:  Loss: 0.5214911103248596   Validation Accuracy: 0.5461999177932739\n",
      "Epoch 211, CIFAR-10 Batch 3:  Loss: 0.5420697331428528   Validation Accuracy: 0.5495999455451965\n",
      "Epoch 211, CIFAR-10 Batch 4:  Loss: 0.5124145746231079   Validation Accuracy: 0.5519999265670776\n",
      "Epoch 211, CIFAR-10 Batch 5:  Loss: 0.5362970232963562   Validation Accuracy: 0.5435999631881714\n",
      "Epoch 212, CIFAR-10 Batch 1:  Loss: 0.4919169545173645   Validation Accuracy: 0.547999918460846\n",
      "Epoch 212, CIFAR-10 Batch 2:  Loss: 0.5183483958244324   Validation Accuracy: 0.5459999442100525\n",
      "Epoch 212, CIFAR-10 Batch 3:  Loss: 0.5374027490615845   Validation Accuracy: 0.5509999394416809\n",
      "Epoch 212, CIFAR-10 Batch 4:  Loss: 0.5045945644378662   Validation Accuracy: 0.5573999285697937\n",
      "Epoch 212, CIFAR-10 Batch 5:  Loss: 0.5323513746261597   Validation Accuracy: 0.5523999929428101\n",
      "Epoch 213, CIFAR-10 Batch 1:  Loss: 0.500798225402832    Validation Accuracy: 0.5423999428749084\n",
      "Epoch 213, CIFAR-10 Batch 2:  Loss: 0.5203043818473816   Validation Accuracy: 0.5411999821662903\n",
      "Epoch 213, CIFAR-10 Batch 3:  Loss: 0.5420621037483215   Validation Accuracy: 0.550399899482727\n",
      "Epoch 213, CIFAR-10 Batch 4:  Loss: 0.506975531578064    Validation Accuracy: 0.5567998886108398\n",
      "Epoch 213, CIFAR-10 Batch 5:  Loss: 0.5324504375457764   Validation Accuracy: 0.5555999279022217\n",
      "Epoch 214, CIFAR-10 Batch 1:  Loss: 0.48950114846229553  Validation Accuracy: 0.5529999732971191\n",
      "Epoch 214, CIFAR-10 Batch 2:  Loss: 0.5190463662147522   Validation Accuracy: 0.548799991607666\n",
      "Epoch 214, CIFAR-10 Batch 3:  Loss: 0.5365815162658691   Validation Accuracy: 0.5513999462127686\n",
      "Epoch 214, CIFAR-10 Batch 4:  Loss: 0.5133928656578064   Validation Accuracy: 0.5629999041557312\n",
      "Epoch 214, CIFAR-10 Batch 5:  Loss: 0.5313662886619568   Validation Accuracy: 0.5508000254631042\n",
      "Epoch 215, CIFAR-10 Batch 1:  Loss: 0.4887194037437439   Validation Accuracy: 0.5575999617576599\n",
      "Epoch 215, CIFAR-10 Batch 2:  Loss: 0.5193649530410767   Validation Accuracy: 0.5471999645233154\n",
      "Epoch 215, CIFAR-10 Batch 3:  Loss: 0.534476637840271    Validation Accuracy: 0.5567998886108398\n",
      "Epoch 215, CIFAR-10 Batch 4:  Loss: 0.5054576396942139   Validation Accuracy: 0.5585999488830566\n",
      "Epoch 215, CIFAR-10 Batch 5:  Loss: 0.5324186086654663   Validation Accuracy: 0.5521999001502991\n",
      "Epoch 216, CIFAR-10 Batch 1:  Loss: 0.4895898997783661   Validation Accuracy: 0.5625999569892883\n",
      "Epoch 216, CIFAR-10 Batch 2:  Loss: 0.5169658660888672   Validation Accuracy: 0.5529999136924744\n",
      "Epoch 216, CIFAR-10 Batch 3:  Loss: 0.537050187587738    Validation Accuracy: 0.5439999103546143\n",
      "Epoch 216, CIFAR-10 Batch 4:  Loss: 0.5037722587585449   Validation Accuracy: 0.5623999238014221\n",
      "Epoch 216, CIFAR-10 Batch 5:  Loss: 0.533903181552887    Validation Accuracy: 0.5445999503135681\n",
      "Epoch 217, CIFAR-10 Batch 1:  Loss: 0.4899871349334717   Validation Accuracy: 0.5489999651908875\n",
      "Epoch 217, CIFAR-10 Batch 2:  Loss: 0.5165907740592957   Validation Accuracy: 0.5491999387741089\n",
      "Epoch 217, CIFAR-10 Batch 3:  Loss: 0.5349856615066528   Validation Accuracy: 0.559999942779541\n",
      "Epoch 217, CIFAR-10 Batch 4:  Loss: 0.5032604932785034   Validation Accuracy: 0.5585999488830566\n",
      "Epoch 217, CIFAR-10 Batch 5:  Loss: 0.5310653448104858   Validation Accuracy: 0.5483999252319336\n",
      "Epoch 218, CIFAR-10 Batch 1:  Loss: 0.4884442687034607   Validation Accuracy: 0.5557999610900879\n",
      "Epoch 218, CIFAR-10 Batch 2:  Loss: 0.51666659116745     Validation Accuracy: 0.5505999326705933\n",
      "Epoch 218, CIFAR-10 Batch 3:  Loss: 0.5380316376686096   Validation Accuracy: 0.5485999584197998\n",
      "Epoch 218, CIFAR-10 Batch 4:  Loss: 0.49991312623023987  Validation Accuracy: 0.5653998851776123\n",
      "Epoch 218, CIFAR-10 Batch 5:  Loss: 0.536090612411499    Validation Accuracy: 0.5529999136924744\n",
      "Epoch 219, CIFAR-10 Batch 1:  Loss: 0.48895490169525146  Validation Accuracy: 0.5469999313354492\n",
      "Epoch 219, CIFAR-10 Batch 2:  Loss: 0.5198159217834473   Validation Accuracy: 0.5501999258995056\n",
      "Epoch 219, CIFAR-10 Batch 3:  Loss: 0.5414323806762695   Validation Accuracy: 0.5379999876022339\n",
      "Epoch 219, CIFAR-10 Batch 4:  Loss: 0.5005683302879333   Validation Accuracy: 0.5607998967170715\n",
      "Epoch 219, CIFAR-10 Batch 5:  Loss: 0.5325325131416321   Validation Accuracy: 0.5511999726295471\n",
      "Epoch 220, CIFAR-10 Batch 1:  Loss: 0.4887300133705139   Validation Accuracy: 0.5359999537467957\n",
      "Epoch 220, CIFAR-10 Batch 2:  Loss: 0.5147073268890381   Validation Accuracy: 0.5525999069213867\n",
      "Epoch 220, CIFAR-10 Batch 3:  Loss: 0.5354604721069336   Validation Accuracy: 0.5463999509811401\n",
      "Epoch 220, CIFAR-10 Batch 4:  Loss: 0.49767202138900757  Validation Accuracy: 0.558199942111969\n",
      "Epoch 220, CIFAR-10 Batch 5:  Loss: 0.5317132472991943   Validation Accuracy: 0.5615999698638916\n",
      "Epoch 221, CIFAR-10 Batch 1:  Loss: 0.48919618129730225  Validation Accuracy: 0.5515999794006348\n",
      "Epoch 221, CIFAR-10 Batch 2:  Loss: 0.516426682472229    Validation Accuracy: 0.5481999516487122\n",
      "Epoch 221, CIFAR-10 Batch 3:  Loss: 0.5412848591804504   Validation Accuracy: 0.5535999536514282\n",
      "Epoch 221, CIFAR-10 Batch 4:  Loss: 0.4986047148704529   Validation Accuracy: 0.5543999671936035\n",
      "Epoch 221, CIFAR-10 Batch 5:  Loss: 0.5284002423286438   Validation Accuracy: 0.5575999021530151\n",
      "Epoch 222, CIFAR-10 Batch 1:  Loss: 0.4887123703956604   Validation Accuracy: 0.5515999794006348\n",
      "Epoch 222, CIFAR-10 Batch 2:  Loss: 0.5122649073600769   Validation Accuracy: 0.5481999516487122\n",
      "Epoch 222, CIFAR-10 Batch 3:  Loss: 0.5373011827468872   Validation Accuracy: 0.5471999645233154\n",
      "Epoch 222, CIFAR-10 Batch 4:  Loss: 0.4974215626716614   Validation Accuracy: 0.554599940776825\n",
      "Epoch 222, CIFAR-10 Batch 5:  Loss: 0.5280377864837646   Validation Accuracy: 0.5579999685287476\n",
      "Epoch 223, CIFAR-10 Batch 1:  Loss: 0.48872825503349304  Validation Accuracy: 0.5493999123573303\n",
      "Epoch 223, CIFAR-10 Batch 2:  Loss: 0.5112894177436829   Validation Accuracy: 0.5461999177932739\n",
      "Epoch 223, CIFAR-10 Batch 3:  Loss: 0.5378469824790955   Validation Accuracy: 0.5559999346733093\n",
      "Epoch 223, CIFAR-10 Batch 4:  Loss: 0.4986942410469055   Validation Accuracy: 0.5489999651908875\n",
      "Epoch 223, CIFAR-10 Batch 5:  Loss: 0.5311000347137451   Validation Accuracy: 0.5527999401092529\n",
      "Epoch 224, CIFAR-10 Batch 1:  Loss: 0.4877357482910156   Validation Accuracy: 0.5593999028205872\n",
      "Epoch 224, CIFAR-10 Batch 2:  Loss: 0.5118223428726196   Validation Accuracy: 0.5573999285697937\n",
      "Epoch 224, CIFAR-10 Batch 3:  Loss: 0.5345118045806885   Validation Accuracy: 0.5529999136924744\n",
      "Epoch 224, CIFAR-10 Batch 4:  Loss: 0.49609264731407166  Validation Accuracy: 0.5539999008178711\n",
      "Epoch 224, CIFAR-10 Batch 5:  Loss: 0.5331459045410156   Validation Accuracy: 0.5521999001502991\n",
      "Epoch 225, CIFAR-10 Batch 1:  Loss: 0.48877161741256714  Validation Accuracy: 0.5463999509811401\n",
      "Epoch 225, CIFAR-10 Batch 2:  Loss: 0.5105666518211365   Validation Accuracy: 0.5517998933792114\n",
      "Epoch 225, CIFAR-10 Batch 3:  Loss: 0.5336196422576904   Validation Accuracy: 0.5589999556541443\n",
      "Epoch 225, CIFAR-10 Batch 4:  Loss: 0.49774983525276184  Validation Accuracy: 0.5517998933792114\n",
      "Epoch 225, CIFAR-10 Batch 5:  Loss: 0.5285904407501221   Validation Accuracy: 0.5501998662948608\n",
      "Epoch 226, CIFAR-10 Batch 1:  Loss: 0.4880320727825165   Validation Accuracy: 0.559999942779541\n",
      "Epoch 226, CIFAR-10 Batch 2:  Loss: 0.5109154582023621   Validation Accuracy: 0.553399920463562\n",
      "Epoch 226, CIFAR-10 Batch 3:  Loss: 0.5344642996788025   Validation Accuracy: 0.5567998886108398\n",
      "Epoch 226, CIFAR-10 Batch 4:  Loss: 0.49679821729660034  Validation Accuracy: 0.5557999610900879\n",
      "Epoch 226, CIFAR-10 Batch 5:  Loss: 0.5277296900749207   Validation Accuracy: 0.5549999475479126\n",
      "Epoch 227, CIFAR-10 Batch 1:  Loss: 0.4880720376968384   Validation Accuracy: 0.5551999807357788\n",
      "Epoch 227, CIFAR-10 Batch 2:  Loss: 0.5105324983596802   Validation Accuracy: 0.5537999272346497\n",
      "Epoch 227, CIFAR-10 Batch 3:  Loss: 0.5333694219589233   Validation Accuracy: 0.5601999163627625\n",
      "Epoch 227, CIFAR-10 Batch 4:  Loss: 0.49595773220062256  Validation Accuracy: 0.5567999482154846\n",
      "Epoch 227, CIFAR-10 Batch 5:  Loss: 0.5280992388725281   Validation Accuracy: 0.554599940776825\n",
      "Epoch 228, CIFAR-10 Batch 1:  Loss: 0.48768913745880127  Validation Accuracy: 0.554599940776825\n",
      "Epoch 228, CIFAR-10 Batch 2:  Loss: 0.5104452967643738   Validation Accuracy: 0.5521999597549438\n",
      "Epoch 228, CIFAR-10 Batch 3:  Loss: 0.5335454344749451   Validation Accuracy: 0.5613999366760254\n",
      "Epoch 228, CIFAR-10 Batch 4:  Loss: 0.4964936375617981   Validation Accuracy: 0.5595999360084534\n",
      "Epoch 228, CIFAR-10 Batch 5:  Loss: 0.5285982489585876   Validation Accuracy: 0.5583999156951904\n",
      "Epoch 229, CIFAR-10 Batch 1:  Loss: 0.487716943025589    Validation Accuracy: 0.555199921131134\n",
      "Epoch 229, CIFAR-10 Batch 2:  Loss: 0.511139452457428    Validation Accuracy: 0.5579999685287476\n",
      "Epoch 229, CIFAR-10 Batch 3:  Loss: 0.5344122648239136   Validation Accuracy: 0.5567999482154846\n",
      "Epoch 229, CIFAR-10 Batch 4:  Loss: 0.49622535705566406  Validation Accuracy: 0.5583999156951904\n",
      "Epoch 229, CIFAR-10 Batch 5:  Loss: 0.5273178815841675   Validation Accuracy: 0.5613999366760254\n",
      "Epoch 230, CIFAR-10 Batch 1:  Loss: 0.48780128359794617  Validation Accuracy: 0.5513999462127686\n",
      "Epoch 230, CIFAR-10 Batch 2:  Loss: 0.5108304023742676   Validation Accuracy: 0.5491999387741089\n",
      "Epoch 230, CIFAR-10 Batch 3:  Loss: 0.5338005423545837   Validation Accuracy: 0.5589998960494995\n",
      "Epoch 230, CIFAR-10 Batch 4:  Loss: 0.49815794825553894  Validation Accuracy: 0.5575999021530151\n",
      "Epoch 230, CIFAR-10 Batch 5:  Loss: 0.5273504853248596   Validation Accuracy: 0.5605999231338501\n",
      "Epoch 231, CIFAR-10 Batch 1:  Loss: 0.48778897523880005  Validation Accuracy: 0.5507999658584595\n",
      "Epoch 231, CIFAR-10 Batch 2:  Loss: 0.5124973058700562   Validation Accuracy: 0.5443999767303467\n",
      "Epoch 231, CIFAR-10 Batch 3:  Loss: 0.5338072776794434   Validation Accuracy: 0.5519999861717224\n",
      "Epoch 231, CIFAR-10 Batch 4:  Loss: 0.49756288528442383  Validation Accuracy: 0.5549999475479126\n",
      "Epoch 231, CIFAR-10 Batch 5:  Loss: 0.5284445881843567   Validation Accuracy: 0.5605999827384949\n",
      "Epoch 232, CIFAR-10 Batch 1:  Loss: 0.4876810312271118   Validation Accuracy: 0.5631998777389526\n",
      "Epoch 232, CIFAR-10 Batch 2:  Loss: 0.5105360746383667   Validation Accuracy: 0.5499999523162842\n",
      "Epoch 232, CIFAR-10 Batch 3:  Loss: 0.5348924994468689   Validation Accuracy: 0.5491999387741089\n",
      "Epoch 232, CIFAR-10 Batch 4:  Loss: 0.496920645236969    Validation Accuracy: 0.5451999306678772\n",
      "Epoch 232, CIFAR-10 Batch 5:  Loss: 0.5283287763595581   Validation Accuracy: 0.554599940776825\n",
      "Epoch 233, CIFAR-10 Batch 1:  Loss: 0.4881446361541748   Validation Accuracy: 0.5503999590873718\n",
      "Epoch 233, CIFAR-10 Batch 2:  Loss: 0.5104343891143799   Validation Accuracy: 0.5539999604225159\n",
      "Epoch 233, CIFAR-10 Batch 3:  Loss: 0.534644365310669    Validation Accuracy: 0.5535999536514282\n",
      "Epoch 233, CIFAR-10 Batch 4:  Loss: 0.4961853623390198   Validation Accuracy: 0.5573999285697937\n",
      "Epoch 233, CIFAR-10 Batch 5:  Loss: 0.5280131101608276   Validation Accuracy: 0.5505999326705933\n",
      "Epoch 234, CIFAR-10 Batch 1:  Loss: 0.48749840259552     Validation Accuracy: 0.5521999001502991\n",
      "Epoch 234, CIFAR-10 Batch 2:  Loss: 0.5110978484153748   Validation Accuracy: 0.5525999069213867\n",
      "Epoch 234, CIFAR-10 Batch 3:  Loss: 0.5338954925537109   Validation Accuracy: 0.5539999604225159\n",
      "Epoch 234, CIFAR-10 Batch 4:  Loss: 0.498080313205719    Validation Accuracy: 0.5547999143600464\n",
      "Epoch 234, CIFAR-10 Batch 5:  Loss: 0.5279206037521362   Validation Accuracy: 0.5541999340057373\n",
      "Epoch 235, CIFAR-10 Batch 1:  Loss: 0.48819512128829956  Validation Accuracy: 0.5389999151229858\n",
      "Epoch 235, CIFAR-10 Batch 2:  Loss: 0.5115237832069397   Validation Accuracy: 0.556399941444397\n",
      "Epoch 235, CIFAR-10 Batch 3:  Loss: 0.5331151485443115   Validation Accuracy: 0.562799870967865\n",
      "Epoch 235, CIFAR-10 Batch 4:  Loss: 0.4968337416648865   Validation Accuracy: 0.5617998838424683\n",
      "Epoch 235, CIFAR-10 Batch 5:  Loss: 0.5274282097816467   Validation Accuracy: 0.5615999102592468\n",
      "Epoch 236, CIFAR-10 Batch 1:  Loss: 0.48740899562835693  Validation Accuracy: 0.5595998764038086\n",
      "Epoch 236, CIFAR-10 Batch 2:  Loss: 0.5109174847602844   Validation Accuracy: 0.5505999326705933\n",
      "Epoch 236, CIFAR-10 Batch 3:  Loss: 0.5331645607948303   Validation Accuracy: 0.5511999130249023\n",
      "Epoch 236, CIFAR-10 Batch 4:  Loss: 0.49664777517318726  Validation Accuracy: 0.5621999502182007\n",
      "Epoch 236, CIFAR-10 Batch 5:  Loss: 0.527725875377655    Validation Accuracy: 0.564599871635437\n",
      "Epoch 237, CIFAR-10 Batch 1:  Loss: 0.48774296045303345  Validation Accuracy: 0.5511999726295471\n",
      "Epoch 237, CIFAR-10 Batch 2:  Loss: 0.510332465171814    Validation Accuracy: 0.5565999150276184\n",
      "Epoch 237, CIFAR-10 Batch 3:  Loss: 0.5344626903533936   Validation Accuracy: 0.5539999604225159\n",
      "Epoch 237, CIFAR-10 Batch 4:  Loss: 0.4960816502571106   Validation Accuracy: 0.5613999366760254\n",
      "Epoch 237, CIFAR-10 Batch 5:  Loss: 0.5277350544929504   Validation Accuracy: 0.5623998641967773\n",
      "Epoch 238, CIFAR-10 Batch 1:  Loss: 0.48804622888565063  Validation Accuracy: 0.5537999272346497\n",
      "Epoch 238, CIFAR-10 Batch 2:  Loss: 0.5111246705055237   Validation Accuracy: 0.5489999055862427\n",
      "Epoch 238, CIFAR-10 Batch 3:  Loss: 0.5344882011413574   Validation Accuracy: 0.5589998960494995\n",
      "Epoch 238, CIFAR-10 Batch 4:  Loss: 0.4961403012275696   Validation Accuracy: 0.5585998892784119\n",
      "Epoch 238, CIFAR-10 Batch 5:  Loss: 0.5286610722541809   Validation Accuracy: 0.5539999604225159\n",
      "Epoch 239, CIFAR-10 Batch 1:  Loss: 0.4905083179473877   Validation Accuracy: 0.5514000058174133\n",
      "Epoch 239, CIFAR-10 Batch 2:  Loss: 0.5121156573295593   Validation Accuracy: 0.5503999590873718\n",
      "Epoch 239, CIFAR-10 Batch 3:  Loss: 0.5332531332969666   Validation Accuracy: 0.5547999143600464\n",
      "Epoch 239, CIFAR-10 Batch 4:  Loss: 0.49624040722846985  Validation Accuracy: 0.5453999638557434\n",
      "Epoch 239, CIFAR-10 Batch 5:  Loss: 0.5275556445121765   Validation Accuracy: 0.5505999326705933\n",
      "Epoch 240, CIFAR-10 Batch 1:  Loss: 0.4874679446220398   Validation Accuracy: 0.5447999835014343\n",
      "Epoch 240, CIFAR-10 Batch 2:  Loss: 0.5111678838729858   Validation Accuracy: 0.554599940776825\n",
      "Epoch 240, CIFAR-10 Batch 3:  Loss: 0.5333701968193054   Validation Accuracy: 0.5493999123573303\n",
      "Epoch 240, CIFAR-10 Batch 4:  Loss: 0.49641329050064087  Validation Accuracy: 0.556999921798706\n",
      "Epoch 240, CIFAR-10 Batch 5:  Loss: 0.5270557403564453   Validation Accuracy: 0.5579999685287476\n",
      "Epoch 241, CIFAR-10 Batch 1:  Loss: 0.4885992407798767   Validation Accuracy: 0.5449999570846558\n",
      "Epoch 241, CIFAR-10 Batch 2:  Loss: 0.5113757848739624   Validation Accuracy: 0.5553999543190002\n",
      "Epoch 241, CIFAR-10 Batch 3:  Loss: 0.5340248346328735   Validation Accuracy: 0.5515999794006348\n",
      "Epoch 241, CIFAR-10 Batch 4:  Loss: 0.49990516901016235  Validation Accuracy: 0.5423998832702637\n",
      "Epoch 241, CIFAR-10 Batch 5:  Loss: 0.5247899293899536   Validation Accuracy: 0.5557999610900879\n",
      "Epoch 242, CIFAR-10 Batch 1:  Loss: 0.49091094732284546  Validation Accuracy: 0.5499999523162842\n",
      "Epoch 242, CIFAR-10 Batch 2:  Loss: 0.5103023648262024   Validation Accuracy: 0.5523999333381653\n",
      "Epoch 242, CIFAR-10 Batch 3:  Loss: 0.5341999530792236   Validation Accuracy: 0.558199942111969\n",
      "Epoch 242, CIFAR-10 Batch 4:  Loss: 0.493802547454834    Validation Accuracy: 0.5493999123573303\n",
      "Epoch 242, CIFAR-10 Batch 5:  Loss: 0.5250164270401001   Validation Accuracy: 0.5529999732971191\n",
      "Epoch 243, CIFAR-10 Batch 1:  Loss: 0.4903234839439392   Validation Accuracy: 0.5425999164581299\n",
      "Epoch 243, CIFAR-10 Batch 2:  Loss: 0.5102957487106323   Validation Accuracy: 0.5439999103546143\n",
      "Epoch 243, CIFAR-10 Batch 3:  Loss: 0.5346322059631348   Validation Accuracy: 0.5499998927116394\n",
      "Epoch 243, CIFAR-10 Batch 4:  Loss: 0.49352872371673584  Validation Accuracy: 0.5501999855041504\n",
      "Epoch 243, CIFAR-10 Batch 5:  Loss: 0.525213360786438    Validation Accuracy: 0.5531999468803406\n",
      "Epoch 244, CIFAR-10 Batch 1:  Loss: 0.48777976632118225  Validation Accuracy: 0.5493999123573303\n",
      "Epoch 244, CIFAR-10 Batch 2:  Loss: 0.5107527375221252   Validation Accuracy: 0.5495999455451965\n",
      "Epoch 244, CIFAR-10 Batch 3:  Loss: 0.5331521034240723   Validation Accuracy: 0.5501999855041504\n",
      "Epoch 244, CIFAR-10 Batch 4:  Loss: 0.49371734261512756  Validation Accuracy: 0.5525999665260315\n",
      "Epoch 244, CIFAR-10 Batch 5:  Loss: 0.5288954973220825   Validation Accuracy: 0.5477998852729797\n",
      "Epoch 245, CIFAR-10 Batch 1:  Loss: 0.4916844367980957   Validation Accuracy: 0.5435999035835266\n",
      "Epoch 245, CIFAR-10 Batch 2:  Loss: 0.5110808610916138   Validation Accuracy: 0.5491999387741089\n",
      "Epoch 245, CIFAR-10 Batch 3:  Loss: 0.5336679220199585   Validation Accuracy: 0.5455999374389648\n",
      "Epoch 245, CIFAR-10 Batch 4:  Loss: 0.49433451890945435  Validation Accuracy: 0.5465999245643616\n",
      "Epoch 245, CIFAR-10 Batch 5:  Loss: 0.5260229110717773   Validation Accuracy: 0.5539999008178711\n",
      "Epoch 246, CIFAR-10 Batch 1:  Loss: 0.49048829078674316  Validation Accuracy: 0.5441998839378357\n",
      "Epoch 246, CIFAR-10 Batch 2:  Loss: 0.5126342177391052   Validation Accuracy: 0.5437999367713928\n",
      "Epoch 246, CIFAR-10 Batch 3:  Loss: 0.534366250038147    Validation Accuracy: 0.5561999678611755\n",
      "Epoch 246, CIFAR-10 Batch 4:  Loss: 0.49379727244377136  Validation Accuracy: 0.5503999590873718\n",
      "Epoch 246, CIFAR-10 Batch 5:  Loss: 0.5280929207801819   Validation Accuracy: 0.546999990940094\n",
      "Epoch 247, CIFAR-10 Batch 1:  Loss: 0.4909994900226593   Validation Accuracy: 0.5511999130249023\n",
      "Epoch 247, CIFAR-10 Batch 2:  Loss: 0.5154377222061157   Validation Accuracy: 0.5411999821662903\n",
      "Epoch 247, CIFAR-10 Batch 3:  Loss: 0.5374031662940979   Validation Accuracy: 0.5489999651908875\n",
      "Epoch 247, CIFAR-10 Batch 4:  Loss: 0.494571328163147    Validation Accuracy: 0.549799919128418\n",
      "Epoch 247, CIFAR-10 Batch 5:  Loss: 0.5267437696456909   Validation Accuracy: 0.5553999543190002\n",
      "Epoch 248, CIFAR-10 Batch 1:  Loss: 0.49750667810440063  Validation Accuracy: 0.546799898147583\n",
      "Epoch 248, CIFAR-10 Batch 2:  Loss: 0.5122965574264526   Validation Accuracy: 0.5487998723983765\n",
      "Epoch 248, CIFAR-10 Batch 3:  Loss: 0.5335999727249146   Validation Accuracy: 0.556399941444397\n",
      "Epoch 248, CIFAR-10 Batch 4:  Loss: 0.4937702715396881   Validation Accuracy: 0.553399920463562\n",
      "Epoch 248, CIFAR-10 Batch 5:  Loss: 0.524919867515564    Validation Accuracy: 0.5483999252319336\n",
      "Epoch 249, CIFAR-10 Batch 1:  Loss: 0.4897781014442444   Validation Accuracy: 0.5413999557495117\n",
      "Epoch 249, CIFAR-10 Batch 2:  Loss: 0.5142106413841248   Validation Accuracy: 0.5547999143600464\n",
      "Epoch 249, CIFAR-10 Batch 3:  Loss: 0.536293625831604    Validation Accuracy: 0.5547999143600464\n",
      "Epoch 249, CIFAR-10 Batch 4:  Loss: 0.4935739040374756   Validation Accuracy: 0.5509998798370361\n",
      "Epoch 249, CIFAR-10 Batch 5:  Loss: 0.5254099369049072   Validation Accuracy: 0.561799943447113\n",
      "Epoch 250, CIFAR-10 Batch 1:  Loss: 0.4899027347564697   Validation Accuracy: 0.5527999401092529\n",
      "Epoch 250, CIFAR-10 Batch 2:  Loss: 0.51188725233078     Validation Accuracy: 0.5487999320030212\n",
      "Epoch 250, CIFAR-10 Batch 3:  Loss: 0.5310835242271423   Validation Accuracy: 0.5513999462127686\n",
      "Epoch 250, CIFAR-10 Batch 4:  Loss: 0.49308449029922485  Validation Accuracy: 0.5517999529838562\n",
      "Epoch 250, CIFAR-10 Batch 5:  Loss: 0.5277502536773682   Validation Accuracy: 0.5481999516487122\n",
      "Epoch 251, CIFAR-10 Batch 1:  Loss: 0.4848177134990692   Validation Accuracy: 0.556999921798706\n",
      "Epoch 251, CIFAR-10 Batch 2:  Loss: 0.5108992457389832   Validation Accuracy: 0.5437999367713928\n",
      "Epoch 251, CIFAR-10 Batch 3:  Loss: 0.5317569971084595   Validation Accuracy: 0.5481998920440674\n",
      "Epoch 251, CIFAR-10 Batch 4:  Loss: 0.49601006507873535  Validation Accuracy: 0.5543999075889587\n",
      "Epoch 251, CIFAR-10 Batch 5:  Loss: 0.5255627036094666   Validation Accuracy: 0.5531999468803406\n",
      "Epoch 252, CIFAR-10 Batch 1:  Loss: 0.4853389859199524   Validation Accuracy: 0.5499999523162842\n",
      "Epoch 252, CIFAR-10 Batch 2:  Loss: 0.5103952884674072   Validation Accuracy: 0.5483999252319336\n",
      "Epoch 252, CIFAR-10 Batch 3:  Loss: 0.5307353734970093   Validation Accuracy: 0.5525999665260315\n",
      "Epoch 252, CIFAR-10 Batch 4:  Loss: 0.49053168296813965  Validation Accuracy: 0.5601999759674072\n",
      "Epoch 252, CIFAR-10 Batch 5:  Loss: 0.5248167514801025   Validation Accuracy: 0.5595999360084534\n",
      "Epoch 253, CIFAR-10 Batch 1:  Loss: 0.4854811131954193   Validation Accuracy: 0.5559999346733093\n",
      "Epoch 253, CIFAR-10 Batch 2:  Loss: 0.5107157826423645   Validation Accuracy: 0.5459999442100525\n",
      "Epoch 253, CIFAR-10 Batch 3:  Loss: 0.5304244756698608   Validation Accuracy: 0.5543999671936035\n",
      "Epoch 253, CIFAR-10 Batch 4:  Loss: 0.4904820919036865   Validation Accuracy: 0.556999921798706\n",
      "Epoch 253, CIFAR-10 Batch 5:  Loss: 0.5252313613891602   Validation Accuracy: 0.5455999374389648\n",
      "Epoch 254, CIFAR-10 Batch 1:  Loss: 0.48238134384155273  Validation Accuracy: 0.55159991979599\n",
      "Epoch 254, CIFAR-10 Batch 2:  Loss: 0.5106089115142822   Validation Accuracy: 0.5433999300003052\n",
      "Epoch 254, CIFAR-10 Batch 3:  Loss: 0.5327199697494507   Validation Accuracy: 0.5461999177932739\n",
      "Epoch 254, CIFAR-10 Batch 4:  Loss: 0.4921955466270447   Validation Accuracy: 0.5495999455451965\n",
      "Epoch 254, CIFAR-10 Batch 5:  Loss: 0.5253614783287048   Validation Accuracy: 0.5535999536514282\n",
      "Epoch 255, CIFAR-10 Batch 1:  Loss: 0.4906507432460785   Validation Accuracy: 0.5519999265670776\n",
      "Epoch 255, CIFAR-10 Batch 2:  Loss: 0.5120116472244263   Validation Accuracy: 0.5453999042510986\n",
      "Epoch 255, CIFAR-10 Batch 3:  Loss: 0.5327297449111938   Validation Accuracy: 0.5449999570846558\n",
      "Epoch 255, CIFAR-10 Batch 4:  Loss: 0.49170589447021484  Validation Accuracy: 0.5561999678611755\n",
      "Epoch 255, CIFAR-10 Batch 5:  Loss: 0.5262206792831421   Validation Accuracy: 0.5485999584197998\n",
      "Epoch 256, CIFAR-10 Batch 1:  Loss: 0.48317086696624756  Validation Accuracy: 0.545799970626831\n",
      "Epoch 256, CIFAR-10 Batch 2:  Loss: 0.5137309432029724   Validation Accuracy: 0.5451999306678772\n",
      "Epoch 256, CIFAR-10 Batch 3:  Loss: 0.5312789082527161   Validation Accuracy: 0.5475999116897583\n",
      "Epoch 256, CIFAR-10 Batch 4:  Loss: 0.49093127250671387  Validation Accuracy: 0.5497999787330627\n",
      "Epoch 256, CIFAR-10 Batch 5:  Loss: 0.5299328565597534   Validation Accuracy: 0.5469999313354492\n",
      "Epoch 257, CIFAR-10 Batch 1:  Loss: 0.48478710651397705  Validation Accuracy: 0.5447999238967896\n",
      "Epoch 257, CIFAR-10 Batch 2:  Loss: 0.5108556747436523   Validation Accuracy: 0.5473998785018921\n",
      "Epoch 257, CIFAR-10 Batch 3:  Loss: 0.5306492447853088   Validation Accuracy: 0.5491999983787537\n",
      "Epoch 257, CIFAR-10 Batch 4:  Loss: 0.4904235601425171   Validation Accuracy: 0.5489999055862427\n",
      "Epoch 257, CIFAR-10 Batch 5:  Loss: 0.5244932174682617   Validation Accuracy: 0.5511999726295471\n",
      "Epoch 258, CIFAR-10 Batch 1:  Loss: 0.4817364811897278   Validation Accuracy: 0.5519999265670776\n",
      "Epoch 258, CIFAR-10 Batch 2:  Loss: 0.5109854340553284   Validation Accuracy: 0.5513999462127686\n",
      "Epoch 258, CIFAR-10 Batch 3:  Loss: 0.5303558111190796   Validation Accuracy: 0.5481998920440674\n",
      "Epoch 258, CIFAR-10 Batch 4:  Loss: 0.4912240505218506   Validation Accuracy: 0.5549999475479126\n",
      "Epoch 258, CIFAR-10 Batch 5:  Loss: 0.5248064398765564   Validation Accuracy: 0.5543999075889587\n",
      "Epoch 259, CIFAR-10 Batch 1:  Loss: 0.4825584888458252   Validation Accuracy: 0.5483999252319336\n",
      "Epoch 259, CIFAR-10 Batch 2:  Loss: 0.5156760215759277   Validation Accuracy: 0.5463999509811401\n",
      "Epoch 259, CIFAR-10 Batch 3:  Loss: 0.5324249863624573   Validation Accuracy: 0.545199990272522\n",
      "Epoch 259, CIFAR-10 Batch 4:  Loss: 0.49043673276901245  Validation Accuracy: 0.5541998744010925\n",
      "Epoch 259, CIFAR-10 Batch 5:  Loss: 0.5276864767074585   Validation Accuracy: 0.5505999326705933\n",
      "Epoch 260, CIFAR-10 Batch 1:  Loss: 0.48181968927383423  Validation Accuracy: 0.5575999021530151\n",
      "Epoch 260, CIFAR-10 Batch 2:  Loss: 0.5107345581054688   Validation Accuracy: 0.5499999523162842\n",
      "Epoch 260, CIFAR-10 Batch 3:  Loss: 0.531410813331604    Validation Accuracy: 0.5411999225616455\n",
      "Epoch 260, CIFAR-10 Batch 4:  Loss: 0.49074235558509827  Validation Accuracy: 0.5513999462127686\n",
      "Epoch 260, CIFAR-10 Batch 5:  Loss: 0.524834930896759    Validation Accuracy: 0.5475999712944031\n",
      "Epoch 261, CIFAR-10 Batch 1:  Loss: 0.48245853185653687  Validation Accuracy: 0.5425999760627747\n",
      "Epoch 261, CIFAR-10 Batch 2:  Loss: 0.5184506177902222   Validation Accuracy: 0.5443999171257019\n",
      "Epoch 261, CIFAR-10 Batch 3:  Loss: 0.5303488969802856   Validation Accuracy: 0.5527999401092529\n",
      "Epoch 261, CIFAR-10 Batch 4:  Loss: 0.4908994138240814   Validation Accuracy: 0.5541999936103821\n",
      "Epoch 261, CIFAR-10 Batch 5:  Loss: 0.5285598039627075   Validation Accuracy: 0.5499999523162842\n",
      "Epoch 262, CIFAR-10 Batch 1:  Loss: 0.48794496059417725  Validation Accuracy: 0.5481999516487122\n",
      "Epoch 262, CIFAR-10 Batch 2:  Loss: 0.5107196569442749   Validation Accuracy: 0.549799919128418\n",
      "Epoch 262, CIFAR-10 Batch 3:  Loss: 0.5301626324653625   Validation Accuracy: 0.5499999523162842\n",
      "Epoch 262, CIFAR-10 Batch 4:  Loss: 0.49359655380249023  Validation Accuracy: 0.5471999645233154\n",
      "Epoch 262, CIFAR-10 Batch 5:  Loss: 0.5262734293937683   Validation Accuracy: 0.5511999726295471\n",
      "Epoch 263, CIFAR-10 Batch 1:  Loss: 0.48221129179000854  Validation Accuracy: 0.5485999584197998\n",
      "Epoch 263, CIFAR-10 Batch 2:  Loss: 0.5129355192184448   Validation Accuracy: 0.5423999428749084\n",
      "Epoch 263, CIFAR-10 Batch 3:  Loss: 0.5308241248130798   Validation Accuracy: 0.5567998886108398\n",
      "Epoch 263, CIFAR-10 Batch 4:  Loss: 0.49315619468688965  Validation Accuracy: 0.5455999374389648\n",
      "Epoch 263, CIFAR-10 Batch 5:  Loss: 0.5256502628326416   Validation Accuracy: 0.5513999462127686\n",
      "Epoch 264, CIFAR-10 Batch 1:  Loss: 0.48194989562034607  Validation Accuracy: 0.5523999333381653\n",
      "Epoch 264, CIFAR-10 Batch 2:  Loss: 0.5116068124771118   Validation Accuracy: 0.5453999042510986\n",
      "Epoch 264, CIFAR-10 Batch 3:  Loss: 0.5346442461013794   Validation Accuracy: 0.5537999272346497\n",
      "Epoch 264, CIFAR-10 Batch 4:  Loss: 0.4914763569831848   Validation Accuracy: 0.5473999381065369\n",
      "Epoch 264, CIFAR-10 Batch 5:  Loss: 0.5247510671615601   Validation Accuracy: 0.558199942111969\n",
      "Epoch 265, CIFAR-10 Batch 1:  Loss: 0.48186540603637695  Validation Accuracy: 0.550399899482727\n",
      "Epoch 265, CIFAR-10 Batch 2:  Loss: 0.5111613273620605   Validation Accuracy: 0.5499998927116394\n",
      "Epoch 265, CIFAR-10 Batch 3:  Loss: 0.5302540063858032   Validation Accuracy: 0.5509999394416809\n",
      "Epoch 265, CIFAR-10 Batch 4:  Loss: 0.4909117817878723   Validation Accuracy: 0.5525999665260315\n",
      "Epoch 265, CIFAR-10 Batch 5:  Loss: 0.5290575623512268   Validation Accuracy: 0.5519998669624329\n",
      "Epoch 266, CIFAR-10 Batch 1:  Loss: 0.48202624917030334  Validation Accuracy: 0.5451999306678772\n",
      "Epoch 266, CIFAR-10 Batch 2:  Loss: 0.5106407403945923   Validation Accuracy: 0.5433999300003052\n",
      "Epoch 266, CIFAR-10 Batch 3:  Loss: 0.5308039784431458   Validation Accuracy: 0.548799991607666\n",
      "Epoch 266, CIFAR-10 Batch 4:  Loss: 0.4921746850013733   Validation Accuracy: 0.5529999136924744\n",
      "Epoch 266, CIFAR-10 Batch 5:  Loss: 0.5246275067329407   Validation Accuracy: 0.5539999604225159\n",
      "Epoch 267, CIFAR-10 Batch 1:  Loss: 0.48281556367874146  Validation Accuracy: 0.5567999482154846\n",
      "Epoch 267, CIFAR-10 Batch 2:  Loss: 0.513051450252533    Validation Accuracy: 0.5425999164581299\n",
      "Epoch 267, CIFAR-10 Batch 3:  Loss: 0.5339457392692566   Validation Accuracy: 0.5453999638557434\n",
      "Epoch 267, CIFAR-10 Batch 4:  Loss: 0.4905296266078949   Validation Accuracy: 0.5537999272346497\n",
      "Epoch 267, CIFAR-10 Batch 5:  Loss: 0.5259320735931396   Validation Accuracy: 0.5429999828338623\n",
      "Epoch 268, CIFAR-10 Batch 1:  Loss: 0.4829751253128052   Validation Accuracy: 0.5493999123573303\n",
      "Epoch 268, CIFAR-10 Batch 2:  Loss: 0.5133869051933289   Validation Accuracy: 0.5393999218940735\n",
      "Epoch 268, CIFAR-10 Batch 3:  Loss: 0.5311993360519409   Validation Accuracy: 0.5511999130249023\n",
      "Epoch 268, CIFAR-10 Batch 4:  Loss: 0.4915691018104553   Validation Accuracy: 0.5503999590873718\n",
      "Epoch 268, CIFAR-10 Batch 5:  Loss: 0.5252100229263306   Validation Accuracy: 0.5527999401092529\n",
      "Epoch 269, CIFAR-10 Batch 1:  Loss: 0.48199474811553955  Validation Accuracy: 0.5513999462127686\n",
      "Epoch 269, CIFAR-10 Batch 2:  Loss: 0.5105211734771729   Validation Accuracy: 0.5471999645233154\n",
      "Epoch 269, CIFAR-10 Batch 3:  Loss: 0.528766393661499    Validation Accuracy: 0.5479999780654907\n",
      "Epoch 269, CIFAR-10 Batch 4:  Loss: 0.49539992213249207  Validation Accuracy: 0.5495999455451965\n",
      "Epoch 269, CIFAR-10 Batch 5:  Loss: 0.5257984399795532   Validation Accuracy: 0.5482000112533569\n",
      "Epoch 270, CIFAR-10 Batch 1:  Loss: 0.4885428547859192   Validation Accuracy: 0.5481999516487122\n",
      "Epoch 270, CIFAR-10 Batch 2:  Loss: 0.5131583213806152   Validation Accuracy: 0.5457999110221863\n",
      "Epoch 270, CIFAR-10 Batch 3:  Loss: 0.5333701372146606   Validation Accuracy: 0.5387998819351196\n",
      "Epoch 270, CIFAR-10 Batch 4:  Loss: 0.49229922890663147  Validation Accuracy: 0.5379999279975891\n",
      "Epoch 270, CIFAR-10 Batch 5:  Loss: 0.5300759673118591   Validation Accuracy: 0.5503999590873718\n",
      "Epoch 271, CIFAR-10 Batch 1:  Loss: 0.48603156208992004  Validation Accuracy: 0.5425999760627747\n",
      "Epoch 271, CIFAR-10 Batch 2:  Loss: 0.5131185054779053   Validation Accuracy: 0.543999969959259\n",
      "Epoch 271, CIFAR-10 Batch 3:  Loss: 0.5334073901176453   Validation Accuracy: 0.5423999428749084\n",
      "Epoch 271, CIFAR-10 Batch 4:  Loss: 0.49035200476646423  Validation Accuracy: 0.5537999868392944\n",
      "Epoch 271, CIFAR-10 Batch 5:  Loss: 0.524709165096283    Validation Accuracy: 0.5475999116897583\n",
      "Epoch 272, CIFAR-10 Batch 1:  Loss: 0.48046261072158813  Validation Accuracy: 0.5483999252319336\n",
      "Epoch 272, CIFAR-10 Batch 2:  Loss: 0.5120943188667297   Validation Accuracy: 0.5475999116897583\n",
      "Epoch 272, CIFAR-10 Batch 3:  Loss: 0.529776394367218    Validation Accuracy: 0.53739994764328\n",
      "Epoch 272, CIFAR-10 Batch 4:  Loss: 0.49032434821128845  Validation Accuracy: 0.5511999726295471\n",
      "Epoch 272, CIFAR-10 Batch 5:  Loss: 0.5262345671653748   Validation Accuracy: 0.5471999645233154\n",
      "Epoch 273, CIFAR-10 Batch 1:  Loss: 0.4812975525856018   Validation Accuracy: 0.5443999767303467\n",
      "Epoch 273, CIFAR-10 Batch 2:  Loss: 0.5167654752731323   Validation Accuracy: 0.5387998819351196\n",
      "Epoch 273, CIFAR-10 Batch 3:  Loss: 0.5324630737304688   Validation Accuracy: 0.547999918460846\n",
      "Epoch 273, CIFAR-10 Batch 4:  Loss: 0.4909607470035553   Validation Accuracy: 0.5413999557495117\n",
      "Epoch 273, CIFAR-10 Batch 5:  Loss: 0.5250586271286011   Validation Accuracy: 0.5507999658584595\n",
      "Epoch 274, CIFAR-10 Batch 1:  Loss: 0.4791702628135681   Validation Accuracy: 0.5497999787330627\n",
      "Epoch 274, CIFAR-10 Batch 2:  Loss: 0.5114082098007202   Validation Accuracy: 0.5463998913764954\n",
      "Epoch 274, CIFAR-10 Batch 3:  Loss: 0.5286842584609985   Validation Accuracy: 0.5539999604225159\n",
      "Epoch 274, CIFAR-10 Batch 4:  Loss: 0.49067550897598267  Validation Accuracy: 0.5439999103546143\n",
      "Epoch 274, CIFAR-10 Batch 5:  Loss: 0.5366871953010559   Validation Accuracy: 0.5495999455451965\n",
      "Epoch 275, CIFAR-10 Batch 1:  Loss: 0.47946614027023315  Validation Accuracy: 0.5525999665260315\n",
      "Epoch 275, CIFAR-10 Batch 2:  Loss: 0.5103427171707153   Validation Accuracy: 0.5447999238967896\n",
      "Epoch 275, CIFAR-10 Batch 3:  Loss: 0.5273484587669373   Validation Accuracy: 0.5455999374389648\n",
      "Epoch 275, CIFAR-10 Batch 4:  Loss: 0.49065059423446655  Validation Accuracy: 0.5491999387741089\n",
      "Epoch 275, CIFAR-10 Batch 5:  Loss: 0.5244028568267822   Validation Accuracy: 0.5533999800682068\n",
      "Epoch 276, CIFAR-10 Batch 1:  Loss: 0.4792731702327728   Validation Accuracy: 0.5345999598503113\n",
      "Epoch 276, CIFAR-10 Batch 2:  Loss: 0.5171376466751099   Validation Accuracy: 0.5505999326705933\n",
      "Epoch 276, CIFAR-10 Batch 3:  Loss: 0.5297839045524597   Validation Accuracy: 0.5423999428749084\n",
      "Epoch 276, CIFAR-10 Batch 4:  Loss: 0.49080801010131836  Validation Accuracy: 0.5459999442100525\n",
      "Epoch 276, CIFAR-10 Batch 5:  Loss: 0.5245501399040222   Validation Accuracy: 0.5539999008178711\n",
      "Epoch 277, CIFAR-10 Batch 1:  Loss: 0.4806923270225525   Validation Accuracy: 0.5435999035835266\n",
      "Epoch 277, CIFAR-10 Batch 2:  Loss: 0.5118285417556763   Validation Accuracy: 0.5477999448776245\n",
      "Epoch 277, CIFAR-10 Batch 3:  Loss: 0.5277745723724365   Validation Accuracy: 0.5519999265670776\n",
      "Epoch 277, CIFAR-10 Batch 4:  Loss: 0.4902944564819336   Validation Accuracy: 0.549799919128418\n",
      "Epoch 277, CIFAR-10 Batch 5:  Loss: 0.5246880054473877   Validation Accuracy: 0.5553998947143555\n",
      "Epoch 278, CIFAR-10 Batch 1:  Loss: 0.479045569896698    Validation Accuracy: 0.5467999577522278\n",
      "Epoch 278, CIFAR-10 Batch 2:  Loss: 0.5133283138275146   Validation Accuracy: 0.540399968624115\n",
      "Epoch 278, CIFAR-10 Batch 3:  Loss: 0.5274254679679871   Validation Accuracy: 0.5491999387741089\n",
      "Epoch 278, CIFAR-10 Batch 4:  Loss: 0.49035683274269104  Validation Accuracy: 0.5543999075889587\n",
      "Epoch 278, CIFAR-10 Batch 5:  Loss: 0.5263440608978271   Validation Accuracy: 0.5541999340057373\n",
      "Epoch 279, CIFAR-10 Batch 1:  Loss: 0.482078492641449    Validation Accuracy: 0.545799970626831\n",
      "Epoch 279, CIFAR-10 Batch 2:  Loss: 0.5105099678039551   Validation Accuracy: 0.5495998859405518\n",
      "Epoch 279, CIFAR-10 Batch 3:  Loss: 0.5274360179901123   Validation Accuracy: 0.547999918460846\n",
      "Epoch 279, CIFAR-10 Batch 4:  Loss: 0.4936800003051758   Validation Accuracy: 0.5473999381065369\n",
      "Epoch 279, CIFAR-10 Batch 5:  Loss: 0.5244192481040955   Validation Accuracy: 0.5459999442100525\n",
      "Epoch 280, CIFAR-10 Batch 1:  Loss: 0.4788888990879059   Validation Accuracy: 0.5485999584197998\n",
      "Epoch 280, CIFAR-10 Batch 2:  Loss: 0.5133888721466064   Validation Accuracy: 0.5467999577522278\n",
      "Epoch 280, CIFAR-10 Batch 3:  Loss: 0.5277095437049866   Validation Accuracy: 0.5529999136924744\n",
      "Epoch 280, CIFAR-10 Batch 4:  Loss: 0.4906976819038391   Validation Accuracy: 0.5478000044822693\n",
      "Epoch 280, CIFAR-10 Batch 5:  Loss: 0.5255141258239746   Validation Accuracy: 0.5477999448776245\n",
      "Epoch 281, CIFAR-10 Batch 1:  Loss: 0.47919440269470215  Validation Accuracy: 0.539199948310852\n",
      "Epoch 281, CIFAR-10 Batch 2:  Loss: 0.5158336758613586   Validation Accuracy: 0.5423998832702637\n",
      "Epoch 281, CIFAR-10 Batch 3:  Loss: 0.5287314653396606   Validation Accuracy: 0.5495998859405518\n",
      "Epoch 281, CIFAR-10 Batch 4:  Loss: 0.4914863109588623   Validation Accuracy: 0.5523999333381653\n",
      "Epoch 281, CIFAR-10 Batch 5:  Loss: 0.5245503783226013   Validation Accuracy: 0.5351999998092651\n",
      "Epoch 282, CIFAR-10 Batch 1:  Loss: 0.48073118925094604  Validation Accuracy: 0.549799919128418\n",
      "Epoch 282, CIFAR-10 Batch 2:  Loss: 0.513524055480957    Validation Accuracy: 0.5343999862670898\n",
      "Epoch 282, CIFAR-10 Batch 3:  Loss: 0.528535008430481    Validation Accuracy: 0.5351999402046204\n",
      "Epoch 282, CIFAR-10 Batch 4:  Loss: 0.49047547578811646  Validation Accuracy: 0.5431999564170837\n",
      "Epoch 282, CIFAR-10 Batch 5:  Loss: 0.5244269371032715   Validation Accuracy: 0.5471999645233154\n",
      "Epoch 283, CIFAR-10 Batch 1:  Loss: 0.4788752794265747   Validation Accuracy: 0.5343999266624451\n",
      "Epoch 283, CIFAR-10 Batch 2:  Loss: 0.515133261680603    Validation Accuracy: 0.5385999083518982\n",
      "Epoch 283, CIFAR-10 Batch 3:  Loss: 0.5312027931213379   Validation Accuracy: 0.5573999285697937\n",
      "Epoch 283, CIFAR-10 Batch 4:  Loss: 0.49503976106643677  Validation Accuracy: 0.5475999116897583\n",
      "Epoch 283, CIFAR-10 Batch 5:  Loss: 0.5257596969604492   Validation Accuracy: 0.5437999367713928\n",
      "Epoch 284, CIFAR-10 Batch 1:  Loss: 0.4804146885871887   Validation Accuracy: 0.5505999326705933\n",
      "Epoch 284, CIFAR-10 Batch 2:  Loss: 0.5115916132926941   Validation Accuracy: 0.54339998960495\n",
      "Epoch 284, CIFAR-10 Batch 3:  Loss: 0.5274074673652649   Validation Accuracy: 0.5477999448776245\n",
      "Epoch 284, CIFAR-10 Batch 4:  Loss: 0.49033376574516296  Validation Accuracy: 0.5513999462127686\n",
      "Epoch 284, CIFAR-10 Batch 5:  Loss: 0.5244490504264832   Validation Accuracy: 0.5509999394416809\n",
      "Epoch 285, CIFAR-10 Batch 1:  Loss: 0.480180561542511    Validation Accuracy: 0.5473998785018921\n",
      "Epoch 285, CIFAR-10 Batch 2:  Loss: 0.5147894024848938   Validation Accuracy: 0.5483999848365784\n",
      "Epoch 285, CIFAR-10 Batch 3:  Loss: 0.5277514457702637   Validation Accuracy: 0.5455999374389648\n",
      "Epoch 285, CIFAR-10 Batch 4:  Loss: 0.4904016852378845   Validation Accuracy: 0.5467999577522278\n",
      "Epoch 285, CIFAR-10 Batch 5:  Loss: 0.5253199338912964   Validation Accuracy: 0.5463999509811401\n",
      "Epoch 286, CIFAR-10 Batch 1:  Loss: 0.4808228015899658   Validation Accuracy: 0.5449999570846558\n",
      "Epoch 286, CIFAR-10 Batch 2:  Loss: 0.5104844570159912   Validation Accuracy: 0.5513999462127686\n",
      "Epoch 286, CIFAR-10 Batch 3:  Loss: 0.5310882925987244   Validation Accuracy: 0.5441999435424805\n",
      "Epoch 286, CIFAR-10 Batch 4:  Loss: 0.4904273748397827   Validation Accuracy: 0.5571999549865723\n",
      "Epoch 286, CIFAR-10 Batch 5:  Loss: 0.5245110988616943   Validation Accuracy: 0.5533999800682068\n",
      "Epoch 287, CIFAR-10 Batch 1:  Loss: 0.4802688956260681   Validation Accuracy: 0.5459999442100525\n",
      "Epoch 287, CIFAR-10 Batch 2:  Loss: 0.5139010548591614   Validation Accuracy: 0.5403999090194702\n",
      "Epoch 287, CIFAR-10 Batch 3:  Loss: 0.5288280248641968   Validation Accuracy: 0.5441999435424805\n",
      "Epoch 287, CIFAR-10 Batch 4:  Loss: 0.49100273847579956  Validation Accuracy: 0.5529999732971191\n",
      "Epoch 287, CIFAR-10 Batch 5:  Loss: 0.5271086692810059   Validation Accuracy: 0.5437999367713928\n",
      "Epoch 288, CIFAR-10 Batch 1:  Loss: 0.4792962968349457   Validation Accuracy: 0.5389999151229858\n",
      "Epoch 288, CIFAR-10 Batch 2:  Loss: 0.5113152265548706   Validation Accuracy: 0.542199969291687\n",
      "Epoch 288, CIFAR-10 Batch 3:  Loss: 0.5354014039039612   Validation Accuracy: 0.5443999767303467\n",
      "Epoch 288, CIFAR-10 Batch 4:  Loss: 0.4911985993385315   Validation Accuracy: 0.5505999326705933\n",
      "Epoch 288, CIFAR-10 Batch 5:  Loss: 0.5244928002357483   Validation Accuracy: 0.5525999665260315\n",
      "Epoch 289, CIFAR-10 Batch 1:  Loss: 0.4795248210430145   Validation Accuracy: 0.5487999320030212\n",
      "Epoch 289, CIFAR-10 Batch 2:  Loss: 0.5111846923828125   Validation Accuracy: 0.5465999245643616\n",
      "Epoch 289, CIFAR-10 Batch 3:  Loss: 0.529353678226471    Validation Accuracy: 0.5447999238967896\n",
      "Epoch 289, CIFAR-10 Batch 4:  Loss: 0.49076637625694275  Validation Accuracy: 0.5525999069213867\n",
      "Epoch 289, CIFAR-10 Batch 5:  Loss: 0.5293200612068176   Validation Accuracy: 0.5531999468803406\n",
      "Epoch 290, CIFAR-10 Batch 1:  Loss: 0.47935423254966736  Validation Accuracy: 0.5477999448776245\n",
      "Epoch 290, CIFAR-10 Batch 2:  Loss: 0.5209424495697021   Validation Accuracy: 0.5429999232292175\n",
      "Epoch 290, CIFAR-10 Batch 3:  Loss: 0.5278885960578918   Validation Accuracy: 0.5479999780654907\n",
      "Epoch 290, CIFAR-10 Batch 4:  Loss: 0.4903474450111389   Validation Accuracy: 0.5553998947143555\n",
      "Epoch 290, CIFAR-10 Batch 5:  Loss: 0.5249266624450684   Validation Accuracy: 0.5543999671936035\n",
      "Epoch 291, CIFAR-10 Batch 1:  Loss: 0.479060560464859    Validation Accuracy: 0.5473999977111816\n",
      "Epoch 291, CIFAR-10 Batch 2:  Loss: 0.5102095007896423   Validation Accuracy: 0.5491999387741089\n",
      "Epoch 291, CIFAR-10 Batch 3:  Loss: 0.5304964184761047   Validation Accuracy: 0.545199990272522\n",
      "Epoch 291, CIFAR-10 Batch 4:  Loss: 0.49053362011909485  Validation Accuracy: 0.5499999523162842\n",
      "Epoch 291, CIFAR-10 Batch 5:  Loss: 0.5246114730834961   Validation Accuracy: 0.5453999638557434\n",
      "Epoch 292, CIFAR-10 Batch 1:  Loss: 0.47915327548980713  Validation Accuracy: 0.5411999225616455\n",
      "Epoch 292, CIFAR-10 Batch 2:  Loss: 0.5160374045372009   Validation Accuracy: 0.5465999245643616\n",
      "Epoch 292, CIFAR-10 Batch 3:  Loss: 0.5330665707588196   Validation Accuracy: 0.5287999510765076\n",
      "Epoch 292, CIFAR-10 Batch 4:  Loss: 0.4906739890575409   Validation Accuracy: 0.5523999333381653\n",
      "Epoch 292, CIFAR-10 Batch 5:  Loss: 0.5272455811500549   Validation Accuracy: 0.5445999503135681\n",
      "Epoch 293, CIFAR-10 Batch 1:  Loss: 0.47936809062957764  Validation Accuracy: 0.5329999327659607\n",
      "Epoch 293, CIFAR-10 Batch 2:  Loss: 0.5191956758499146   Validation Accuracy: 0.533799946308136\n",
      "Epoch 293, CIFAR-10 Batch 3:  Loss: 0.5279021859169006   Validation Accuracy: 0.53739994764328\n",
      "Epoch 293, CIFAR-10 Batch 4:  Loss: 0.4903887212276459   Validation Accuracy: 0.5505999326705933\n",
      "Epoch 293, CIFAR-10 Batch 5:  Loss: 0.5249532461166382   Validation Accuracy: 0.5493999719619751\n",
      "Epoch 294, CIFAR-10 Batch 1:  Loss: 0.47931593656539917  Validation Accuracy: 0.5497999787330627\n",
      "Epoch 294, CIFAR-10 Batch 2:  Loss: 0.5104372501373291   Validation Accuracy: 0.5447999238967896\n",
      "Epoch 294, CIFAR-10 Batch 3:  Loss: 0.5310946106910706   Validation Accuracy: 0.5349999666213989\n",
      "Epoch 294, CIFAR-10 Batch 4:  Loss: 0.4903358221054077   Validation Accuracy: 0.5419999361038208\n",
      "Epoch 294, CIFAR-10 Batch 5:  Loss: 0.5276483297348022   Validation Accuracy: 0.5529999732971191\n",
      "Epoch 295, CIFAR-10 Batch 1:  Loss: 0.48207786679267883  Validation Accuracy: 0.5447999835014343\n",
      "Epoch 295, CIFAR-10 Batch 2:  Loss: 0.511617124080658    Validation Accuracy: 0.5491999387741089\n",
      "Epoch 295, CIFAR-10 Batch 3:  Loss: 0.5247651934623718   Validation Accuracy: 0.5475999116897583\n",
      "Epoch 295, CIFAR-10 Batch 4:  Loss: 0.4963909685611725   Validation Accuracy: 0.5413999557495117\n",
      "Epoch 295, CIFAR-10 Batch 5:  Loss: 0.527820885181427    Validation Accuracy: 0.5473999381065369\n",
      "Epoch 296, CIFAR-10 Batch 1:  Loss: 0.47974032163619995  Validation Accuracy: 0.5427999496459961\n",
      "Epoch 296, CIFAR-10 Batch 2:  Loss: 0.5077004432678223   Validation Accuracy: 0.5471999645233154\n",
      "Epoch 296, CIFAR-10 Batch 3:  Loss: 0.5291471481323242   Validation Accuracy: 0.547999918460846\n",
      "Epoch 296, CIFAR-10 Batch 4:  Loss: 0.4903566837310791   Validation Accuracy: 0.5443999171257019\n",
      "Epoch 296, CIFAR-10 Batch 5:  Loss: 0.5245250463485718   Validation Accuracy: 0.5395999550819397\n",
      "Epoch 297, CIFAR-10 Batch 1:  Loss: 0.47907519340515137  Validation Accuracy: 0.53659987449646\n",
      "Epoch 297, CIFAR-10 Batch 2:  Loss: 0.5079303979873657   Validation Accuracy: 0.5425999164581299\n",
      "Epoch 297, CIFAR-10 Batch 3:  Loss: 0.5284050703048706   Validation Accuracy: 0.5401999354362488\n",
      "Epoch 297, CIFAR-10 Batch 4:  Loss: 0.4906070828437805   Validation Accuracy: 0.5397999286651611\n",
      "Epoch 297, CIFAR-10 Batch 5:  Loss: 0.5248492360115051   Validation Accuracy: 0.5459999442100525\n",
      "Epoch 298, CIFAR-10 Batch 1:  Loss: 0.4784698486328125   Validation Accuracy: 0.5439999103546143\n",
      "Epoch 298, CIFAR-10 Batch 2:  Loss: 0.5083632469177246   Validation Accuracy: 0.5487999320030212\n",
      "Epoch 298, CIFAR-10 Batch 3:  Loss: 0.5247341394424438   Validation Accuracy: 0.5429999232292175\n",
      "Epoch 298, CIFAR-10 Batch 4:  Loss: 0.49022048711776733  Validation Accuracy: 0.5532000064849854\n",
      "Epoch 298, CIFAR-10 Batch 5:  Loss: 0.5262554287910461   Validation Accuracy: 0.5443999171257019\n",
      "Epoch 299, CIFAR-10 Batch 1:  Loss: 0.47650155425071716  Validation Accuracy: 0.5383999347686768\n",
      "Epoch 299, CIFAR-10 Batch 2:  Loss: 0.510494589805603    Validation Accuracy: 0.5491999387741089\n",
      "Epoch 299, CIFAR-10 Batch 3:  Loss: 0.5260052680969238   Validation Accuracy: 0.5473999381065369\n",
      "Epoch 299, CIFAR-10 Batch 4:  Loss: 0.49058520793914795  Validation Accuracy: 0.5509999394416809\n",
      "Epoch 299, CIFAR-10 Batch 5:  Loss: 0.5244913697242737   Validation Accuracy: 0.5501999855041504\n",
      "Epoch 300, CIFAR-10 Batch 1:  Loss: 0.4759640097618103   Validation Accuracy: 0.5495999455451965\n",
      "Epoch 300, CIFAR-10 Batch 2:  Loss: 0.5102440714836121   Validation Accuracy: 0.5501999258995056\n",
      "Epoch 300, CIFAR-10 Batch 3:  Loss: 0.5244256854057312   Validation Accuracy: 0.5513999462127686\n",
      "Epoch 300, CIFAR-10 Batch 4:  Loss: 0.49384719133377075  Validation Accuracy: 0.5453999042510986\n",
      "Epoch 300, CIFAR-10 Batch 5:  Loss: 0.5243980884552002   Validation Accuracy: 0.5437999367713928\n",
      "Epoch 301, CIFAR-10 Batch 1:  Loss: 0.4803731441497803   Validation Accuracy: 0.5443999767303467\n",
      "Epoch 301, CIFAR-10 Batch 2:  Loss: 0.5073611736297607   Validation Accuracy: 0.5489999055862427\n",
      "Epoch 301, CIFAR-10 Batch 3:  Loss: 0.5244722962379456   Validation Accuracy: 0.5449999570846558\n",
      "Epoch 301, CIFAR-10 Batch 4:  Loss: 0.4931880533695221   Validation Accuracy: 0.5433999300003052\n",
      "Epoch 301, CIFAR-10 Batch 5:  Loss: 0.5248002409934998   Validation Accuracy: 0.55159991979599\n",
      "Epoch 302, CIFAR-10 Batch 1:  Loss: 0.48035383224487305  Validation Accuracy: 0.5433999300003052\n",
      "Epoch 302, CIFAR-10 Batch 2:  Loss: 0.5074322819709778   Validation Accuracy: 0.5479999780654907\n",
      "Epoch 302, CIFAR-10 Batch 3:  Loss: 0.5278058052062988   Validation Accuracy: 0.5449999570846558\n",
      "Epoch 302, CIFAR-10 Batch 4:  Loss: 0.4907839298248291   Validation Accuracy: 0.5435999035835266\n",
      "Epoch 302, CIFAR-10 Batch 5:  Loss: 0.5246413350105286   Validation Accuracy: 0.5460000038146973\n",
      "Epoch 303, CIFAR-10 Batch 1:  Loss: 0.4761563539505005   Validation Accuracy: 0.545799970626831\n",
      "Epoch 303, CIFAR-10 Batch 2:  Loss: 0.5079488754272461   Validation Accuracy: 0.5417999625205994\n",
      "Epoch 303, CIFAR-10 Batch 3:  Loss: 0.5245807766914368   Validation Accuracy: 0.5441999435424805\n",
      "Epoch 303, CIFAR-10 Batch 4:  Loss: 0.4904348850250244   Validation Accuracy: 0.546799898147583\n",
      "Epoch 303, CIFAR-10 Batch 5:  Loss: 0.5266528725624084   Validation Accuracy: 0.5403999090194702\n",
      "Epoch 304, CIFAR-10 Batch 1:  Loss: 0.4771811366081238   Validation Accuracy: 0.5481999516487122\n",
      "Epoch 304, CIFAR-10 Batch 2:  Loss: 0.510728657245636    Validation Accuracy: 0.5443999767303467\n",
      "Epoch 304, CIFAR-10 Batch 3:  Loss: 0.5245399475097656   Validation Accuracy: 0.5483999252319336\n",
      "Epoch 304, CIFAR-10 Batch 4:  Loss: 0.4902135133743286   Validation Accuracy: 0.5507999062538147\n",
      "Epoch 304, CIFAR-10 Batch 5:  Loss: 0.524477481842041    Validation Accuracy: 0.5586000084877014\n",
      "Epoch 305, CIFAR-10 Batch 1:  Loss: 0.4779447317123413   Validation Accuracy: 0.5509999394416809\n",
      "Epoch 305, CIFAR-10 Batch 2:  Loss: 0.5073896646499634   Validation Accuracy: 0.5501999258995056\n",
      "Epoch 305, CIFAR-10 Batch 3:  Loss: 0.5245934724807739   Validation Accuracy: 0.5461999177932739\n",
      "Epoch 305, CIFAR-10 Batch 4:  Loss: 0.4906046390533447   Validation Accuracy: 0.549799919128418\n",
      "Epoch 305, CIFAR-10 Batch 5:  Loss: 0.524596095085144    Validation Accuracy: 0.5529999136924744\n",
      "Epoch 306, CIFAR-10 Batch 1:  Loss: 0.4801165461540222   Validation Accuracy: 0.547999918460846\n",
      "Epoch 306, CIFAR-10 Batch 2:  Loss: 0.5079014897346497   Validation Accuracy: 0.5477999448776245\n",
      "Epoch 306, CIFAR-10 Batch 3:  Loss: 0.5249099731445312   Validation Accuracy: 0.555199921131134\n",
      "Epoch 306, CIFAR-10 Batch 4:  Loss: 0.4916958808898926   Validation Accuracy: 0.5483999252319336\n",
      "Epoch 306, CIFAR-10 Batch 5:  Loss: 0.5250019431114197   Validation Accuracy: 0.5427998900413513\n",
      "Epoch 307, CIFAR-10 Batch 1:  Loss: 0.47926294803619385  Validation Accuracy: 0.5421999096870422\n",
      "Epoch 307, CIFAR-10 Batch 2:  Loss: 0.507519543170929    Validation Accuracy: 0.5523999333381653\n",
      "Epoch 307, CIFAR-10 Batch 3:  Loss: 0.5304697751998901   Validation Accuracy: 0.5375999808311462\n",
      "Epoch 307, CIFAR-10 Batch 4:  Loss: 0.49027231335639954  Validation Accuracy: 0.5501999258995056\n",
      "Epoch 307, CIFAR-10 Batch 5:  Loss: 0.524400532245636    Validation Accuracy: 0.5575999617576599\n",
      "Epoch 308, CIFAR-10 Batch 1:  Loss: 0.4792449176311493   Validation Accuracy: 0.5473999977111816\n",
      "Epoch 308, CIFAR-10 Batch 2:  Loss: 0.5060638189315796   Validation Accuracy: 0.5461999177932739\n",
      "Epoch 308, CIFAR-10 Batch 3:  Loss: 0.5249403119087219   Validation Accuracy: 0.5461999773979187\n",
      "Epoch 308, CIFAR-10 Batch 4:  Loss: 0.49085479974746704  Validation Accuracy: 0.5507999062538147\n",
      "Epoch 308, CIFAR-10 Batch 5:  Loss: 0.5245589017868042   Validation Accuracy: 0.5482000112533569\n",
      "Epoch 309, CIFAR-10 Batch 1:  Loss: 0.48187175393104553  Validation Accuracy: 0.546799898147583\n",
      "Epoch 309, CIFAR-10 Batch 2:  Loss: 0.5047137141227722   Validation Accuracy: 0.5529999136924744\n",
      "Epoch 309, CIFAR-10 Batch 3:  Loss: 0.5245711803436279   Validation Accuracy: 0.5515999794006348\n",
      "Epoch 309, CIFAR-10 Batch 4:  Loss: 0.4903731942176819   Validation Accuracy: 0.5485999584197998\n",
      "Epoch 309, CIFAR-10 Batch 5:  Loss: 0.5243679881095886   Validation Accuracy: 0.5529999136924744\n",
      "Epoch 310, CIFAR-10 Batch 1:  Loss: 0.47607824206352234  Validation Accuracy: 0.5477999448776245\n",
      "Epoch 310, CIFAR-10 Batch 2:  Loss: 0.5077314972877502   Validation Accuracy: 0.5491999387741089\n",
      "Epoch 310, CIFAR-10 Batch 3:  Loss: 0.5248417258262634   Validation Accuracy: 0.5487999320030212\n",
      "Epoch 310, CIFAR-10 Batch 4:  Loss: 0.4902317523956299   Validation Accuracy: 0.5537999272346497\n",
      "Epoch 310, CIFAR-10 Batch 5:  Loss: 0.5258030891418457   Validation Accuracy: 0.5531999468803406\n",
      "Epoch 311, CIFAR-10 Batch 1:  Loss: 0.4769246578216553   Validation Accuracy: 0.5441998839378357\n",
      "Epoch 311, CIFAR-10 Batch 2:  Loss: 0.5074208974838257   Validation Accuracy: 0.5441999435424805\n",
      "Epoch 311, CIFAR-10 Batch 3:  Loss: 0.5247091054916382   Validation Accuracy: 0.5469999313354492\n",
      "Epoch 311, CIFAR-10 Batch 4:  Loss: 0.4904736578464508   Validation Accuracy: 0.549799919128418\n",
      "Epoch 311, CIFAR-10 Batch 5:  Loss: 0.524563193321228    Validation Accuracy: 0.546799898147583\n",
      "Epoch 312, CIFAR-10 Batch 1:  Loss: 0.476090669631958    Validation Accuracy: 0.5447998642921448\n",
      "Epoch 312, CIFAR-10 Batch 2:  Loss: 0.508551299571991    Validation Accuracy: 0.5475999116897583\n",
      "Epoch 312, CIFAR-10 Batch 3:  Loss: 0.5247070789337158   Validation Accuracy: 0.5419999361038208\n",
      "Epoch 312, CIFAR-10 Batch 4:  Loss: 0.49024873971939087  Validation Accuracy: 0.5363999605178833\n",
      "Epoch 312, CIFAR-10 Batch 5:  Loss: 0.5243927240371704   Validation Accuracy: 0.5551999807357788\n",
      "Epoch 313, CIFAR-10 Batch 1:  Loss: 0.476592481136322    Validation Accuracy: 0.5499999523162842\n",
      "Epoch 313, CIFAR-10 Batch 2:  Loss: 0.5045909881591797   Validation Accuracy: 0.5505999326705933\n",
      "Epoch 313, CIFAR-10 Batch 3:  Loss: 0.5258569717407227   Validation Accuracy: 0.5505999326705933\n",
      "Epoch 313, CIFAR-10 Batch 4:  Loss: 0.49033451080322266  Validation Accuracy: 0.5413999557495117\n",
      "Epoch 313, CIFAR-10 Batch 5:  Loss: 0.5272449254989624   Validation Accuracy: 0.5457999110221863\n",
      "Epoch 314, CIFAR-10 Batch 1:  Loss: 0.4769420027732849   Validation Accuracy: 0.5463999509811401\n",
      "Epoch 314, CIFAR-10 Batch 2:  Loss: 0.5047187805175781   Validation Accuracy: 0.5471999049186707\n",
      "Epoch 314, CIFAR-10 Batch 3:  Loss: 0.5248755216598511   Validation Accuracy: 0.5389999151229858\n",
      "Epoch 314, CIFAR-10 Batch 4:  Loss: 0.4902123212814331   Validation Accuracy: 0.5435999631881714\n",
      "Epoch 314, CIFAR-10 Batch 5:  Loss: 0.5296604037284851   Validation Accuracy: 0.5401999354362488\n",
      "Epoch 315, CIFAR-10 Batch 1:  Loss: 0.47611311078071594  Validation Accuracy: 0.5388000011444092\n",
      "Epoch 315, CIFAR-10 Batch 2:  Loss: 0.5046482086181641   Validation Accuracy: 0.5459999442100525\n",
      "Epoch 315, CIFAR-10 Batch 3:  Loss: 0.524601399898529    Validation Accuracy: 0.5521999597549438\n",
      "Epoch 315, CIFAR-10 Batch 4:  Loss: 0.49136850237846375  Validation Accuracy: 0.5407999157905579\n",
      "Epoch 315, CIFAR-10 Batch 5:  Loss: 0.5279822945594788   Validation Accuracy: 0.5455999374389648\n",
      "Epoch 316, CIFAR-10 Batch 1:  Loss: 0.47612419724464417  Validation Accuracy: 0.5461999177932739\n",
      "Epoch 316, CIFAR-10 Batch 2:  Loss: 0.5073347687721252   Validation Accuracy: 0.549799919128418\n",
      "Epoch 316, CIFAR-10 Batch 3:  Loss: 0.5247993469238281   Validation Accuracy: 0.5523999333381653\n",
      "Epoch 316, CIFAR-10 Batch 4:  Loss: 0.4952127933502197   Validation Accuracy: 0.5493999123573303\n",
      "Epoch 316, CIFAR-10 Batch 5:  Loss: 0.5246803760528564   Validation Accuracy: 0.5449999570846558\n",
      "Epoch 317, CIFAR-10 Batch 1:  Loss: 0.4759553074836731   Validation Accuracy: 0.538599967956543\n",
      "Epoch 317, CIFAR-10 Batch 2:  Loss: 0.5052627325057983   Validation Accuracy: 0.5433999300003052\n",
      "Epoch 317, CIFAR-10 Batch 3:  Loss: 0.5285030603408813   Validation Accuracy: 0.5393999218940735\n",
      "Epoch 317, CIFAR-10 Batch 4:  Loss: 0.49021482467651367  Validation Accuracy: 0.5451999306678772\n",
      "Epoch 317, CIFAR-10 Batch 5:  Loss: 0.5248910784721375   Validation Accuracy: 0.5463999509811401\n",
      "Epoch 318, CIFAR-10 Batch 1:  Loss: 0.47605907917022705  Validation Accuracy: 0.5423998832702637\n",
      "Epoch 318, CIFAR-10 Batch 2:  Loss: 0.5045996308326721   Validation Accuracy: 0.5445999503135681\n",
      "Epoch 318, CIFAR-10 Batch 3:  Loss: 0.5244694352149963   Validation Accuracy: 0.554599940776825\n",
      "Epoch 318, CIFAR-10 Batch 4:  Loss: 0.49035435914993286  Validation Accuracy: 0.545799970626831\n",
      "Epoch 318, CIFAR-10 Batch 5:  Loss: 0.5245251059532166   Validation Accuracy: 0.5493999123573303\n",
      "Epoch 319, CIFAR-10 Batch 1:  Loss: 0.47726890444755554  Validation Accuracy: 0.5517998933792114\n",
      "Epoch 319, CIFAR-10 Batch 2:  Loss: 0.5075063109397888   Validation Accuracy: 0.543999969959259\n",
      "Epoch 319, CIFAR-10 Batch 3:  Loss: 0.5245147943496704   Validation Accuracy: 0.5445998907089233\n",
      "Epoch 319, CIFAR-10 Batch 4:  Loss: 0.49047788977622986  Validation Accuracy: 0.5541999340057373\n",
      "Epoch 319, CIFAR-10 Batch 5:  Loss: 0.52481609582901     Validation Accuracy: 0.5483999252319336\n",
      "Epoch 320, CIFAR-10 Batch 1:  Loss: 0.4762551784515381   Validation Accuracy: 0.5539999008178711\n",
      "Epoch 320, CIFAR-10 Batch 2:  Loss: 0.5073511600494385   Validation Accuracy: 0.5585999488830566\n",
      "Epoch 320, CIFAR-10 Batch 3:  Loss: 0.524511456489563    Validation Accuracy: 0.5477999448776245\n",
      "Epoch 320, CIFAR-10 Batch 4:  Loss: 0.4904923439025879   Validation Accuracy: 0.5475999712944031\n",
      "Epoch 320, CIFAR-10 Batch 5:  Loss: 0.5243980288505554   Validation Accuracy: 0.5465999245643616\n",
      "Epoch 321, CIFAR-10 Batch 1:  Loss: 0.48023197054862976  Validation Accuracy: 0.5367999076843262\n",
      "Epoch 321, CIFAR-10 Batch 2:  Loss: 0.5046364068984985   Validation Accuracy: 0.5475999116897583\n",
      "Epoch 321, CIFAR-10 Batch 3:  Loss: 0.5244167447090149   Validation Accuracy: 0.5537999868392944\n",
      "Epoch 321, CIFAR-10 Batch 4:  Loss: 0.4909869134426117   Validation Accuracy: 0.5427999496459961\n",
      "Epoch 321, CIFAR-10 Batch 5:  Loss: 0.5271217226982117   Validation Accuracy: 0.5483999252319336\n",
      "Epoch 322, CIFAR-10 Batch 1:  Loss: 0.47684580087661743  Validation Accuracy: 0.5445999503135681\n",
      "Epoch 322, CIFAR-10 Batch 2:  Loss: 0.5046101808547974   Validation Accuracy: 0.5431999564170837\n",
      "Epoch 322, CIFAR-10 Batch 3:  Loss: 0.5252652168273926   Validation Accuracy: 0.5449999570846558\n",
      "Epoch 322, CIFAR-10 Batch 4:  Loss: 0.49046581983566284  Validation Accuracy: 0.5527999401092529\n",
      "Epoch 322, CIFAR-10 Batch 5:  Loss: 0.5247158408164978   Validation Accuracy: 0.5489999651908875\n",
      "Epoch 323, CIFAR-10 Batch 1:  Loss: 0.47698330879211426  Validation Accuracy: 0.5477999448776245\n",
      "Epoch 323, CIFAR-10 Batch 2:  Loss: 0.5060732364654541   Validation Accuracy: 0.554599940776825\n",
      "Epoch 323, CIFAR-10 Batch 3:  Loss: 0.5328114032745361   Validation Accuracy: 0.5411999225616455\n",
      "Epoch 323, CIFAR-10 Batch 4:  Loss: 0.4902188777923584   Validation Accuracy: 0.5407999157905579\n",
      "Epoch 323, CIFAR-10 Batch 5:  Loss: 0.5278112888336182   Validation Accuracy: 0.5473999381065369\n",
      "Epoch 324, CIFAR-10 Batch 1:  Loss: 0.4759129285812378   Validation Accuracy: 0.5473999381065369\n",
      "Epoch 324, CIFAR-10 Batch 2:  Loss: 0.5073620676994324   Validation Accuracy: 0.5477999448776245\n",
      "Epoch 324, CIFAR-10 Batch 3:  Loss: 0.5245901346206665   Validation Accuracy: 0.5419999361038208\n",
      "Epoch 324, CIFAR-10 Batch 4:  Loss: 0.4909346103668213   Validation Accuracy: 0.5487999320030212\n",
      "Epoch 324, CIFAR-10 Batch 5:  Loss: 0.5256901979446411   Validation Accuracy: 0.5411999225616455\n",
      "Epoch 325, CIFAR-10 Batch 1:  Loss: 0.47694024443626404  Validation Accuracy: 0.5417999029159546\n",
      "Epoch 325, CIFAR-10 Batch 2:  Loss: 0.504803478717804    Validation Accuracy: 0.5423999428749084\n",
      "Epoch 325, CIFAR-10 Batch 3:  Loss: 0.524470865726471    Validation Accuracy: 0.5489999651908875\n",
      "Epoch 325, CIFAR-10 Batch 4:  Loss: 0.49632564187049866  Validation Accuracy: 0.5417999029159546\n",
      "Epoch 325, CIFAR-10 Batch 5:  Loss: 0.5260905027389526   Validation Accuracy: 0.5405999422073364\n",
      "Epoch 326, CIFAR-10 Batch 1:  Loss: 0.4759707450866699   Validation Accuracy: 0.5489999055862427\n",
      "Epoch 326, CIFAR-10 Batch 2:  Loss: 0.5075148344039917   Validation Accuracy: 0.5523999333381653\n",
      "Epoch 326, CIFAR-10 Batch 3:  Loss: 0.5274540185928345   Validation Accuracy: 0.5519999265670776\n",
      "Epoch 326, CIFAR-10 Batch 4:  Loss: 0.4901900291442871   Validation Accuracy: 0.5539999008178711\n",
      "Epoch 326, CIFAR-10 Batch 5:  Loss: 0.5255192518234253   Validation Accuracy: 0.5529999136924744\n",
      "Epoch 327, CIFAR-10 Batch 1:  Loss: 0.47879528999328613  Validation Accuracy: 0.5453999042510986\n",
      "Epoch 327, CIFAR-10 Batch 2:  Loss: 0.5080245733261108   Validation Accuracy: 0.5428000092506409\n",
      "Epoch 327, CIFAR-10 Batch 3:  Loss: 0.5253853797912598   Validation Accuracy: 0.543999969959259\n",
      "Epoch 327, CIFAR-10 Batch 4:  Loss: 0.49017441272735596  Validation Accuracy: 0.5521999001502991\n",
      "Epoch 327, CIFAR-10 Batch 5:  Loss: 0.5276025533676147   Validation Accuracy: 0.5343999862670898\n",
      "Epoch 328, CIFAR-10 Batch 1:  Loss: 0.47760289907455444  Validation Accuracy: 0.5407999157905579\n",
      "Epoch 328, CIFAR-10 Batch 2:  Loss: 0.5046812295913696   Validation Accuracy: 0.548799991607666\n",
      "Epoch 328, CIFAR-10 Batch 3:  Loss: 0.5257512331008911   Validation Accuracy: 0.5523999929428101\n",
      "Epoch 328, CIFAR-10 Batch 4:  Loss: 0.48772743344306946  Validation Accuracy: 0.5387999415397644\n",
      "Epoch 328, CIFAR-10 Batch 5:  Loss: 0.5274104475975037   Validation Accuracy: 0.5445998907089233\n",
      "Epoch 329, CIFAR-10 Batch 1:  Loss: 0.4761752188205719   Validation Accuracy: 0.55159991979599\n",
      "Epoch 329, CIFAR-10 Batch 2:  Loss: 0.5044838190078735   Validation Accuracy: 0.5529999136924744\n",
      "Epoch 329, CIFAR-10 Batch 3:  Loss: 0.5244004130363464   Validation Accuracy: 0.5457999110221863\n",
      "Epoch 329, CIFAR-10 Batch 4:  Loss: 0.49037376046180725  Validation Accuracy: 0.547999918460846\n",
      "Epoch 329, CIFAR-10 Batch 5:  Loss: 0.5251840353012085   Validation Accuracy: 0.5463999509811401\n",
      "Epoch 330, CIFAR-10 Batch 1:  Loss: 0.4785657525062561   Validation Accuracy: 0.5405999422073364\n",
      "Epoch 330, CIFAR-10 Batch 2:  Loss: 0.5074837803840637   Validation Accuracy: 0.5453999638557434\n",
      "Epoch 330, CIFAR-10 Batch 3:  Loss: 0.5257924795150757   Validation Accuracy: 0.548799991607666\n",
      "Epoch 330, CIFAR-10 Batch 4:  Loss: 0.49441754817962646  Validation Accuracy: 0.55159991979599\n",
      "Epoch 330, CIFAR-10 Batch 5:  Loss: 0.5275479555130005   Validation Accuracy: 0.5465999245643616\n",
      "Epoch 331, CIFAR-10 Batch 1:  Loss: 0.47592103481292725  Validation Accuracy: 0.5475999712944031\n",
      "Epoch 331, CIFAR-10 Batch 2:  Loss: 0.5059821605682373   Validation Accuracy: 0.538599967956543\n",
      "Epoch 331, CIFAR-10 Batch 3:  Loss: 0.5250236988067627   Validation Accuracy: 0.5453999042510986\n",
      "Epoch 331, CIFAR-10 Batch 4:  Loss: 0.49218833446502686  Validation Accuracy: 0.562999963760376\n",
      "Epoch 331, CIFAR-10 Batch 5:  Loss: 0.5260076522827148   Validation Accuracy: 0.5495999455451965\n",
      "Epoch 332, CIFAR-10 Batch 1:  Loss: 0.4765614867210388   Validation Accuracy: 0.5475999712944031\n",
      "Epoch 332, CIFAR-10 Batch 2:  Loss: 0.5061159133911133   Validation Accuracy: 0.5503999590873718\n",
      "Epoch 332, CIFAR-10 Batch 3:  Loss: 0.5245712995529175   Validation Accuracy: 0.5509999394416809\n",
      "Epoch 332, CIFAR-10 Batch 4:  Loss: 0.4908057749271393   Validation Accuracy: 0.5517999529838562\n",
      "Epoch 332, CIFAR-10 Batch 5:  Loss: 0.5244951844215393   Validation Accuracy: 0.5443999767303467\n",
      "Epoch 333, CIFAR-10 Batch 1:  Loss: 0.4763406217098236   Validation Accuracy: 0.5441999435424805\n",
      "Epoch 333, CIFAR-10 Batch 2:  Loss: 0.5058211088180542   Validation Accuracy: 0.5515999794006348\n",
      "Epoch 333, CIFAR-10 Batch 3:  Loss: 0.5255991220474243   Validation Accuracy: 0.5361999869346619\n",
      "Epoch 333, CIFAR-10 Batch 4:  Loss: 0.4941430687904358   Validation Accuracy: 0.5455999374389648\n",
      "Epoch 333, CIFAR-10 Batch 5:  Loss: 0.5255154371261597   Validation Accuracy: 0.5455999374389648\n",
      "Epoch 334, CIFAR-10 Batch 1:  Loss: 0.47636714577674866  Validation Accuracy: 0.5403999090194702\n",
      "Epoch 334, CIFAR-10 Batch 2:  Loss: 0.5044980049133301   Validation Accuracy: 0.5511999130249023\n",
      "Epoch 334, CIFAR-10 Batch 3:  Loss: 0.5244458317756653   Validation Accuracy: 0.5487999320030212\n",
      "Epoch 334, CIFAR-10 Batch 4:  Loss: 0.49031323194503784  Validation Accuracy: 0.5529999732971191\n",
      "Epoch 334, CIFAR-10 Batch 5:  Loss: 0.5247427821159363   Validation Accuracy: 0.5467999577522278\n",
      "Epoch 335, CIFAR-10 Batch 1:  Loss: 0.4760065972805023   Validation Accuracy: 0.5521999001502991\n",
      "Epoch 335, CIFAR-10 Batch 2:  Loss: 0.5060096979141235   Validation Accuracy: 0.5547999739646912\n",
      "Epoch 335, CIFAR-10 Batch 3:  Loss: 0.5245799422264099   Validation Accuracy: 0.5461999177932739\n",
      "Epoch 335, CIFAR-10 Batch 4:  Loss: 0.4919884502887726   Validation Accuracy: 0.5473999381065369\n",
      "Epoch 335, CIFAR-10 Batch 5:  Loss: 0.5283889174461365   Validation Accuracy: 0.553399920463562\n",
      "Epoch 336, CIFAR-10 Batch 1:  Loss: 0.47595781087875366  Validation Accuracy: 0.549799919128418\n",
      "Epoch 336, CIFAR-10 Batch 2:  Loss: 0.5047179460525513   Validation Accuracy: 0.553399920463562\n",
      "Epoch 336, CIFAR-10 Batch 3:  Loss: 0.5247238278388977   Validation Accuracy: 0.5433999300003052\n",
      "Epoch 336, CIFAR-10 Batch 4:  Loss: 0.49395468831062317  Validation Accuracy: 0.5457999110221863\n",
      "Epoch 336, CIFAR-10 Batch 5:  Loss: 0.5275036096572876   Validation Accuracy: 0.5489999651908875\n",
      "Epoch 337, CIFAR-10 Batch 1:  Loss: 0.4761924147605896   Validation Accuracy: 0.53739994764328\n",
      "Epoch 337, CIFAR-10 Batch 2:  Loss: 0.5064255595207214   Validation Accuracy: 0.5465999245643616\n",
      "Epoch 337, CIFAR-10 Batch 3:  Loss: 0.5250637531280518   Validation Accuracy: 0.5501999258995056\n",
      "Epoch 337, CIFAR-10 Batch 4:  Loss: 0.4930887520313263   Validation Accuracy: 0.5477999448776245\n",
      "Epoch 337, CIFAR-10 Batch 5:  Loss: 0.5276032090187073   Validation Accuracy: 0.5443999171257019\n",
      "Epoch 338, CIFAR-10 Batch 1:  Loss: 0.4775134325027466   Validation Accuracy: 0.5403999090194702\n",
      "Epoch 338, CIFAR-10 Batch 2:  Loss: 0.5079596042633057   Validation Accuracy: 0.5481998920440674\n",
      "Epoch 338, CIFAR-10 Batch 3:  Loss: 0.5243781805038452   Validation Accuracy: 0.5587999224662781\n",
      "Epoch 338, CIFAR-10 Batch 4:  Loss: 0.49060022830963135  Validation Accuracy: 0.5429999232292175\n",
      "Epoch 338, CIFAR-10 Batch 5:  Loss: 0.5304772853851318   Validation Accuracy: 0.5427999496459961\n",
      "Epoch 339, CIFAR-10 Batch 1:  Loss: 0.47756773233413696  Validation Accuracy: 0.5455999374389648\n",
      "Epoch 339, CIFAR-10 Batch 2:  Loss: 0.5074224472045898   Validation Accuracy: 0.553399920463562\n",
      "Epoch 339, CIFAR-10 Batch 3:  Loss: 0.5242007374763489   Validation Accuracy: 0.549799919128418\n",
      "Epoch 339, CIFAR-10 Batch 4:  Loss: 0.4901973009109497   Validation Accuracy: 0.5551999807357788\n",
      "Epoch 339, CIFAR-10 Batch 5:  Loss: 0.524815559387207    Validation Accuracy: 0.5439999103546143\n",
      "Epoch 340, CIFAR-10 Batch 1:  Loss: 0.47596031427383423  Validation Accuracy: 0.5461999177932739\n",
      "Epoch 340, CIFAR-10 Batch 2:  Loss: 0.5047224760055542   Validation Accuracy: 0.5485999584197998\n",
      "Epoch 340, CIFAR-10 Batch 3:  Loss: 0.5221006870269775   Validation Accuracy: 0.5464000105857849\n",
      "Epoch 340, CIFAR-10 Batch 4:  Loss: 0.490911066532135    Validation Accuracy: 0.5395998954772949\n",
      "Epoch 340, CIFAR-10 Batch 5:  Loss: 0.5277256369590759   Validation Accuracy: 0.5429999828338623\n",
      "Epoch 341, CIFAR-10 Batch 1:  Loss: 0.47601011395454407  Validation Accuracy: 0.5441999435424805\n",
      "Epoch 341, CIFAR-10 Batch 2:  Loss: 0.5047399997711182   Validation Accuracy: 0.5441999435424805\n",
      "Epoch 341, CIFAR-10 Batch 3:  Loss: 0.5216174125671387   Validation Accuracy: 0.5431999564170837\n",
      "Epoch 341, CIFAR-10 Batch 4:  Loss: 0.4965271055698395   Validation Accuracy: 0.5433999300003052\n",
      "Epoch 341, CIFAR-10 Batch 5:  Loss: 0.525169849395752    Validation Accuracy: 0.5411999225616455\n",
      "Epoch 342, CIFAR-10 Batch 1:  Loss: 0.4767024517059326   Validation Accuracy: 0.5455999374389648\n",
      "Epoch 342, CIFAR-10 Batch 2:  Loss: 0.5045381188392639   Validation Accuracy: 0.5453999042510986\n",
      "Epoch 342, CIFAR-10 Batch 3:  Loss: 0.5239962339401245   Validation Accuracy: 0.5495998859405518\n",
      "Epoch 342, CIFAR-10 Batch 4:  Loss: 0.49057409167289734  Validation Accuracy: 0.5411999821662903\n",
      "Epoch 342, CIFAR-10 Batch 5:  Loss: 0.525412380695343    Validation Accuracy: 0.5461999177932739\n",
      "Epoch 343, CIFAR-10 Batch 1:  Loss: 0.47596874833106995  Validation Accuracy: 0.5501999855041504\n",
      "Epoch 343, CIFAR-10 Batch 2:  Loss: 0.5044540762901306   Validation Accuracy: 0.5509999990463257\n",
      "Epoch 343, CIFAR-10 Batch 3:  Loss: 0.5216954350471497   Validation Accuracy: 0.5469999313354492\n",
      "Epoch 343, CIFAR-10 Batch 4:  Loss: 0.4934103786945343   Validation Accuracy: 0.538599967956543\n",
      "Epoch 343, CIFAR-10 Batch 5:  Loss: 0.5264039635658264   Validation Accuracy: 0.5465999245643616\n",
      "Epoch 344, CIFAR-10 Batch 1:  Loss: 0.476296067237854    Validation Accuracy: 0.5469999313354492\n",
      "Epoch 344, CIFAR-10 Batch 2:  Loss: 0.5074228644371033   Validation Accuracy: 0.5463999509811401\n",
      "Epoch 344, CIFAR-10 Batch 3:  Loss: 0.52457195520401     Validation Accuracy: 0.5507999062538147\n",
      "Epoch 344, CIFAR-10 Batch 4:  Loss: 0.4937348961830139   Validation Accuracy: 0.5423999428749084\n",
      "Epoch 344, CIFAR-10 Batch 5:  Loss: 0.5247237086296082   Validation Accuracy: 0.5457999110221863\n",
      "Epoch 345, CIFAR-10 Batch 1:  Loss: 0.47609061002731323  Validation Accuracy: 0.5507999658584595\n",
      "Epoch 345, CIFAR-10 Batch 2:  Loss: 0.5055429339408875   Validation Accuracy: 0.5461999177932739\n",
      "Epoch 345, CIFAR-10 Batch 3:  Loss: 0.5215420126914978   Validation Accuracy: 0.5423999428749084\n",
      "Epoch 345, CIFAR-10 Batch 4:  Loss: 0.493512898683548    Validation Accuracy: 0.5395998954772949\n",
      "Epoch 345, CIFAR-10 Batch 5:  Loss: 0.5278435349464417   Validation Accuracy: 0.5465999841690063\n",
      "Epoch 346, CIFAR-10 Batch 1:  Loss: 0.4759618639945984   Validation Accuracy: 0.5493999123573303\n",
      "Epoch 346, CIFAR-10 Batch 2:  Loss: 0.5108928084373474   Validation Accuracy: 0.5419999361038208\n",
      "Epoch 346, CIFAR-10 Batch 3:  Loss: 0.5222227573394775   Validation Accuracy: 0.5423998832702637\n",
      "Epoch 346, CIFAR-10 Batch 4:  Loss: 0.49376508593559265  Validation Accuracy: 0.5493999123573303\n",
      "Epoch 346, CIFAR-10 Batch 5:  Loss: 0.5268658995628357   Validation Accuracy: 0.538599967956543\n",
      "Epoch 347, CIFAR-10 Batch 1:  Loss: 0.4764254689216614   Validation Accuracy: 0.5465999245643616\n",
      "Epoch 347, CIFAR-10 Batch 2:  Loss: 0.5064114928245544   Validation Accuracy: 0.5443999767303467\n",
      "Epoch 347, CIFAR-10 Batch 3:  Loss: 0.5232037901878357   Validation Accuracy: 0.5451999306678772\n",
      "Epoch 347, CIFAR-10 Batch 4:  Loss: 0.49065276980400085  Validation Accuracy: 0.5457999110221863\n",
      "Epoch 347, CIFAR-10 Batch 5:  Loss: 0.5244774222373962   Validation Accuracy: 0.5425999760627747\n",
      "Epoch 348, CIFAR-10 Batch 1:  Loss: 0.47997918725013733  Validation Accuracy: 0.544999897480011\n",
      "Epoch 348, CIFAR-10 Batch 2:  Loss: 0.5056732892990112   Validation Accuracy: 0.5473999977111816\n",
      "Epoch 348, CIFAR-10 Batch 3:  Loss: 0.5220500826835632   Validation Accuracy: 0.5439999103546143\n",
      "Epoch 348, CIFAR-10 Batch 4:  Loss: 0.4905782639980316   Validation Accuracy: 0.5463999509811401\n",
      "Epoch 348, CIFAR-10 Batch 5:  Loss: 0.5244290828704834   Validation Accuracy: 0.554599940776825\n",
      "Epoch 349, CIFAR-10 Batch 1:  Loss: 0.47931498289108276  Validation Accuracy: 0.5383999347686768\n",
      "Epoch 349, CIFAR-10 Batch 2:  Loss: 0.507621169090271    Validation Accuracy: 0.5475999116897583\n",
      "Epoch 349, CIFAR-10 Batch 3:  Loss: 0.5238596200942993   Validation Accuracy: 0.5437999963760376\n",
      "Epoch 349, CIFAR-10 Batch 4:  Loss: 0.4908475875854492   Validation Accuracy: 0.5459999442100525\n",
      "Epoch 349, CIFAR-10 Batch 5:  Loss: 0.5280078649520874   Validation Accuracy: 0.5453999638557434\n",
      "Epoch 350, CIFAR-10 Batch 1:  Loss: 0.47743216156959534  Validation Accuracy: 0.5521999001502991\n",
      "Epoch 350, CIFAR-10 Batch 2:  Loss: 0.507813036441803    Validation Accuracy: 0.5413999557495117\n",
      "Epoch 350, CIFAR-10 Batch 3:  Loss: 0.5218551158905029   Validation Accuracy: 0.5401999354362488\n",
      "Epoch 350, CIFAR-10 Batch 4:  Loss: 0.4910157322883606   Validation Accuracy: 0.5399999618530273\n",
      "Epoch 350, CIFAR-10 Batch 5:  Loss: 0.5302225351333618   Validation Accuracy: 0.5473999381065369\n",
      "Epoch 351, CIFAR-10 Batch 1:  Loss: 0.4861077666282654   Validation Accuracy: 0.5397998690605164\n",
      "Epoch 351, CIFAR-10 Batch 2:  Loss: 0.504791259765625    Validation Accuracy: 0.543199896812439\n",
      "Epoch 351, CIFAR-10 Batch 3:  Loss: 0.5216718912124634   Validation Accuracy: 0.5521999597549438\n",
      "Epoch 351, CIFAR-10 Batch 4:  Loss: 0.49358466267585754  Validation Accuracy: 0.5425999164581299\n",
      "Epoch 351, CIFAR-10 Batch 5:  Loss: 0.5286444425582886   Validation Accuracy: 0.5407999753952026\n",
      "Epoch 352, CIFAR-10 Batch 1:  Loss: 0.47655123472213745  Validation Accuracy: 0.5411999225616455\n",
      "Epoch 352, CIFAR-10 Batch 2:  Loss: 0.5102828741073608   Validation Accuracy: 0.5363999009132385\n",
      "Epoch 352, CIFAR-10 Batch 3:  Loss: 0.5219019651412964   Validation Accuracy: 0.5399999618530273\n",
      "Epoch 352, CIFAR-10 Batch 4:  Loss: 0.49345114827156067  Validation Accuracy: 0.533799946308136\n",
      "Epoch 352, CIFAR-10 Batch 5:  Loss: 0.5266706943511963   Validation Accuracy: 0.5423999428749084\n",
      "Epoch 353, CIFAR-10 Batch 1:  Loss: 0.4764174818992615   Validation Accuracy: 0.542199969291687\n",
      "Epoch 353, CIFAR-10 Batch 2:  Loss: 0.5046280026435852   Validation Accuracy: 0.5457999110221863\n",
      "Epoch 353, CIFAR-10 Batch 3:  Loss: 0.5231773853302002   Validation Accuracy: 0.5481998920440674\n",
      "Epoch 353, CIFAR-10 Batch 4:  Loss: 0.4909367561340332   Validation Accuracy: 0.5409999489784241\n",
      "Epoch 353, CIFAR-10 Batch 5:  Loss: 0.5271347761154175   Validation Accuracy: 0.5439999103546143\n",
      "Epoch 354, CIFAR-10 Batch 1:  Loss: 0.4795989394187927   Validation Accuracy: 0.5419999361038208\n",
      "Epoch 354, CIFAR-10 Batch 2:  Loss: 0.5066603422164917   Validation Accuracy: 0.5481998920440674\n",
      "Epoch 354, CIFAR-10 Batch 3:  Loss: 0.5188299417495728   Validation Accuracy: 0.5495998859405518\n",
      "Epoch 354, CIFAR-10 Batch 4:  Loss: 0.4902070164680481   Validation Accuracy: 0.5507999062538147\n",
      "Epoch 354, CIFAR-10 Batch 5:  Loss: 0.5244790315628052   Validation Accuracy: 0.546799898147583\n",
      "Epoch 355, CIFAR-10 Batch 1:  Loss: 0.4759984612464905   Validation Accuracy: 0.5511999726295471\n",
      "Epoch 355, CIFAR-10 Batch 2:  Loss: 0.5046923160552979   Validation Accuracy: 0.5513999462127686\n",
      "Epoch 355, CIFAR-10 Batch 3:  Loss: 0.5188895463943481   Validation Accuracy: 0.55159991979599\n",
      "Epoch 355, CIFAR-10 Batch 4:  Loss: 0.4945693016052246   Validation Accuracy: 0.5437999963760376\n",
      "Epoch 355, CIFAR-10 Batch 5:  Loss: 0.5249506831169128   Validation Accuracy: 0.5393999218940735\n",
      "Epoch 356, CIFAR-10 Batch 1:  Loss: 0.47604700922966003  Validation Accuracy: 0.5465999841690063\n",
      "Epoch 356, CIFAR-10 Batch 2:  Loss: 0.5050024390220642   Validation Accuracy: 0.5461999177932739\n",
      "Epoch 356, CIFAR-10 Batch 3:  Loss: 0.5211396217346191   Validation Accuracy: 0.5459999442100525\n",
      "Epoch 356, CIFAR-10 Batch 4:  Loss: 0.4922240376472473   Validation Accuracy: 0.5445999503135681\n",
      "Epoch 356, CIFAR-10 Batch 5:  Loss: 0.5245269536972046   Validation Accuracy: 0.550399899482727\n",
      "Epoch 357, CIFAR-10 Batch 1:  Loss: 0.4792237877845764   Validation Accuracy: 0.5515999794006348\n",
      "Epoch 357, CIFAR-10 Batch 2:  Loss: 0.5045332908630371   Validation Accuracy: 0.5431999564170837\n",
      "Epoch 357, CIFAR-10 Batch 3:  Loss: 0.5188829898834229   Validation Accuracy: 0.5535999536514282\n",
      "Epoch 357, CIFAR-10 Batch 4:  Loss: 0.49414265155792236  Validation Accuracy: 0.5461999773979187\n",
      "Epoch 357, CIFAR-10 Batch 5:  Loss: 0.5243858695030212   Validation Accuracy: 0.5525999665260315\n",
      "Epoch 358, CIFAR-10 Batch 1:  Loss: 0.475925087928772    Validation Accuracy: 0.5539999008178711\n",
      "Epoch 358, CIFAR-10 Batch 2:  Loss: 0.504427969455719    Validation Accuracy: 0.5549998879432678\n",
      "Epoch 358, CIFAR-10 Batch 3:  Loss: 0.5193944573402405   Validation Accuracy: 0.5455999374389648\n",
      "Epoch 358, CIFAR-10 Batch 4:  Loss: 0.49017664790153503  Validation Accuracy: 0.5511999130249023\n",
      "Epoch 358, CIFAR-10 Batch 5:  Loss: 0.5253793001174927   Validation Accuracy: 0.5515999794006348\n",
      "Epoch 359, CIFAR-10 Batch 1:  Loss: 0.47630152106285095  Validation Accuracy: 0.5529999732971191\n",
      "Epoch 359, CIFAR-10 Batch 2:  Loss: 0.5045458674430847   Validation Accuracy: 0.5467999577522278\n",
      "Epoch 359, CIFAR-10 Batch 3:  Loss: 0.5187471508979797   Validation Accuracy: 0.5425999164581299\n",
      "Epoch 359, CIFAR-10 Batch 4:  Loss: 0.49018388986587524  Validation Accuracy: 0.5461999177932739\n",
      "Epoch 359, CIFAR-10 Batch 5:  Loss: 0.5244348645210266   Validation Accuracy: 0.5449999570846558\n",
      "Epoch 360, CIFAR-10 Batch 1:  Loss: 0.4786926507949829   Validation Accuracy: 0.5461999773979187\n",
      "Epoch 360, CIFAR-10 Batch 2:  Loss: 0.5060443878173828   Validation Accuracy: 0.5423999428749084\n",
      "Epoch 360, CIFAR-10 Batch 3:  Loss: 0.5191217064857483   Validation Accuracy: 0.5489999651908875\n",
      "Epoch 360, CIFAR-10 Batch 4:  Loss: 0.4911443889141083   Validation Accuracy: 0.5427999496459961\n",
      "Epoch 360, CIFAR-10 Batch 5:  Loss: 0.5303660035133362   Validation Accuracy: 0.5489999055862427\n",
      "Epoch 361, CIFAR-10 Batch 1:  Loss: 0.474129319190979    Validation Accuracy: 0.5493999719619751\n",
      "Epoch 361, CIFAR-10 Batch 2:  Loss: 0.5052791833877563   Validation Accuracy: 0.5479999780654907\n",
      "Epoch 361, CIFAR-10 Batch 3:  Loss: 0.5187263488769531   Validation Accuracy: 0.5483999252319336\n",
      "Epoch 361, CIFAR-10 Batch 4:  Loss: 0.4914415180683136   Validation Accuracy: 0.5409999489784241\n",
      "Epoch 361, CIFAR-10 Batch 5:  Loss: 0.5246865153312683   Validation Accuracy: 0.5425999760627747\n",
      "Epoch 362, CIFAR-10 Batch 1:  Loss: 0.4762308597564697   Validation Accuracy: 0.5525999665260315\n",
      "Epoch 362, CIFAR-10 Batch 2:  Loss: 0.50888592004776     Validation Accuracy: 0.5503999590873718\n",
      "Epoch 362, CIFAR-10 Batch 3:  Loss: 0.519516110420227    Validation Accuracy: 0.5389999747276306\n",
      "Epoch 362, CIFAR-10 Batch 4:  Loss: 0.490208238363266    Validation Accuracy: 0.5445998907089233\n",
      "Epoch 362, CIFAR-10 Batch 5:  Loss: 0.5247116684913635   Validation Accuracy: 0.5449999570846558\n",
      "Epoch 363, CIFAR-10 Batch 1:  Loss: 0.4759579598903656   Validation Accuracy: 0.5469999313354492\n",
      "Epoch 363, CIFAR-10 Batch 2:  Loss: 0.5072562098503113   Validation Accuracy: 0.5505999326705933\n",
      "Epoch 363, CIFAR-10 Batch 3:  Loss: 0.5194356441497803   Validation Accuracy: 0.540199875831604\n",
      "Epoch 363, CIFAR-10 Batch 4:  Loss: 0.4907686710357666   Validation Accuracy: 0.5329999923706055\n",
      "Epoch 363, CIFAR-10 Batch 5:  Loss: 0.527103066444397    Validation Accuracy: 0.5449999570846558\n",
      "Epoch 364, CIFAR-10 Batch 1:  Loss: 0.47634565830230713  Validation Accuracy: 0.5405999422073364\n",
      "Epoch 364, CIFAR-10 Batch 2:  Loss: 0.5044097304344177   Validation Accuracy: 0.5541999340057373\n",
      "Epoch 364, CIFAR-10 Batch 3:  Loss: 0.5187985301017761   Validation Accuracy: 0.5505999326705933\n",
      "Epoch 364, CIFAR-10 Batch 4:  Loss: 0.4902042746543884   Validation Accuracy: 0.5547999143600464\n",
      "Epoch 364, CIFAR-10 Batch 5:  Loss: 0.5248098373413086   Validation Accuracy: 0.5547999739646912\n",
      "Epoch 365, CIFAR-10 Batch 1:  Loss: 0.4761285185813904   Validation Accuracy: 0.5499999523162842\n",
      "Epoch 365, CIFAR-10 Batch 2:  Loss: 0.5073545575141907   Validation Accuracy: 0.5401999354362488\n",
      "Epoch 365, CIFAR-10 Batch 3:  Loss: 0.5183492302894592   Validation Accuracy: 0.5463999509811401\n",
      "Epoch 365, CIFAR-10 Batch 4:  Loss: 0.4916191101074219   Validation Accuracy: 0.5465999245643616\n",
      "Epoch 365, CIFAR-10 Batch 5:  Loss: 0.5215335488319397   Validation Accuracy: 0.55159991979599\n",
      "Epoch 366, CIFAR-10 Batch 1:  Loss: 0.47600656747817993  Validation Accuracy: 0.543999969959259\n",
      "Epoch 366, CIFAR-10 Batch 2:  Loss: 0.5085731148719788   Validation Accuracy: 0.5435999631881714\n",
      "Epoch 366, CIFAR-10 Batch 3:  Loss: 0.5181836485862732   Validation Accuracy: 0.5553999543190002\n",
      "Epoch 366, CIFAR-10 Batch 4:  Loss: 0.4904690980911255   Validation Accuracy: 0.5519999265670776\n",
      "Epoch 366, CIFAR-10 Batch 5:  Loss: 0.5216665267944336   Validation Accuracy: 0.5429999828338623\n",
      "Epoch 367, CIFAR-10 Batch 1:  Loss: 0.4759112298488617   Validation Accuracy: 0.5481999516487122\n",
      "Epoch 367, CIFAR-10 Batch 2:  Loss: 0.5044829845428467   Validation Accuracy: 0.5477999448776245\n",
      "Epoch 367, CIFAR-10 Batch 3:  Loss: 0.5159443020820618   Validation Accuracy: 0.541999876499176\n",
      "Epoch 367, CIFAR-10 Batch 4:  Loss: 0.4924008250236511   Validation Accuracy: 0.5455999374389648\n",
      "Epoch 367, CIFAR-10 Batch 5:  Loss: 0.5249865055084229   Validation Accuracy: 0.5445999503135681\n",
      "Epoch 368, CIFAR-10 Batch 1:  Loss: 0.47611841559410095  Validation Accuracy: 0.5413998961448669\n",
      "Epoch 368, CIFAR-10 Batch 2:  Loss: 0.5044536590576172   Validation Accuracy: 0.5417999029159546\n",
      "Epoch 368, CIFAR-10 Batch 3:  Loss: 0.5175032615661621   Validation Accuracy: 0.5457999110221863\n",
      "Epoch 368, CIFAR-10 Batch 4:  Loss: 0.4912377595901489   Validation Accuracy: 0.5435999631881714\n",
      "Epoch 368, CIFAR-10 Batch 5:  Loss: 0.5215783715248108   Validation Accuracy: 0.5496000051498413\n",
      "Epoch 369, CIFAR-10 Batch 1:  Loss: 0.47529298067092896  Validation Accuracy: 0.5553999543190002\n",
      "Epoch 369, CIFAR-10 Batch 2:  Loss: 0.5044451951980591   Validation Accuracy: 0.5481999516487122\n",
      "Epoch 369, CIFAR-10 Batch 3:  Loss: 0.5158463716506958   Validation Accuracy: 0.5483999252319336\n",
      "Epoch 369, CIFAR-10 Batch 4:  Loss: 0.49035540223121643  Validation Accuracy: 0.5425999760627747\n",
      "Epoch 369, CIFAR-10 Batch 5:  Loss: 0.5271614193916321   Validation Accuracy: 0.5451999306678772\n",
      "Epoch 370, CIFAR-10 Batch 1:  Loss: 0.4765215814113617   Validation Accuracy: 0.5489999055862427\n",
      "Epoch 370, CIFAR-10 Batch 2:  Loss: 0.5051408410072327   Validation Accuracy: 0.5489999055862427\n",
      "Epoch 370, CIFAR-10 Batch 3:  Loss: 0.5158427953720093   Validation Accuracy: 0.5431999564170837\n",
      "Epoch 370, CIFAR-10 Batch 4:  Loss: 0.49017995595932007  Validation Accuracy: 0.5555999279022217\n",
      "Epoch 370, CIFAR-10 Batch 5:  Loss: 0.5215650796890259   Validation Accuracy: 0.5513999462127686\n",
      "Epoch 371, CIFAR-10 Batch 1:  Loss: 0.480616956949234    Validation Accuracy: 0.5481998920440674\n",
      "Epoch 371, CIFAR-10 Batch 2:  Loss: 0.5046162009239197   Validation Accuracy: 0.5487998723983765\n",
      "Epoch 371, CIFAR-10 Batch 3:  Loss: 0.5160858631134033   Validation Accuracy: 0.5423999428749084\n",
      "Epoch 371, CIFAR-10 Batch 4:  Loss: 0.49622970819473267  Validation Accuracy: 0.5379999279975891\n",
      "Epoch 371, CIFAR-10 Batch 5:  Loss: 0.5221870541572571   Validation Accuracy: 0.5525999665260315\n",
      "Epoch 372, CIFAR-10 Batch 1:  Loss: 0.4759182333946228   Validation Accuracy: 0.5497999787330627\n",
      "Epoch 372, CIFAR-10 Batch 2:  Loss: 0.5069776773452759   Validation Accuracy: 0.546799898147583\n",
      "Epoch 372, CIFAR-10 Batch 3:  Loss: 0.5160205364227295   Validation Accuracy: 0.5475999116897583\n",
      "Epoch 372, CIFAR-10 Batch 4:  Loss: 0.4919552505016327   Validation Accuracy: 0.55159991979599\n",
      "Epoch 372, CIFAR-10 Batch 5:  Loss: 0.5225219130516052   Validation Accuracy: 0.5513999462127686\n",
      "Epoch 373, CIFAR-10 Batch 1:  Loss: 0.47646626830101013  Validation Accuracy: 0.5497999787330627\n",
      "Epoch 373, CIFAR-10 Batch 2:  Loss: 0.5068011283874512   Validation Accuracy: 0.5463999509811401\n",
      "Epoch 373, CIFAR-10 Batch 3:  Loss: 0.5195830464363098   Validation Accuracy: 0.5435999631881714\n",
      "Epoch 373, CIFAR-10 Batch 4:  Loss: 0.4883238971233368   Validation Accuracy: 0.5447999238967896\n",
      "Epoch 373, CIFAR-10 Batch 5:  Loss: 0.5215885639190674   Validation Accuracy: 0.5431999564170837\n",
      "Epoch 374, CIFAR-10 Batch 1:  Loss: 0.47602489590644836  Validation Accuracy: 0.5532000064849854\n",
      "Epoch 374, CIFAR-10 Batch 2:  Loss: 0.5044574737548828   Validation Accuracy: 0.5509999394416809\n",
      "Epoch 374, CIFAR-10 Batch 3:  Loss: 0.5167315006256104   Validation Accuracy: 0.5493999123573303\n",
      "Epoch 374, CIFAR-10 Batch 4:  Loss: 0.48774439096450806  Validation Accuracy: 0.5449999570846558\n",
      "Epoch 374, CIFAR-10 Batch 5:  Loss: 0.5226014256477356   Validation Accuracy: 0.5499999523162842\n",
      "Epoch 375, CIFAR-10 Batch 1:  Loss: 0.4759259819984436   Validation Accuracy: 0.5541999340057373\n",
      "Epoch 375, CIFAR-10 Batch 2:  Loss: 0.5044125318527222   Validation Accuracy: 0.5503999590873718\n",
      "Epoch 375, CIFAR-10 Batch 3:  Loss: 0.5167218446731567   Validation Accuracy: 0.5483999252319336\n",
      "Epoch 375, CIFAR-10 Batch 4:  Loss: 0.4874090850353241   Validation Accuracy: 0.5525999069213867\n",
      "Epoch 375, CIFAR-10 Batch 5:  Loss: 0.5216158032417297   Validation Accuracy: 0.5543999075889587\n",
      "Epoch 376, CIFAR-10 Batch 1:  Loss: 0.4762219786643982   Validation Accuracy: 0.553399920463562\n",
      "Epoch 376, CIFAR-10 Batch 2:  Loss: 0.50444096326828     Validation Accuracy: 0.5477999448776245\n",
      "Epoch 376, CIFAR-10 Batch 3:  Loss: 0.5162636637687683   Validation Accuracy: 0.5455999374389648\n",
      "Epoch 376, CIFAR-10 Batch 4:  Loss: 0.48819196224212646  Validation Accuracy: 0.5413999557495117\n",
      "Epoch 376, CIFAR-10 Batch 5:  Loss: 0.5221162438392639   Validation Accuracy: 0.5497999787330627\n",
      "Epoch 377, CIFAR-10 Batch 1:  Loss: 0.47590869665145874  Validation Accuracy: 0.5523999333381653\n",
      "Epoch 377, CIFAR-10 Batch 2:  Loss: 0.5044829845428467   Validation Accuracy: 0.5437999963760376\n",
      "Epoch 377, CIFAR-10 Batch 3:  Loss: 0.516157865524292    Validation Accuracy: 0.5451999306678772\n",
      "Epoch 377, CIFAR-10 Batch 4:  Loss: 0.48816901445388794  Validation Accuracy: 0.5529999732971191\n",
      "Epoch 377, CIFAR-10 Batch 5:  Loss: 0.5232021808624268   Validation Accuracy: 0.5519999265670776\n",
      "Epoch 378, CIFAR-10 Batch 1:  Loss: 0.4759257137775421   Validation Accuracy: 0.5573999285697937\n",
      "Epoch 378, CIFAR-10 Batch 2:  Loss: 0.5044068694114685   Validation Accuracy: 0.5565999150276184\n",
      "Epoch 378, CIFAR-10 Batch 3:  Loss: 0.5159813165664673   Validation Accuracy: 0.5433999300003052\n",
      "Epoch 378, CIFAR-10 Batch 4:  Loss: 0.48737189173698425  Validation Accuracy: 0.5479999780654907\n",
      "Epoch 378, CIFAR-10 Batch 5:  Loss: 0.5221327543258667   Validation Accuracy: 0.53739994764328\n",
      "Epoch 379, CIFAR-10 Batch 1:  Loss: 0.4761742949485779   Validation Accuracy: 0.5431999564170837\n",
      "Epoch 379, CIFAR-10 Batch 2:  Loss: 0.504479169845581    Validation Accuracy: 0.548599898815155\n",
      "Epoch 379, CIFAR-10 Batch 3:  Loss: 0.5160505771636963   Validation Accuracy: 0.5489999651908875\n",
      "Epoch 379, CIFAR-10 Batch 4:  Loss: 0.4905717372894287   Validation Accuracy: 0.5481998920440674\n",
      "Epoch 379, CIFAR-10 Batch 5:  Loss: 0.5215178728103638   Validation Accuracy: 0.5571999549865723\n",
      "Epoch 380, CIFAR-10 Batch 1:  Loss: 0.4760584831237793   Validation Accuracy: 0.5477999448776245\n",
      "Epoch 380, CIFAR-10 Batch 2:  Loss: 0.5091663599014282   Validation Accuracy: 0.5465999245643616\n",
      "Epoch 380, CIFAR-10 Batch 3:  Loss: 0.5304162502288818   Validation Accuracy: 0.5403999090194702\n",
      "Epoch 380, CIFAR-10 Batch 4:  Loss: 0.48769906163215637  Validation Accuracy: 0.544999897480011\n",
      "Epoch 380, CIFAR-10 Batch 5:  Loss: 0.5215256214141846   Validation Accuracy: 0.5561999082565308\n",
      "Epoch 381, CIFAR-10 Batch 1:  Loss: 0.47938066720962524  Validation Accuracy: 0.5577999949455261\n",
      "Epoch 381, CIFAR-10 Batch 2:  Loss: 0.5044528245925903   Validation Accuracy: 0.5493999719619751\n",
      "Epoch 381, CIFAR-10 Batch 3:  Loss: 0.5187561511993408   Validation Accuracy: 0.5463999509811401\n",
      "Epoch 381, CIFAR-10 Batch 4:  Loss: 0.4873230457305908   Validation Accuracy: 0.5511999726295471\n",
      "Epoch 381, CIFAR-10 Batch 5:  Loss: 0.5216706991195679   Validation Accuracy: 0.5519999265670776\n",
      "Epoch 382, CIFAR-10 Batch 1:  Loss: 0.47890201210975647  Validation Accuracy: 0.5449999570846558\n",
      "Epoch 382, CIFAR-10 Batch 2:  Loss: 0.5049698948860168   Validation Accuracy: 0.5437999367713928\n",
      "Epoch 382, CIFAR-10 Batch 3:  Loss: 0.5193974375724792   Validation Accuracy: 0.5446000099182129\n",
      "Epoch 382, CIFAR-10 Batch 4:  Loss: 0.48742246627807617  Validation Accuracy: 0.5523998737335205\n",
      "Epoch 382, CIFAR-10 Batch 5:  Loss: 0.5215609073638916   Validation Accuracy: 0.5509999394416809\n",
      "Epoch 383, CIFAR-10 Batch 1:  Loss: 0.47653213143348694  Validation Accuracy: 0.5473999977111816\n",
      "Epoch 383, CIFAR-10 Batch 2:  Loss: 0.5055790543556213   Validation Accuracy: 0.5437999367713928\n",
      "Epoch 383, CIFAR-10 Batch 3:  Loss: 0.515923798084259    Validation Accuracy: 0.5429999232292175\n",
      "Epoch 383, CIFAR-10 Batch 4:  Loss: 0.4873119592666626   Validation Accuracy: 0.5519999265670776\n",
      "Epoch 383, CIFAR-10 Batch 5:  Loss: 0.5218127369880676   Validation Accuracy: 0.553399920463562\n",
      "Epoch 384, CIFAR-10 Batch 1:  Loss: 0.47606003284454346  Validation Accuracy: 0.5533999800682068\n",
      "Epoch 384, CIFAR-10 Batch 2:  Loss: 0.5045201778411865   Validation Accuracy: 0.5495999455451965\n",
      "Epoch 384, CIFAR-10 Batch 3:  Loss: 0.5163078904151917   Validation Accuracy: 0.5501999855041504\n",
      "Epoch 384, CIFAR-10 Batch 4:  Loss: 0.48757505416870117  Validation Accuracy: 0.5601999759674072\n",
      "Epoch 384, CIFAR-10 Batch 5:  Loss: 0.5215758085250854   Validation Accuracy: 0.5531998872756958\n",
      "Epoch 385, CIFAR-10 Batch 1:  Loss: 0.4763299226760864   Validation Accuracy: 0.5463999509811401\n",
      "Epoch 385, CIFAR-10 Batch 2:  Loss: 0.5044180154800415   Validation Accuracy: 0.5541999340057373\n",
      "Epoch 385, CIFAR-10 Batch 3:  Loss: 0.5167821645736694   Validation Accuracy: 0.5427999496459961\n",
      "Epoch 385, CIFAR-10 Batch 4:  Loss: 0.4904315769672394   Validation Accuracy: 0.5433999300003052\n",
      "Epoch 385, CIFAR-10 Batch 5:  Loss: 0.525653600692749    Validation Accuracy: 0.5509999990463257\n",
      "Epoch 386, CIFAR-10 Batch 1:  Loss: 0.4760456085205078   Validation Accuracy: 0.5469999313354492\n",
      "Epoch 386, CIFAR-10 Batch 2:  Loss: 0.5044500827789307   Validation Accuracy: 0.5379999876022339\n",
      "Epoch 386, CIFAR-10 Batch 3:  Loss: 0.5158835649490356   Validation Accuracy: 0.5459999442100525\n",
      "Epoch 386, CIFAR-10 Batch 4:  Loss: 0.4901624023914337   Validation Accuracy: 0.5473999381065369\n",
      "Epoch 386, CIFAR-10 Batch 5:  Loss: 0.5215436816215515   Validation Accuracy: 0.5523999333381653\n",
      "Epoch 387, CIFAR-10 Batch 1:  Loss: 0.4759126305580139   Validation Accuracy: 0.55159991979599\n",
      "Epoch 387, CIFAR-10 Batch 2:  Loss: 0.5044165849685669   Validation Accuracy: 0.553399920463562\n",
      "Epoch 387, CIFAR-10 Batch 3:  Loss: 0.515891432762146    Validation Accuracy: 0.5441999435424805\n",
      "Epoch 387, CIFAR-10 Batch 4:  Loss: 0.49793583154678345  Validation Accuracy: 0.5501998662948608\n",
      "Epoch 387, CIFAR-10 Batch 5:  Loss: 0.5215216875076294   Validation Accuracy: 0.5564000010490417\n",
      "Epoch 388, CIFAR-10 Batch 1:  Loss: 0.47594326734542847  Validation Accuracy: 0.547999918460846\n",
      "Epoch 388, CIFAR-10 Batch 2:  Loss: 0.5044326186180115   Validation Accuracy: 0.5465999245643616\n",
      "Epoch 388, CIFAR-10 Batch 3:  Loss: 0.5212996006011963   Validation Accuracy: 0.531999945640564\n",
      "Epoch 388, CIFAR-10 Batch 4:  Loss: 0.49068692326545715  Validation Accuracy: 0.5501999258995056\n",
      "Epoch 388, CIFAR-10 Batch 5:  Loss: 0.521579384803772    Validation Accuracy: 0.5511999726295471\n",
      "Epoch 389, CIFAR-10 Batch 1:  Loss: 0.4759863018989563   Validation Accuracy: 0.550399899482727\n",
      "Epoch 389, CIFAR-10 Batch 2:  Loss: 0.5063889622688293   Validation Accuracy: 0.547999918460846\n",
      "Epoch 389, CIFAR-10 Batch 3:  Loss: 0.5164169669151306   Validation Accuracy: 0.5539999008178711\n",
      "Epoch 389, CIFAR-10 Batch 4:  Loss: 0.48998960852622986  Validation Accuracy: 0.5559999942779541\n",
      "Epoch 389, CIFAR-10 Batch 5:  Loss: 0.5240769386291504   Validation Accuracy: 0.5519999265670776\n",
      "Epoch 390, CIFAR-10 Batch 1:  Loss: 0.4760040044784546   Validation Accuracy: 0.550399899482727\n",
      "Epoch 390, CIFAR-10 Batch 2:  Loss: 0.5046660900115967   Validation Accuracy: 0.5409998893737793\n",
      "Epoch 390, CIFAR-10 Batch 3:  Loss: 0.5178671479225159   Validation Accuracy: 0.5405999422073364\n",
      "Epoch 390, CIFAR-10 Batch 4:  Loss: 0.49048706889152527  Validation Accuracy: 0.5527999401092529\n",
      "Epoch 390, CIFAR-10 Batch 5:  Loss: 0.5216456651687622   Validation Accuracy: 0.5489999055862427\n",
      "Epoch 391, CIFAR-10 Batch 1:  Loss: 0.4779536724090576   Validation Accuracy: 0.5435999035835266\n",
      "Epoch 391, CIFAR-10 Batch 2:  Loss: 0.5081427693367004   Validation Accuracy: 0.5309999585151672\n",
      "Epoch 391, CIFAR-10 Batch 3:  Loss: 0.5159370303153992   Validation Accuracy: 0.5441999435424805\n",
      "Epoch 391, CIFAR-10 Batch 4:  Loss: 0.4873211979866028   Validation Accuracy: 0.5509999394416809\n",
      "Epoch 391, CIFAR-10 Batch 5:  Loss: 0.5283779501914978   Validation Accuracy: 0.5549999475479126\n",
      "Epoch 392, CIFAR-10 Batch 1:  Loss: 0.4792243242263794   Validation Accuracy: 0.5473999381065369\n",
      "Epoch 392, CIFAR-10 Batch 2:  Loss: 0.5055738091468811   Validation Accuracy: 0.5393998622894287\n",
      "Epoch 392, CIFAR-10 Batch 3:  Loss: 0.5211315155029297   Validation Accuracy: 0.5455999374389648\n",
      "Epoch 392, CIFAR-10 Batch 4:  Loss: 0.4874333143234253   Validation Accuracy: 0.5417999625205994\n",
      "Epoch 392, CIFAR-10 Batch 5:  Loss: 0.5216494202613831   Validation Accuracy: 0.5437999367713928\n",
      "Epoch 393, CIFAR-10 Batch 1:  Loss: 0.4759508967399597   Validation Accuracy: 0.5381999611854553\n",
      "Epoch 393, CIFAR-10 Batch 2:  Loss: 0.5058584809303284   Validation Accuracy: 0.5423999428749084\n",
      "Epoch 393, CIFAR-10 Batch 3:  Loss: 0.5164960026741028   Validation Accuracy: 0.5443999767303467\n",
      "Epoch 393, CIFAR-10 Batch 4:  Loss: 0.4873267710208893   Validation Accuracy: 0.5425999164581299\n",
      "Epoch 393, CIFAR-10 Batch 5:  Loss: 0.5215175747871399   Validation Accuracy: 0.5429999232292175\n",
      "Epoch 394, CIFAR-10 Batch 1:  Loss: 0.4759727716445923   Validation Accuracy: 0.5459999442100525\n",
      "Epoch 394, CIFAR-10 Batch 2:  Loss: 0.5052053928375244   Validation Accuracy: 0.5445999503135681\n",
      "Epoch 394, CIFAR-10 Batch 3:  Loss: 0.5159192085266113   Validation Accuracy: 0.5389999151229858\n",
      "Epoch 394, CIFAR-10 Batch 4:  Loss: 0.48839253187179565  Validation Accuracy: 0.5431999564170837\n",
      "Epoch 394, CIFAR-10 Batch 5:  Loss: 0.5223056077957153   Validation Accuracy: 0.5445998907089233\n",
      "Epoch 395, CIFAR-10 Batch 1:  Loss: 0.4760335087776184   Validation Accuracy: 0.5461999773979187\n",
      "Epoch 395, CIFAR-10 Batch 2:  Loss: 0.5045247077941895   Validation Accuracy: 0.547999918460846\n",
      "Epoch 395, CIFAR-10 Batch 3:  Loss: 0.5161359906196594   Validation Accuracy: 0.5447999835014343\n",
      "Epoch 395, CIFAR-10 Batch 4:  Loss: 0.48761945962905884  Validation Accuracy: 0.5509999394416809\n",
      "Epoch 395, CIFAR-10 Batch 5:  Loss: 0.5244244337081909   Validation Accuracy: 0.5427998900413513\n",
      "Epoch 396, CIFAR-10 Batch 1:  Loss: 0.47615790367126465  Validation Accuracy: 0.5493999719619751\n",
      "Epoch 396, CIFAR-10 Batch 2:  Loss: 0.5108424425125122   Validation Accuracy: 0.5347999334335327\n",
      "Epoch 396, CIFAR-10 Batch 3:  Loss: 0.5158634781837463   Validation Accuracy: 0.5415999293327332\n",
      "Epoch 396, CIFAR-10 Batch 4:  Loss: 0.4915415942668915   Validation Accuracy: 0.5495998859405518\n",
      "Epoch 396, CIFAR-10 Batch 5:  Loss: 0.5216364860534668   Validation Accuracy: 0.5461999177932739\n",
      "Epoch 397, CIFAR-10 Batch 1:  Loss: 0.4809224009513855   Validation Accuracy: 0.5445999503135681\n",
      "Epoch 397, CIFAR-10 Batch 2:  Loss: 0.5054678916931152   Validation Accuracy: 0.5553998947143555\n",
      "Epoch 397, CIFAR-10 Batch 3:  Loss: 0.5161083340644836   Validation Accuracy: 0.5447999238967896\n",
      "Epoch 397, CIFAR-10 Batch 4:  Loss: 0.487697958946228    Validation Accuracy: 0.5521999001502991\n",
      "Epoch 397, CIFAR-10 Batch 5:  Loss: 0.523547887802124    Validation Accuracy: 0.5483999252319336\n",
      "Epoch 398, CIFAR-10 Batch 1:  Loss: 0.47889959812164307  Validation Accuracy: 0.5495999455451965\n",
      "Epoch 398, CIFAR-10 Batch 2:  Loss: 0.509637713432312    Validation Accuracy: 0.5445999503135681\n",
      "Epoch 398, CIFAR-10 Batch 3:  Loss: 0.5191935300827026   Validation Accuracy: 0.5406000018119812\n",
      "Epoch 398, CIFAR-10 Batch 4:  Loss: 0.4874178171157837   Validation Accuracy: 0.5487999320030212\n",
      "Epoch 398, CIFAR-10 Batch 5:  Loss: 0.5221824645996094   Validation Accuracy: 0.5467999577522278\n",
      "Epoch 399, CIFAR-10 Batch 1:  Loss: 0.47608405351638794  Validation Accuracy: 0.5499999523162842\n",
      "Epoch 399, CIFAR-10 Batch 2:  Loss: 0.5048052668571472   Validation Accuracy: 0.5417999625205994\n",
      "Epoch 399, CIFAR-10 Batch 3:  Loss: 0.5208256244659424   Validation Accuracy: 0.5335999727249146\n",
      "Epoch 399, CIFAR-10 Batch 4:  Loss: 0.48956865072250366  Validation Accuracy: 0.5443999767303467\n",
      "Epoch 399, CIFAR-10 Batch 5:  Loss: 0.5215044021606445   Validation Accuracy: 0.5513999462127686\n",
      "Epoch 400, CIFAR-10 Batch 1:  Loss: 0.47714364528656006  Validation Accuracy: 0.5489999055862427\n",
      "Epoch 400, CIFAR-10 Batch 2:  Loss: 0.504505455493927    Validation Accuracy: 0.5475999116897583\n",
      "Epoch 400, CIFAR-10 Batch 3:  Loss: 0.5158525705337524   Validation Accuracy: 0.546799898147583\n",
      "Epoch 400, CIFAR-10 Batch 4:  Loss: 0.48745957016944885  Validation Accuracy: 0.5521999597549438\n",
      "Epoch 400, CIFAR-10 Batch 5:  Loss: 0.5282044410705566   Validation Accuracy: 0.5367999076843262\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "save_model_path = './image_classification'\n",
    "\n",
    "print('Training...')\n",
    "with tf.Session() as sess:\n",
    "    # Initializing the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Training cycle\n",
    "    for epoch in range(epochs):\n",
    "        # Loop over all batches\n",
    "        n_batches = 5\n",
    "        for batch_i in range(1, n_batches + 1):\n",
    "            for batch_features, batch_labels in helper.load_preprocess_training_batch(batch_i, batch_size):\n",
    "                train_neural_network(sess, optimizer, keep_probability, batch_features, batch_labels)\n",
    "            print('Epoch {:>2}, CIFAR-10 Batch {}:  '.format(epoch + 1, batch_i), end='')\n",
    "            print_stats(sess, batch_features, batch_labels, cost, accuracy)\n",
    "            \n",
    "    # Save Model\n",
    "    saver = tf.train.Saver()\n",
    "    save_path = saver.save(sess, save_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Checkpoint\n",
    "The model has been saved to disk.\n",
    "## Test Model\n",
    "Test your model against the test dataset.  This will be your final accuracy. You should have an accuracy greater than 50%. If you don't, keep tweaking the model architecture and parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy: 0.5336774528026581\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAscAAAJ/CAYAAACUb342AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7c457f9438>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 319,
       "width": 355
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import helper\n",
    "import random\n",
    "\n",
    "# Set batch size if not already set\n",
    "try:\n",
    "    if batch_size:\n",
    "        pass\n",
    "except NameError:\n",
    "    batch_size = 64\n",
    "\n",
    "save_model_path = './image_classification'\n",
    "n_samples = 4\n",
    "top_n_predictions = 3\n",
    "\n",
    "def test_model():\n",
    "    \"\"\"\n",
    "    Test the saved model against the test dataset\n",
    "    \"\"\"\n",
    "\n",
    "    test_features, test_labels = pickle.load(open('preprocess_test.p', mode='rb'))\n",
    "    loaded_graph = tf.Graph()\n",
    "\n",
    "    with tf.Session(graph=loaded_graph) as sess:\n",
    "        # Load model\n",
    "        loader = tf.train.import_meta_graph(save_model_path + '.meta')\n",
    "        loader.restore(sess, save_model_path)\n",
    "\n",
    "        # Get Tensors from loaded model\n",
    "        loaded_x = loaded_graph.get_tensor_by_name('x:0')\n",
    "        loaded_y = loaded_graph.get_tensor_by_name('y:0')\n",
    "        loaded_keep_prob = loaded_graph.get_tensor_by_name('keep_prob:0')\n",
    "        loaded_logits = loaded_graph.get_tensor_by_name('logits:0')\n",
    "        loaded_acc = loaded_graph.get_tensor_by_name('accuracy:0')\n",
    "        \n",
    "        # Get accuracy in batches for memory limitations\n",
    "        test_batch_acc_total = 0\n",
    "        test_batch_count = 0\n",
    "        \n",
    "        for test_feature_batch, test_label_batch in helper.batch_features_labels(test_features, test_labels, batch_size):\n",
    "            test_batch_acc_total += sess.run(\n",
    "                loaded_acc,\n",
    "                feed_dict={loaded_x: test_feature_batch, loaded_y: test_label_batch, loaded_keep_prob: 1.0})\n",
    "            test_batch_count += 1\n",
    "\n",
    "        print('Testing Accuracy: {}\\n'.format(test_batch_acc_total/test_batch_count))\n",
    "\n",
    "        # Print Random Samples\n",
    "        random_test_features, random_test_labels = tuple(zip(*random.sample(list(zip(test_features, test_labels)), n_samples)))\n",
    "        random_test_predictions = sess.run(\n",
    "            tf.nn.top_k(tf.nn.softmax(loaded_logits), top_n_predictions),\n",
    "            feed_dict={loaded_x: random_test_features, loaded_y: random_test_labels, loaded_keep_prob: 1.0})\n",
    "        helper.display_image_predictions(random_test_features, random_test_labels, random_test_predictions)\n",
    "\n",
    "\n",
    "test_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Why 50-80% Accuracy?\n",
    "You might be wondering why you can't get an accuracy any higher. First things first, 50% isn't bad for a simple CNN.  Pure guessing would get you 10% accuracy. However, you might notice people are getting scores [well above 80%](http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html#43494641522d3130).  That's because we haven't taught you all there is to know about neural networks. We still need to cover a few more techniques.\n",
    "## Submitting This Project\n",
    "When submitting this project, make sure to run all the cells before saving the notebook.  Save the notebook file as \"dlnd_image_classification.ipynb\" and save it as a HTML file under \"File\" -> \"Download as\".  Include the \"helper.py\" and \"problem_unittests.py\" files in your submission."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
